---
title: "Flair Models"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Flair Models}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

<!-- ```{r, include = FALSE} -->
<!-- library(flaiR) -->
<!-- library(reticulate) -->
<!-- # system(paste(reticulate::py_config()$python, "-m pip install flair")) -->
<!-- reticulate::py_install("flair") -->
<!-- ``` -->


## List of NER Models

| ID                  | Task              | Language         | Training Dataset            | Accuracy     | Contributor / Notes    |
|---------------------|-------------------|------------------|-----------------------------|--------------|------------------------|
| 'ner'               | NER (4-class)     | English          | Conll-03                    | 93.03 (F1)   |                        |
| 'ner-fast'          | NER (4-class)     | English          | Conll-03                    | 92.75 (F1)   | (fast model)           |
| 'ner-large'         | NER (4-class)     | English / Multilingual | Conll-03               | 94.09 (F1)   | (large model)         |
| 'ner-pooled'        | NER (4-class)     | English          | Conll-03                    | 93.24 (F1)   | (memory inefficient)   |
| 'ner-ontonotes'     | NER (18-class)    | English          | Ontonotes                   | 89.06 (F1)   |                        |
| 'ner-ontonotes-fast'| NER (18-class)    | English          | Ontonotes                   | 89.27 (F1)   | (fast model)           |
| 'ner-ontonotes-large'| NER (18-class)   | English / Multilingual | Ontonotes             | 90.93 (F1)   | (large model)          |
| 'ar-ner'            | NER (4-class)     | Arabic           | AQMAR & ANERcorp (curated)  | 86.66 (F1)   |                        |
| 'da-ner'            | NER (4-class)     | Danish           | Danish NER dataset          |              | AmaliePauli            |
| 'de-ner'            | NER (4-class)     | German           | Conll-03                    | 87.94 (F1)   |                        |
| 'de-ner-large'      | NER (4-class)     | German / Multilingual | Conll-03               | 92.31 (F1)   |                        |
| 'de-ner-germeval'   | NER (4-class)     | German           | Germeval                    | 84.90 (F1)   |                        |
| 'de-ner-legal'      | NER (legal text)  | German           | LER dataset                 | 96.35 (F1)   |                        |
| 'fr-ner'            | NER (4-class)     | French           | WikiNER (aij-wikiner-fr-wp3)| 95.57 (F1)   | mhham                  |
| 'es-ner-large'      | NER (4-class)     | Spanish          | CoNLL-03                    | 90.54 (F1)   | mhham                  |
| 'nl-ner'            | NER (4-class)     | Dutch            | CoNLL 2002                  | 92.58 (F1)   |                        |
| 'nl-ner-large'      | NER (4-class)     | Dutch            | Conll-03                    | 95.25 (F1)   |                        |
| 'nl-ner-rnn'        | NER (4-class)     | Dutch            | CoNLL 2002                  | 90.79 (F1)   |                        |
| 'ner-ukrainian'     | NER (4-class)     | Ukrainian        | NER-UK dataset              | 86.05 (F1)   | dchaplinsky             |


__Source__: https://flairnlp.github.io/docs/tutorial-basics/tagging-entities


&nbsp;

-----

## List of POS Models

| ID              | Task                     | Language            | Training Dataset                  | Accuracy             | Contributor / Notes                 |
|-----------------|--------------------------|---------------------|-----------------------------------|----------------------|-------------------------------------|
| 'pos'           | POS-tagging              | English             | Ontonotes                         | 98.19 (Accuracy)     |                                     |
| 'pos-fast'      | POS-tagging              | English             | Ontonotes                         | 98.1 (Accuracy)      | (fast model)                        |
| 'upos'          | POS-tagging (universal)  | English             | Ontonotes                         | 98.6 (Accuracy)      |                                     |
| 'upos-fast'     | POS-tagging (universal)  | English             | Ontonotes                         | 98.47 (Accuracy)     | (fast model)                        |
| 'pos-multi'     | POS-tagging              | Multilingual        | UD Treebanks                      | 96.41 (average acc.) | (12 languages)                      |
| 'pos-multi-fast'| POS-tagging              | Multilingual        | UD Treebanks                      | 92.88 (average acc.) | (12 languages)                      |
| 'ar-pos'        | POS-tagging              | Arabic (+dialects)  | combination of corpora            |                      |                                     |
| 'de-pos'        | POS-tagging              | German              | UD German - HDT                   | 98.50 (Accuracy)     |                                     |
| 'de-pos-tweets' | POS-tagging              | German              | German Tweets                     | 93.06 (Accuracy)     | stefan-it                           |
| 'da-pos'        | POS-tagging              | Danish              | Danish Dependency Treebank        |                      | AmaliePauli                         |
| 'ml-pos'        | POS-tagging              | Malayalam           | 30000 Malayalam sentences         | 83                   | sabiqueqb                           |
| 'ml-upos'       | POS-tagging              | Malayalam           | 30000 Malayalam sentences         | 87                   | sabiqueqb                           |
| 'pt-pos-clinical'|POS-tagging              | Portuguese          | PUCPR                             | 92.39                | LucasFerroHAILab for clinical texts|
| 'pos-ukrainian' | POS-tagging              | Ukrainian           | Ukrainian UD                      | 97.93 (F1)           | dchaplinsky                         |

__Source__: https://flairnlp.github.io/docs/tutorial-basics/part-of-speech-tagging

&nbsp;

-----

## List of Sentiment Models
| ID                      | Language | Task                                                      | Training Dataset           | Accuracy           |
|-------------------------|----------|-----------------------------------------------------------|----------------------------|--------------------|
| 'sentiment'             | English  | detecting positive and negative sentiment (transformer-based) | movie and product reviews | 98.87              |
| 'sentiment-fast'        | English  | detecting positive and negative sentiment (RNN-based)     | movie and product reviews | 96.83              |
| 'de-offensive-language' | German   | detecting offensive language                              | GermEval 2018 Task 1       | 75.71 (Macro F1)   |

__Source__: https://flairnlp.github.io/docs/tutorial-basics/tagging-sentiment


