[{"path":[]},{"path":"https://davidycliao.github.io/flaiR/articles/quickstart.html","id":"option-1-direct-installation","dir":"Articles","previous_headings":"","what":"Option 1: Direct Installation","title":"Quick Start","text":"System Requirements: Python >= 3.10 R >= 4.2.0 Rstudio","code":""},{"path":"https://davidycliao.github.io/flaiR/articles/quickstart.html","id":"macos-terminal","dir":"Articles","previous_headings":"Option 1: Direct Installation","what":"macOS Terminal","title":"Quick Start","text":"","code":"# Install Python 3.10 or higher. brew install python@3.10  # Verify Python installation python3 --version  # Install R brew install R  # Verify R installation R --version  # Install RStudio brew install --cask rstudio"},{"path":"https://davidycliao.github.io/flaiR/articles/quickstart.html","id":"powershell-for-windows","dir":"Articles","previous_headings":"Option 1: Direct Installation","what":"PowerShell for Windows","title":"Quick Start","text":"","code":"# Download Python installer from python.org and run: # https://www.python.org/downloads/  # Verify Python installation python --version  # Install R # Download R installer from CRAN and run: # https://cran.r-project.org/bin/windows/base/  # Verify R installation R --version"},{"path":"https://davidycliao.github.io/flaiR/articles/quickstart.html","id":"option-2-docker-setup","dir":"Articles","previous_headings":"","what":"Option 2: Docker Setup","title":"Quick Start","text":"Docker image (12.5GB) includes complete R/Python development environment RStudio Server + R environments Python 3.9 flair NLP dependencies (PyTorch, models). Please ensure system meets requirements: least 15GB free disk space Minimum 16GB RAM recommended Stable internet connection initial download Docker installed running Intel/AMD Processors: Apple Silicon (M1/M2 Mac): Access RStudio Server: Open browser: http://localhost:8787 Username: rstudio Password: rstudio123","code":"# Pull and run docker pull ghcr.io/davidycliao/flair-rstudio:latest docker run -d \\   -p 8787:8787 \\   --user root \\   -e USER=rstudio \\   -e PASSWORD=rstudio123 \\   --name flair-rstudio \\   ghcr.io/davidycliao/flair-rstudio:latest # Pull and run with platform specification docker pull --platform linux/amd64 ghcr.io/davidycliao/flair-rstudio:latest docker run -d \\   -p 8787:8787 \\   --platform linux/amd64 \\   --user root \\   -e USER=rstudio \\   -e PASSWORD=rstudio123 \\   --name flair-rstudio \\   ghcr.io/davidycliao/flair-rstudio:latest"},{"path":"https://davidycliao.github.io/flaiR/articles/quickstart.html","id":"troubleshooting-guide","dir":"Articles","previous_headings":"","what":"Troubleshooting Guide","title":"Quick Start","text":"faiR : Automatically check Python environment Install required Python packages (flair dependencies) Configure Python-R connection Installation typically proceeds automatically RStudio R handling dependencies. However, users (particularly Mac ARM64 systems) may encounter compilation issues. ’s comprehensive guide resolve common problems: Mac M1/M2 (Apple Silicon) Specific Setup 1 Architecture Options Requires specific compiler setup May encounter additional compatibility issues Native ARM64 Version Requires specific compiler setup May encounter additional compatibility issues Version Compatibility R Version Requirements: R 4.5.0+: Matrix 1.7-0 newer R 4.4.x: Matrix 1.6-x R 4.3.x: Matrix 1.5-1 R 4.2.x: Matrix 1.4-1 Compiler Setup ARM64 Systems Required Steps: Download GNU Fortran https://mac.r-project.org/tools/ R 4.3.0+: Install GNU Fortran 12.2 (universal) Supports Intel Apple Silicon CRAN macOS tools page GitHub R-macos GNU Fortran releases Automatic Dependencies (Python) flaiR automatically install following Python packages setup: flair (default dependencies) scipy (1.12.0) gensim (4.3.2) Note: manual installation required. packages handled automatically flaiR installation. can manage Python settings RStudio Tools -> Global Options -> Python. check Python configuration, use: Recommended Configurations stable usage, strongly recommend installing specific versions. *: R 4.2.1, particularly using Matrix package ARM 64 architecture Macs (M1/M2), compatibility issues gfortran may occur. ’s recommended avoid combination.   encounter problems questions: Check documentation Visit Issues page Join Discussion forum Troubleshooting Docker encounter issues: access via http://localhost:8788 Container already exists: retry run command. Check container status:","code":"install.packages(\"remotes\") remotes::install_github(\"davidycliao/flaiR\", force = TRUE) reticulate::py_config() # Try using a different port (e.g., 8788) docker run -d \\   -p 8788:8787 \\   --platform linux/amd64 \\   --user root \\   --name flair-rstudio \\   ghcr.io/davidycliao/flair-rstudio:latest # Remove existing container docker stop flair-rstudio docker rm flair-rstudio # View running containers docker ps # View all containers including stopped ones docker ps -a # View container logs docker logs flair-rstudio"},{"path":"https://davidycliao.github.io/flaiR/articles/quickstart.html","id":"nlp-tasks","dir":"Articles","previous_headings":"","what":"NLP Tasks","title":"Quick Start","text":"R users, flairR extends FlairNLP three NLP task functions extract features neat format data.table. featured functions, don’t write loops format parsed output . main features include part--speech tagging, named entity recognition sentiment analysis. Additionally, handle load RAM dealing larger corpora, flairR supports batch processing handle texts batches, especially useful dealing large datasets, optimize memory usage performance.  ","code":""},{"path":"https://davidycliao.github.io/flaiR/articles/quickstart.html","id":"training-and-fine-tuning","dir":"Articles","previous_headings":"","what":"Training and Fine-tuning","title":"Quick Start","text":"flairR, use simplest S3 method wrap major modules. modules work like R6 R environment loaded Flair NLP. Python, functions methods (sometimes referred functions R) within class can accessed using $ operator. example, flair.trainers import ModelTrainer Python equivalent ModelTrainer <- flair_trainers()$ModelTrainer R environment flairR.  ","code":""},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"flair-nlp-and-flair-for-social-science","dir":"Articles","previous_headings":"","what":"Flair NLP and flaiR for Social Science","title":"Tutorial","text":"Flair NLP open-source Natural Language Processing (NLP) library developed Zalando Research. Known state---art solutions, excels contextual string embeddings, Named Entity Recognition (NER), Part--Speech tagging (POS). Flair offers robust text analysis tools multiple embedding approaches, including Flair contextual string embeddings, transformer-based embeddings Hugging Face, traditional models like GloVe fasttext. Additionally, provides pre-trained models various languages seamless integration fine-tuned transformers hosted Hugging Face. flaiR bridges powerful NLP features Python R environment, making advanced text analysis accessible social science researcher combining Flair’s ease use R’s familiar interface integration popular R packages quanteda .","code":""},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"the-overview","dir":"Articles","previous_headings":"","what":"The Overview","title":"Tutorial","text":"Sentence Token Object FlaiR Sequence Taggings Overview Embedding Embedding Examples Performing NER Tasks Training Binary Classifier flaiR Training RNNa Finetune BERT Extending conText’s Embedding Regression  ","code":""},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"sentence-and-token","dir":"Articles","previous_headings":"","what":"Sentence and Token","title":"Tutorial","text":"Sentence Token fundamental classes.","code":""},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"sentence","dir":"Articles","previous_headings":"Sentence and Token","what":"Sentence","title":"Tutorial","text":"Sentence Flair object contains sequence Token objects, can annotated labels, named entities, part--speech tags, . also can store embeddings sentence whole different kinds linguistic annotations. ’s simple example create Sentence: Sentence[26] means total 26 tokens sentence.","code":"# Creating a Sentence object library(flaiR) string <- \"What I see in UCD today, what I have seen of UCD in its impact on my own life and the life of Ireland.\" Sentence <- flair_data()$Sentence sentence <- Sentence(string) print(sentence) #> Sentence[26]: \"What I see in UCD today, what I have seen of UCD in its impact on my own life and the life of Ireland.\""},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"token","dir":"Articles","previous_headings":"Sentence and Token","what":"Token","title":"Tutorial","text":"use Flair handle text data,1 Sentence Token objects often play central roles many use cases. create Sentence object, automatically tokenizes text, removing need create Token object manually. Unlike R, indexes 1, Python indexes 0. Therefore, using loop, use seq_along(sentence) - 1. output something like: can directly use $tokens method print tokens. Retrieve Token comprehend string representation format Sentence object, tagging least one token adequate. Python’s get_token(n) method allows us retrieve Token object particular token. Additionally, can use [] index specific token. word (punctuation) text treated individual Token object. Token objects store text information possible linguistic information (part--speech tags named entity tags) embedding (used model generate ). need create Token objects manually, understanding manage useful situations might want fine-tune tokenization process. example, can control exactness tokenization manually creating Token objects Sentence object. makes Flair flexible handling text data since automatic tokenization feature can used rapid development, also allowing users fine-tune tokenization. Annotate POS tag NER tag add_label(label_type, value) method can employed assign label token. Universal POS tags, sentence[10] ‘see’, ‘seen’ might tagged VERB, indicating past participle form verb. can also add NER (Named Entity Recognition) tag sentence[4], “UCD”, identifying university Dublin. print sentence object, Sentence[50] provides information 50 tokens → [‘’/ORG, ‘seen’/VERB], thus displaying two tagging pieces information.","code":"# The Sentence object has automatically created and contains multiple Token objects # We can iterate through the Sentence object to view each Token  for (i in seq_along(sentence)-1) {   print(sentence[[i]]) } #> Token[0]: \"What\" #> Token[1]: \"I\" #> Token[2]: \"see\" #> Token[3]: \"in\" #> Token[4]: \"UCD\" #> Token[5]: \"today\" #> Token[6]: \",\" #> Token[7]: \"what\" #> Token[8]: \"I\" #> Token[9]: \"have\" #> Token[10]: \"seen\" #> Token[11]: \"of\" #> Token[12]: \"UCD\" #> Token[13]: \"in\" #> Token[14]: \"its\" #> Token[15]: \"impact\" #> Token[16]: \"on\" #> Token[17]: \"my\" #> Token[18]: \"own\" #> Token[19]: \"life\" #> Token[20]: \"and\" #> Token[21]: \"the\" #> Token[22]: \"life\" #> Token[23]: \"of\" #> Token[24]: \"Ireland\" #> Token[25]: \".\" print(sentence$tokens) #> [[1]] #> Token[0]: \"What\" #>  #> [[2]] #> Token[1]: \"I\" #>  #> [[3]] #> Token[2]: \"see\" #>  #> [[4]] #> Token[3]: \"in\" #>  #> [[5]] #> Token[4]: \"UCD\" #>  #> [[6]] #> Token[5]: \"today\" #>  #> [[7]] #> Token[6]: \",\" #>  #> [[8]] #> Token[7]: \"what\" #>  #> [[9]] #> Token[8]: \"I\" #>  #> [[10]] #> Token[9]: \"have\" #>  #> [[11]] #> Token[10]: \"seen\" #>  #> [[12]] #> Token[11]: \"of\" #>  #> [[13]] #> Token[12]: \"UCD\" #>  #> [[14]] #> Token[13]: \"in\" #>  #> [[15]] #> Token[14]: \"its\" #>  #> [[16]] #> Token[15]: \"impact\" #>  #> [[17]] #> Token[16]: \"on\" #>  #> [[18]] #> Token[17]: \"my\" #>  #> [[19]] #> Token[18]: \"own\" #>  #> [[20]] #> Token[19]: \"life\" #>  #> [[21]] #> Token[20]: \"and\" #>  #> [[22]] #> Token[21]: \"the\" #>  #> [[23]] #> Token[22]: \"life\" #>  #> [[24]] #> Token[23]: \"of\" #>  #> [[25]] #> Token[24]: \"Ireland\" #>  #> [[26]] #> Token[25]: \".\" # method in Python sentence$get_token(5) #> Token[4]: \"UCD\" # indexing in R  sentence[6] #> Token[6]: \",\" sentence[10]$add_label('manual-pos', 'VERB') print(sentence[10]) #> Token[10]: \"seen\" → VERB (1.0000) sentence[4]$add_label('ner', 'ORG') print(sentence[4]) #> Token[4]: \"UCD\" → ORG (1.0000) print(sentence) #> Sentence[26]: \"What I see in UCD today, what I have seen of UCD in its impact on my own life and the life of Ireland.\" → [\"UCD\"/ORG, \"seen\"/VERB]"},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"corpus","dir":"Articles","previous_headings":"Sentence and Token","what":"Corpus","title":"Tutorial","text":"Corpus object Flair fundamental data structure represents dataset containing text samples, usually comprising training set, development set (validation set), test set. ’s designed work smoothly Flair’s models tasks like named entity recognition, text classification, . Attributes: train: list sentences (ListSentence) form training dataset. dev (development): list sentences (ListSentence) form development (validation) dataset. test: list sentences (ListSentence) form test dataset. Important Methods: downsample: method allows downsample (reduce) number sentences train, dev, test splits. obtain_statistics: method gives quick overview statistics corpus, including number sentences distribution labels. make_vocab_dictionary: Used create vocabulary dictionary corpus. $obtain_statistics() method Corpus object Flair library provides overview dataset statistics. method returns Python dictionary details training, validation (development), test datasets make corpus. R, can use jsonlite package format JSON. R , use data article Temporal Focus Campaign Communication Stefan Muller, published Journal Politics 2020, example. First, vectorize cc_muller$text using Sentence function transform list object. , reformat cc_muller$class_pro_retro factor. ’s essential note R handles numerical values differently Python. R, numerical values represented floating point, ’s advisable convert factors strings. Lastly, employ map function purrr package assign labels sentence corpus using $add_label method. perform train-test split using base R, can follow steps: don’t provide dev set, flaiR force carve portion test set serve dev set. However, cases train test sets provided without dev set, flaiR might automatically take fraction train set (e.g., 10%) use dev set (#2259). offer mechanism model selection prevent model overfitting train set. “Corpus” function, random selection \"dev\" dataset. ensure reproducibility, need set seed flaiR framework. can accomplish calling top-level module “flair” flaiR using $set_seed(1964L) set seed. later sections, similar processing using Corpus. Following , focus advanced NLP applications.  ","code":"library(flaiR) Corpus <- flair_data()$Corpus Sentence <- flair_data()$Sentence # Create some example sentences train <- list(Sentence('This is a training example.')) dev <-  list(Sentence('This is a validation example.')) test <- list(Sentence('This is a test example.'))  # Create a corpus using the custom data splits corp <-  Corpus(train = train, dev = dev, test = test) library(jsonlite) data <- fromJSON(corp$obtain_statistics()) formatted_str <- toJSON(data, pretty=TRUE) print(formatted_str) #> { #>   \"TRAIN\": { #>     \"dataset\": [\"TRAIN\"], #>     \"total_number_of_documents\": [1], #>     \"number_of_documents_per_class\": {}, #>     \"number_of_tokens_per_tag\": {}, #>     \"number_of_tokens\": { #>       \"total\": [6], #>       \"min\": [6], #>       \"max\": [6], #>       \"avg\": [6] #>     } #>   }, #>   \"TEST\": { #>     \"dataset\": [\"TEST\"], #>     \"total_number_of_documents\": [1], #>     \"number_of_documents_per_class\": {}, #>     \"number_of_tokens_per_tag\": {}, #>     \"number_of_tokens\": { #>       \"total\": [6], #>       \"min\": [6], #>       \"max\": [6], #>       \"avg\": [6] #>     } #>   }, #>   \"DEV\": { #>     \"dataset\": [\"DEV\"], #>     \"total_number_of_documents\": [1], #>     \"number_of_documents_per_class\": {}, #>     \"number_of_tokens_per_tag\": {}, #>     \"number_of_tokens\": { #>       \"total\": [6], #>       \"min\": [6], #>       \"max\": [6], #>       \"avg\": [6] #>     } #>   } #> } library(purrr) #>  #> Attaching package: 'purrr' #> The following object is masked from 'package:jsonlite': #>  #>     flatten data(cc_muller) # The `Sentence` object tokenizes text  text <- lapply( cc_muller$text, Sentence) # split sentence object to train and test.  labels <- as.factor(cc_muller$class_pro_retro) # `$add_label` method assigns the corresponding coded type to each Sentence corpus. text <- map2(text, labels, ~ .x$add_label(\"classification\", .y), .progress = TRUE) set.seed(2046) sample <- sample(c(TRUE, FALSE), length(text), replace=TRUE, prob=c(0.8, 0.2)) train  <- text[sample] test   <- text[!sample] sprintf(\"Corpus object sizes - Train: %d |  Test: %d\", length(train), length(test)) #> [1] \"Corpus object sizes - Train: 4710 |  Test: 1148\" flair <- import_flair() flair$set_seed(1964L) corp <- Corpus(train=train,                   # dev=test,                  test=test) #> 2025-01-06 02:14:03,806 No dev split found. Using 10% (i.e. 471 samples) of the train split as dev data sprintf(\"Corpus object sizes - Train: %d | Test: %d | Dev: %d\",          length(corp$train),          length(corp$test),         length(corp$dev)) #> [1] \"Corpus object sizes - Train: 4239 | Test: 1148 | Dev: 471\""},{"path":[]},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"tag-entities-in-text","dir":"Articles","previous_headings":"Sequence Taggings","what":"Tag Entities in Text","title":"Tutorial","text":"Let’s run named entity recognition following example sentence: “love Berlin New York”. , need make Sentence object text, load pre-trained model use predict tags object. NER Models Source: https://flairnlp.github.io/docs/tutorial-basics/tagging-entities POS Models Source: https://flairnlp.github.io/docs/tutorial-basics/part--speech-tagging print annotations: Use loop print POS tag. ’s important note Python indexed 0. Therefore, R environment, must use seq_along(sentence$get_labels()) - 1.","code":"# attach flaiR in R library(flaiR)  # make a sentence  Sentence <- flair_data()$Sentence sentence <- Sentence('I love Berlin and New York.')  # load the NER tagger SequenceTagger <- flair_models()$SequenceTagger tagger <- SequenceTagger$load('flair/ner-english')   #> 2025-01-06 02:14:04,448 SequenceTagger predicts: Dictionary with 20 tags: <unk>, O, S-ORG, S-MISC, B-PER, E-PER, S-LOC, B-ORG, E-ORG, I-PER, S-PER, B-MISC, I-MISC, E-MISC, I-ORG, B-LOC, E-LOC, I-LOC, <START>, <STOP>  # run NER over sentence tagger$predict(sentence) # print the sentence with all annotations print(sentence) #> Sentence[7]: \"I love Berlin and New York.\" → [\"Berlin\"/LOC, \"New York\"/LOC] for (i in seq_along(sentence$get_labels())) {       print(sentence$get_labels()[[i]])   } #> 'Span[2:3]: \"Berlin\"'/'LOC' (0.9812) #> 'Span[4:6]: \"New York\"'/'LOC' (0.9957)"},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"tag-part-of-speech","dir":"Articles","previous_headings":"Sequence Taggings","what":"Tag Part-of-Speech","title":"Tutorial","text":"use flaiR/POS-english POS tagging standard models Hugging Face. Penn Treebank POS Tags Reference Use loop print POS tag.","code":"# attach flaiR in R library(flaiR)  # make a sentence Sentence <- flair_data()$Sentence sentence <- Sentence('I love Berlin and New York.')  # load the NER tagger Classifier <- flair_nn()$Classifier tagger <- Classifier$load('pos') #> 2025-01-06 02:14:05,497 SequenceTagger predicts: Dictionary with 53 tags: <unk>, O, UH, ,, VBD, PRP, VB, PRP$, NN, RB, ., DT, JJ, VBP, VBG, IN, CD, NNS, NNP, WRB, VBZ, WDT, CC, TO, MD, VBN, WP, :, RP, EX, JJR, FW, XX, HYPH, POS, RBR, JJS, PDT, NNPS, RBS, AFX, WP$, -LRB-, -RRB-, ``, '', LS, $, SYM, ADD # run NER over sentence tagger$predict(sentence) # print the sentence with all annotations print(sentence) #> Sentence[7]: \"I love Berlin and New York.\" → [\"I\"/PRP, \"love\"/VBP, \"Berlin\"/NNP, \"and\"/CC, \"New\"/NNP, \"York\"/NNP, \".\"/.] for (i in seq_along(sentence$get_labels())) {       print(sentence$get_labels()[[i]])   } #> 'Token[0]: \"I\"'/'PRP' (1.0) #> 'Token[1]: \"love\"'/'VBP' (1.0) #> 'Token[2]: \"Berlin\"'/'NNP' (0.9999) #> 'Token[3]: \"and\"'/'CC' (1.0) #> 'Token[4]: \"New\"'/'NNP' (1.0) #> 'Token[5]: \"York\"'/'NNP' (1.0) #> 'Token[6]: \".\"'/'.' (1.0)"},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"detect-sentiment","dir":"Articles","previous_headings":"Sequence Taggings","what":"Detect Sentiment","title":"Tutorial","text":"Let’s run sentiment analysis sentence determine whether POSITIVE NEGATIVE. can essentially code . Instead loading ‘ner’ model, now load 'sentiment' model:","code":"# attach flaiR in R library(flaiR)  # make a sentence Sentence <- flair_data()$Sentence sentence <- Sentence('I love Berlin and New York.')  # load the Classifier tagger from flair.nn module Classifier <- flair_nn()$Classifier tagger <- Classifier$load('sentiment')  # run sentiment analysis over sentence tagger$predict(sentence) # print the sentence with all annotations print(sentence) #> Sentence[7]: \"I love Berlin and New York.\" → POSITIVE (0.9982)"},{"path":[]},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"parts-of-speech-tagging-across-full-dataframe","dir":"Articles","previous_headings":"Sequence Taggings > Dealing with Dataframe","what":"Parts-of-Speech Tagging Across Full DataFrame","title":"Tutorial","text":"can apply Part--Speech (POS) tagging across entire DataFrame using Flair’s pre-trained models. Let’s walk example using pos-fast model. can apply Part--Speech (POS) tagging across entire DataFrame using Flair’s pre-trained models. Let’s walk example using pos-fast model. First, let’s load required packages sample data: POS tagging, ’ll use Flair’s pre-trained model. pos-fast model offers good balance speed accuracy. pre-trained models, check Flair’s documentation Flair POS Tagging Documentation. two ways load POS tagger: Load tag dictionary display (default): show available POS tags grouped categories (nouns, verbs, adjectives, etc.). Load without tag display cleaner output: Now can process texts:","code":"library(flaiR) data(uk_immigration) uk_immigration <- uk_immigration[1:2,] tagger_pos <- load_tagger_pos(\"pos-fast\") #> Loading POS tagger model: pos-fast #> 2025-01-06 02:14:09,013 SequenceTagger predicts: Dictionary with 53 tags: <unk>, O, UH, ,, VBD, PRP, VB, PRP$, NN, RB, ., DT, JJ, VBP, VBG, IN, CD, NNS, NNP, WRB, VBZ, WDT, CC, TO, MD, VBN, WP, :, RP, EX, JJR, FW, XX, HYPH, POS, RBR, JJS, PDT, NNPS, RBS, AFX, WP$, -LRB-, -RRB-, ``, '', LS, $, SYM, ADD #>  #> POS Tagger Dictionary: #> ======================================== #> Total tags: 53 #> ---------------------------------------- #> Special:       <unk>, O, <START>, <STOP>  #> Nouns:         PRP, PRP$, NN, NNS, NNP, WP, EX, NNPS, WP$  #> Verbs:         VBD, VB, VBP, VBG, VBZ, MD, VBN  #> Adjectives:    JJ, JJR, POS, JJS  #> Adverbs:       RB, WRB, RBR, RBS  #> Determiners:   DT, WDT, PDT  #> Prepositions:  IN, TO  #> Conjunctions:  CC  #> Numbers:       CD  #> Punctuation:   <unk>, ,, ., :, HYPH, -LRB-, -RRB-, ``, '', $, NFP, <START>, <STOP>  #> Others:        UH, FW, XX, LS, $, SYM, ADD  #> ---------------------------------------- #> Common POS Tag Meanings: #> NN*: Nouns (NNP: Proper, NNS: Plural) #> VB*: Verbs (VBD: Past, VBG: Gerund) #> JJ*: Adjectives (JJR: Comparative) #> RB*: Adverbs #> PRP: Pronouns, DT: Determiners #> IN: Prepositions, CC: Conjunctions #> ======================================== pos_tagger <- load_tagger_pos(\"pos-fast\", show_tags = FALSE) #> Loading POS tagger model: pos-fast #> 2025-01-06 02:14:09,490 SequenceTagger predicts: Dictionary with 53 tags: <unk>, O, UH, ,, VBD, PRP, VB, PRP$, NN, RB, ., DT, JJ, VBP, VBG, IN, CD, NNS, NNP, WRB, VBZ, WDT, CC, TO, MD, VBN, WP, :, RP, EX, JJR, FW, XX, HYPH, POS, RBR, JJS, PDT, NNPS, RBS, AFX, WP$, -LRB-, -RRB-, ``, '', LS, $, SYM, ADD results <- get_pos(texts = uk_immigration$text,                    doc_ids = uk_immigration$speaker,                    show.text_id = TRUE,                    tagger = pos_tagger)  head(results, n = 10) #>               doc_id token_id #>               <char>    <num> #>  1: Philip Hollobone        0 #>  2: Philip Hollobone        1 #>  3: Philip Hollobone        2 #>  4: Philip Hollobone        3 #>  5: Philip Hollobone        4 #>  6: Philip Hollobone        5 #>  7: Philip Hollobone        6 #>  8: Philip Hollobone        7 #>  9: Philip Hollobone        8 #> 10: Philip Hollobone        9 #>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   text_id #>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <char> #>  1: I thank Mr. Speaker for giving me permission to hold this debate today. I welcome the Minister-I very much appreciate the contact from his office prior to today-and the Conservative and Liberal Democrat Front Benchers to the debate. I also welcome my hon. Friends on the Back Benches. Immigration is the most important issue for my constituents. I get more complaints, comments and suggestions about immigration than about anything else. In the Kettering constituency, the number of immigrants is actually very low. There is a well-settled Sikh community in the middle of Kettering town itself, which has been in Kettering for some 40 or 50 years and is very much part of the local community and of the fabric of local life. There are other very small migrant groups in my constituency, but it is predominantly made up of indigenous British people. However, there is huge concern among my constituents about the level of immigration into our country. I believe that I am right in saying that, in recent years, net immigration into the United Kingdom is the largest wave of immigration that our country has ever known and, proportionately, is probably the biggest wave of immigration since the Norman conquest. My contention is that our country simply cannot cope with immigration on that scale-to coin a phrase, we simply cannot go on like this. It is about time that mainstream politicians started airing the views of their constituents, because for too long people have muttered under their breath that they are concerned about immigration. They have been frightened to speak out about it because they are frightened of being accused of being racist. My contention is that immigration is not a racist issue; it is a question of numbers. I personally could not care tuppence about the ethnicity of the immigrants concerned, the colour of their skin or the language that they speak. What I am concerned about is the very large numbers of new arrivals to our country. My contention is that the United Kingdom simply cannot cope with them. #>  2: I thank Mr. Speaker for giving me permission to hold this debate today. I welcome the Minister-I very much appreciate the contact from his office prior to today-and the Conservative and Liberal Democrat Front Benchers to the debate. I also welcome my hon. Friends on the Back Benches. Immigration is the most important issue for my constituents. I get more complaints, comments and suggestions about immigration than about anything else. In the Kettering constituency, the number of immigrants is actually very low. There is a well-settled Sikh community in the middle of Kettering town itself, which has been in Kettering for some 40 or 50 years and is very much part of the local community and of the fabric of local life. There are other very small migrant groups in my constituency, but it is predominantly made up of indigenous British people. However, there is huge concern among my constituents about the level of immigration into our country. I believe that I am right in saying that, in recent years, net immigration into the United Kingdom is the largest wave of immigration that our country has ever known and, proportionately, is probably the biggest wave of immigration since the Norman conquest. My contention is that our country simply cannot cope with immigration on that scale-to coin a phrase, we simply cannot go on like this. It is about time that mainstream politicians started airing the views of their constituents, because for too long people have muttered under their breath that they are concerned about immigration. They have been frightened to speak out about it because they are frightened of being accused of being racist. My contention is that immigration is not a racist issue; it is a question of numbers. I personally could not care tuppence about the ethnicity of the immigrants concerned, the colour of their skin or the language that they speak. What I am concerned about is the very large numbers of new arrivals to our country. My contention is that the United Kingdom simply cannot cope with them. #>  3: I thank Mr. Speaker for giving me permission to hold this debate today. I welcome the Minister-I very much appreciate the contact from his office prior to today-and the Conservative and Liberal Democrat Front Benchers to the debate. I also welcome my hon. Friends on the Back Benches. Immigration is the most important issue for my constituents. I get more complaints, comments and suggestions about immigration than about anything else. In the Kettering constituency, the number of immigrants is actually very low. There is a well-settled Sikh community in the middle of Kettering town itself, which has been in Kettering for some 40 or 50 years and is very much part of the local community and of the fabric of local life. There are other very small migrant groups in my constituency, but it is predominantly made up of indigenous British people. However, there is huge concern among my constituents about the level of immigration into our country. I believe that I am right in saying that, in recent years, net immigration into the United Kingdom is the largest wave of immigration that our country has ever known and, proportionately, is probably the biggest wave of immigration since the Norman conquest. My contention is that our country simply cannot cope with immigration on that scale-to coin a phrase, we simply cannot go on like this. It is about time that mainstream politicians started airing the views of their constituents, because for too long people have muttered under their breath that they are concerned about immigration. They have been frightened to speak out about it because they are frightened of being accused of being racist. My contention is that immigration is not a racist issue; it is a question of numbers. I personally could not care tuppence about the ethnicity of the immigrants concerned, the colour of their skin or the language that they speak. What I am concerned about is the very large numbers of new arrivals to our country. My contention is that the United Kingdom simply cannot cope with them. #>  4: I thank Mr. Speaker for giving me permission to hold this debate today. I welcome the Minister-I very much appreciate the contact from his office prior to today-and the Conservative and Liberal Democrat Front Benchers to the debate. I also welcome my hon. Friends on the Back Benches. Immigration is the most important issue for my constituents. I get more complaints, comments and suggestions about immigration than about anything else. In the Kettering constituency, the number of immigrants is actually very low. There is a well-settled Sikh community in the middle of Kettering town itself, which has been in Kettering for some 40 or 50 years and is very much part of the local community and of the fabric of local life. There are other very small migrant groups in my constituency, but it is predominantly made up of indigenous British people. However, there is huge concern among my constituents about the level of immigration into our country. I believe that I am right in saying that, in recent years, net immigration into the United Kingdom is the largest wave of immigration that our country has ever known and, proportionately, is probably the biggest wave of immigration since the Norman conquest. My contention is that our country simply cannot cope with immigration on that scale-to coin a phrase, we simply cannot go on like this. It is about time that mainstream politicians started airing the views of their constituents, because for too long people have muttered under their breath that they are concerned about immigration. They have been frightened to speak out about it because they are frightened of being accused of being racist. My contention is that immigration is not a racist issue; it is a question of numbers. I personally could not care tuppence about the ethnicity of the immigrants concerned, the colour of their skin or the language that they speak. What I am concerned about is the very large numbers of new arrivals to our country. My contention is that the United Kingdom simply cannot cope with them. #>  5: I thank Mr. Speaker for giving me permission to hold this debate today. I welcome the Minister-I very much appreciate the contact from his office prior to today-and the Conservative and Liberal Democrat Front Benchers to the debate. I also welcome my hon. Friends on the Back Benches. Immigration is the most important issue for my constituents. I get more complaints, comments and suggestions about immigration than about anything else. In the Kettering constituency, the number of immigrants is actually very low. There is a well-settled Sikh community in the middle of Kettering town itself, which has been in Kettering for some 40 or 50 years and is very much part of the local community and of the fabric of local life. There are other very small migrant groups in my constituency, but it is predominantly made up of indigenous British people. However, there is huge concern among my constituents about the level of immigration into our country. I believe that I am right in saying that, in recent years, net immigration into the United Kingdom is the largest wave of immigration that our country has ever known and, proportionately, is probably the biggest wave of immigration since the Norman conquest. My contention is that our country simply cannot cope with immigration on that scale-to coin a phrase, we simply cannot go on like this. It is about time that mainstream politicians started airing the views of their constituents, because for too long people have muttered under their breath that they are concerned about immigration. They have been frightened to speak out about it because they are frightened of being accused of being racist. My contention is that immigration is not a racist issue; it is a question of numbers. I personally could not care tuppence about the ethnicity of the immigrants concerned, the colour of their skin or the language that they speak. What I am concerned about is the very large numbers of new arrivals to our country. My contention is that the United Kingdom simply cannot cope with them. #>  6: I thank Mr. Speaker for giving me permission to hold this debate today. I welcome the Minister-I very much appreciate the contact from his office prior to today-and the Conservative and Liberal Democrat Front Benchers to the debate. I also welcome my hon. Friends on the Back Benches. Immigration is the most important issue for my constituents. I get more complaints, comments and suggestions about immigration than about anything else. In the Kettering constituency, the number of immigrants is actually very low. There is a well-settled Sikh community in the middle of Kettering town itself, which has been in Kettering for some 40 or 50 years and is very much part of the local community and of the fabric of local life. There are other very small migrant groups in my constituency, but it is predominantly made up of indigenous British people. However, there is huge concern among my constituents about the level of immigration into our country. I believe that I am right in saying that, in recent years, net immigration into the United Kingdom is the largest wave of immigration that our country has ever known and, proportionately, is probably the biggest wave of immigration since the Norman conquest. My contention is that our country simply cannot cope with immigration on that scale-to coin a phrase, we simply cannot go on like this. It is about time that mainstream politicians started airing the views of their constituents, because for too long people have muttered under their breath that they are concerned about immigration. They have been frightened to speak out about it because they are frightened of being accused of being racist. My contention is that immigration is not a racist issue; it is a question of numbers. I personally could not care tuppence about the ethnicity of the immigrants concerned, the colour of their skin or the language that they speak. What I am concerned about is the very large numbers of new arrivals to our country. My contention is that the United Kingdom simply cannot cope with them. #>  7: I thank Mr. Speaker for giving me permission to hold this debate today. I welcome the Minister-I very much appreciate the contact from his office prior to today-and the Conservative and Liberal Democrat Front Benchers to the debate. I also welcome my hon. Friends on the Back Benches. Immigration is the most important issue for my constituents. I get more complaints, comments and suggestions about immigration than about anything else. In the Kettering constituency, the number of immigrants is actually very low. There is a well-settled Sikh community in the middle of Kettering town itself, which has been in Kettering for some 40 or 50 years and is very much part of the local community and of the fabric of local life. There are other very small migrant groups in my constituency, but it is predominantly made up of indigenous British people. However, there is huge concern among my constituents about the level of immigration into our country. I believe that I am right in saying that, in recent years, net immigration into the United Kingdom is the largest wave of immigration that our country has ever known and, proportionately, is probably the biggest wave of immigration since the Norman conquest. My contention is that our country simply cannot cope with immigration on that scale-to coin a phrase, we simply cannot go on like this. It is about time that mainstream politicians started airing the views of their constituents, because for too long people have muttered under their breath that they are concerned about immigration. They have been frightened to speak out about it because they are frightened of being accused of being racist. My contention is that immigration is not a racist issue; it is a question of numbers. I personally could not care tuppence about the ethnicity of the immigrants concerned, the colour of their skin or the language that they speak. What I am concerned about is the very large numbers of new arrivals to our country. My contention is that the United Kingdom simply cannot cope with them. #>  8: I thank Mr. Speaker for giving me permission to hold this debate today. I welcome the Minister-I very much appreciate the contact from his office prior to today-and the Conservative and Liberal Democrat Front Benchers to the debate. I also welcome my hon. Friends on the Back Benches. Immigration is the most important issue for my constituents. I get more complaints, comments and suggestions about immigration than about anything else. In the Kettering constituency, the number of immigrants is actually very low. There is a well-settled Sikh community in the middle of Kettering town itself, which has been in Kettering for some 40 or 50 years and is very much part of the local community and of the fabric of local life. There are other very small migrant groups in my constituency, but it is predominantly made up of indigenous British people. However, there is huge concern among my constituents about the level of immigration into our country. I believe that I am right in saying that, in recent years, net immigration into the United Kingdom is the largest wave of immigration that our country has ever known and, proportionately, is probably the biggest wave of immigration since the Norman conquest. My contention is that our country simply cannot cope with immigration on that scale-to coin a phrase, we simply cannot go on like this. It is about time that mainstream politicians started airing the views of their constituents, because for too long people have muttered under their breath that they are concerned about immigration. They have been frightened to speak out about it because they are frightened of being accused of being racist. My contention is that immigration is not a racist issue; it is a question of numbers. I personally could not care tuppence about the ethnicity of the immigrants concerned, the colour of their skin or the language that they speak. What I am concerned about is the very large numbers of new arrivals to our country. My contention is that the United Kingdom simply cannot cope with them. #>  9: I thank Mr. Speaker for giving me permission to hold this debate today. I welcome the Minister-I very much appreciate the contact from his office prior to today-and the Conservative and Liberal Democrat Front Benchers to the debate. I also welcome my hon. Friends on the Back Benches. Immigration is the most important issue for my constituents. I get more complaints, comments and suggestions about immigration than about anything else. In the Kettering constituency, the number of immigrants is actually very low. There is a well-settled Sikh community in the middle of Kettering town itself, which has been in Kettering for some 40 or 50 years and is very much part of the local community and of the fabric of local life. There are other very small migrant groups in my constituency, but it is predominantly made up of indigenous British people. However, there is huge concern among my constituents about the level of immigration into our country. I believe that I am right in saying that, in recent years, net immigration into the United Kingdom is the largest wave of immigration that our country has ever known and, proportionately, is probably the biggest wave of immigration since the Norman conquest. My contention is that our country simply cannot cope with immigration on that scale-to coin a phrase, we simply cannot go on like this. It is about time that mainstream politicians started airing the views of their constituents, because for too long people have muttered under their breath that they are concerned about immigration. They have been frightened to speak out about it because they are frightened of being accused of being racist. My contention is that immigration is not a racist issue; it is a question of numbers. I personally could not care tuppence about the ethnicity of the immigrants concerned, the colour of their skin or the language that they speak. What I am concerned about is the very large numbers of new arrivals to our country. My contention is that the United Kingdom simply cannot cope with them. #> 10: I thank Mr. Speaker for giving me permission to hold this debate today. I welcome the Minister-I very much appreciate the contact from his office prior to today-and the Conservative and Liberal Democrat Front Benchers to the debate. I also welcome my hon. Friends on the Back Benches. Immigration is the most important issue for my constituents. I get more complaints, comments and suggestions about immigration than about anything else. In the Kettering constituency, the number of immigrants is actually very low. There is a well-settled Sikh community in the middle of Kettering town itself, which has been in Kettering for some 40 or 50 years and is very much part of the local community and of the fabric of local life. There are other very small migrant groups in my constituency, but it is predominantly made up of indigenous British people. However, there is huge concern among my constituents about the level of immigration into our country. I believe that I am right in saying that, in recent years, net immigration into the United Kingdom is the largest wave of immigration that our country has ever known and, proportionately, is probably the biggest wave of immigration since the Norman conquest. My contention is that our country simply cannot cope with immigration on that scale-to coin a phrase, we simply cannot go on like this. It is about time that mainstream politicians started airing the views of their constituents, because for too long people have muttered under their breath that they are concerned about immigration. They have been frightened to speak out about it because they are frightened of being accused of being racist. My contention is that immigration is not a racist issue; it is a question of numbers. I personally could not care tuppence about the ethnicity of the immigrants concerned, the colour of their skin or the language that they speak. What I am concerned about is the very large numbers of new arrivals to our country. My contention is that the United Kingdom simply cannot cope with them. #>          token    tag  score #>         <char> <char>  <num> #>  1:          I    PRP 1.0000 #>  2:      thank    VBP 0.9992 #>  3:        Mr.    NNP 1.0000 #>  4:    Speaker    NNP 1.0000 #>  5:        for     IN 1.0000 #>  6:     giving    VBG 1.0000 #>  7:         me    PRP 1.0000 #>  8: permission     NN 0.9999 #>  9:         to     TO 0.9999 #> 10:       hold     VB 1.0000"},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"tagging-entities-across-full-dataframe","dir":"Articles","previous_headings":"Sequence Taggings > Dealing with Dataframe","what":"Tagging Entities Across Full DataFrame","title":"Tutorial","text":"section focuses performing Named Entity Recognition (NER) data stored dataframe format. goal identify tag named entities within text organized structured dataframe. load flaiR package use built-uk_immigration dataset. demonstration purposes, ’m taking first two rows. dataset contains discussions immigration UK. Load pre-trained model ner. pre-trained models, see https://flairnlp.github.io/docs/tutorial-basics/tagging-entities. Next, load latest model hosted maintained Hugging Face Flair NLP team. Flair NER models, can visit official Flair NLP page Hugging Face (https://huggingface.co/flair). load pre-trained NER model. Since ’m using Mac M1/M2, set model run MPS device faster processing. want use pre-trained models, can check Flair documentation website available options. Now ’m ready process text:  ","code":"library(flaiR) data(uk_immigration) uk_immigration <- head(uk_immigration, n = 2) # Load model without displaying tags # tagger <- load_tagger_ner(\"flair/ner-english-large\", show_tags = FALSE)  library(flaiR) tagger_ner <- load_tagger_ner(\"flair/ner-english-ontonotes\") #> 2025-01-06 02:14:15,798 SequenceTagger predicts: Dictionary with 75 tags: O, S-PERSON, B-PERSON, E-PERSON, I-PERSON, S-GPE, B-GPE, E-GPE, I-GPE, S-ORG, B-ORG, E-ORG, I-ORG, S-DATE, B-DATE, E-DATE, I-DATE, S-CARDINAL, B-CARDINAL, E-CARDINAL, I-CARDINAL, S-NORP, B-NORP, E-NORP, I-NORP, S-MONEY, B-MONEY, E-MONEY, I-MONEY, S-PERCENT, B-PERCENT, E-PERCENT, I-PERCENT, S-ORDINAL, B-ORDINAL, E-ORDINAL, I-ORDINAL, S-LOC, B-LOC, E-LOC, I-LOC, S-TIME, B-TIME, E-TIME, I-TIME, S-WORK_OF_ART, B-WORK_OF_ART, E-WORK_OF_ART, I-WORK_OF_ART, S-FAC #>  #> NER Tagger Dictionary: #> ======================================== #> Total tags: 75 #> Model: flair/ner-english-ontonotes #> ---------------------------------------- #> Special        : O, <START>, <STOP> #> Person         : S-PERSON, B-PERSON, E-PERSON, I-PERSON #> Organization   : S-ORG, B-ORG, E-ORG, I-ORG #> Location       : S-GPE, B-GPE, E-GPE, I-GPE, S-LOC, B-LOC, E-LOC, I-LOC #> Time           : S-DATE, B-DATE, E-DATE, I-DATE, S-TIME, B-TIME, E-TIME, I-TIME #> Numbers        : S-CARDINAL, B-CARDINAL, E-CARDINAL, I-CARDINAL, S-MONEY, B-MONEY, E-MONEY, I-MONEY, S-PERCENT, B-PERCENT, E-PERCENT, I-PERCENT, S-ORDINAL, B-ORDINAL, E-ORDINAL, I-ORDINAL #> Groups         : S-NORP, B-NORP, E-NORP, I-NORP #> Facilities     : S-FAC, B-FAC, E-FAC, I-FAC #> Products       : S-PRODUCT, B-PRODUCT, E-PRODUCT, I-PRODUCT #> Events         : S-EVENT, B-EVENT, E-EVENT, I-EVENT #> Art            : S-WORK_OF_ART, B-WORK_OF_ART, E-WORK_OF_ART, I-WORK_OF_ART #> Languages      : S-LANGUAGE, B-LANGUAGE, E-LANGUAGE, I-LANGUAGE #> Laws           : S-LAW, B-LAW, E-LAW, I-LAW #> ---------------------------------------- #> Tag scheme: BIOES #> B-: Beginning of multi-token entity #> I-: Inside of multi-token entity #> O: Outside (not part of any entity) #> E-: End of multi-token entity #> S-: Single token entity #> ======================================== results <- get_entities(texts = uk_immigration$text,                         doc_ids = uk_immigration$speaker,                         tagger = tagger_ner,                         batch_size = 2,                         verbose = FALSE) #> CPU is used. head(results, n = 10) #>               doc_id                          entity    tag     score #>               <char>                          <char> <char>     <num> #>  1: Philip Hollobone                           today   DATE 0.9843611 #>  2: Philip Hollobone                    Conservative   NORP 0.9976857 #>  3: Philip Hollobone Liberal Democrat Front Benchers    ORG 0.7668496 #>  4: Philip Hollobone                       Kettering    GPE 0.9885775 #>  5: Philip Hollobone                            Sikh   NORP 0.9939976 #>  6: Philip Hollobone                       Kettering    GPE 0.9955219 #>  7: Philip Hollobone                       Kettering    GPE 0.9948048 #>  8: Philip Hollobone             some 40 or 50 years   DATE 0.8059650 #>  9: Philip Hollobone                         British   NORP 0.9986911 #> 10: Philip Hollobone                    recent years   DATE 0.8596770"},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"highlight-entities-with-colors","dir":"Articles","previous_headings":"Sequence Taggings","what":"Highlight Entities with Colors","title":"Tutorial","text":"tutorial demonstrates use flaiR package identify highlight named entities (names, locations, organizations) text. Step 1 Create Text Named Entities First, load flaiR package work sample text: Step 2 Highlight Named Entities Use highlight_text function color-code identified entities: Explanation: load_tagger_ner(\"ner\") loads pre-trained NER model get_entities() identifies named entities text map_entities() maps identified entities colors highlight_text() marks original text using colors type entity (person names, locations, organization names) displayed different color, making named entities text immediately visible.  ","code":"library(flaiR) data(\"uk_immigration\") uk_immigration <- uk_immigration[30,] tagger_ner <- load_tagger_ner(\"flair/ner-english-fast\") #> 2025-01-06 02:14:33,595 SequenceTagger predicts: Dictionary with 20 tags: <unk>, O, S-ORG, S-MISC, B-PER, E-PER, S-LOC, B-ORG, E-ORG, I-PER, S-PER, B-MISC, I-MISC, E-MISC, I-ORG, B-LOC, E-LOC, I-LOC, <START>, <STOP> #>  #> NER Tagger Dictionary: #> ======================================== #> Total tags: 20 #> Model: flair/ner-english-fast #> ---------------------------------------- #> Special        : <unk>, O, <START>, <STOP> #> Organization   : S-ORG, B-ORG, E-ORG, I-ORG #> Location       : S-LOC, B-LOC, E-LOC, I-LOC #> Misc           : S-MISC, B-MISC, I-MISC, E-MISC #> ---------------------------------------- #> Tag scheme: BIOES #> B-: Beginning of multi-token entity #> I-: Inside of multi-token entity #> O: Outside (not part of any entity) #> E-: End of multi-token entity #> S-: Single token entity #> ========================================  result <- get_entities(uk_immigration$text,                        tagger = tagger_ner,                        show.text_id = FALSE                        ) #> CPU is used. #> Warning in check_texts_and_ids(texts, doc_ids): doc_ids is NULL. #> Auto-assigning doc_ids. highlighted_text <- highlight_text(text = uk_immigration$text,                                     entities_mapping = map_entities(result)) highlighted_text"},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"the-overview-of-embedding","dir":"Articles","previous_headings":"","what":"The Overview of Embedding","title":"Tutorial","text":"word embedding classes inherit TokenEmbeddings class call embed() method embed text. cases using Flair, various complex embedding processes hidden behind interface. Users simply need instantiate necessary embedding class call embed() embed text. types embeddings currently supported FlairNLP:  ","code":""},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"byte-pair-embeddings","dir":"Articles","previous_headings":"The Overview of Embedding","what":"Byte Pair Embeddings","title":"Tutorial","text":"Please note ihis document R conversion Flair NLP document implemented Python. BytePairEmbeddings word embeddings operate subword level. can embed word breaking subwords looking corresponding embeddings. technique introduced Heinzerling Strube (2018) , demonstrated BytePairEmbeddings achieve comparable accuracy traditional word embeddings requiring fraction model size. makes excellent choice training compact models. initialize BytePairEmbeddings, need specify: language code (275 languages supported) Number syllables Number dimensions (options: 50, 100, 200, 300) information can found byte pair embeddings web page. BytePairEmbeddings also multilingual model capable embedding word language. can instantiate : can also load custom BytePairEmbeddings specifying path model_file_path embedding_file_path arguments. correspond respectively SentencePiece model file embedding file (Word2Vec plain text GenSim binary).","code":"library(flaiR)  # Initialize embedding BytePairEmbeddings <- flair_embeddings()$BytePairEmbeddings  # Create BytePairEmbeddings with specified parameters embedding <- BytePairEmbeddings(     language = \"en\",        # Language code (e.g., \"en\" for English)     dim = 50L,              # Embedding dimensions: options are 50L, 100L, 200L, or 300L     syllables = 100000L     # Subword vocabulary size  )  # Create a sample sentence Sentence <- flair_data()$Sentence sentence = Sentence('The grass is green .')  # Embed words in the sentence embedding$embed(sentence) #> [[1]] #> Sentence[5]: \"The grass is green .\"  # Print embeddings  for (i in 1:length(sentence$tokens)) {     token <- sentence$tokens[[i]]     cat(\"\\nWord:\", token$text, \"\\n\")          # Convert embedding to R vector and print     # Python index starts from 0, so use i-1     embedding_vector <- sentence[i-1]$embedding$numpy()     cat(\"Embedding shape:\", length(embedding_vector), \"\\n\")     cat(\"First 5 values:\", head(embedding_vector, 5), \"\\n\")     cat(\"-------------------\\n\") } #>  #> Word: The  #> Embedding shape: 100  #> First 5 values: -0.585645 0.55233 -0.335385 -0.117119 -0.3433  #> ------------------- #>  #> Word: grass  #> Embedding shape: 100  #> First 5 values: 0.370427 -0.717806 -0.489089 0.384228 0.68443  #> ------------------- #>  #> Word: is  #> Embedding shape: 100  #> First 5 values: -0.186592 0.52804 -1.011618 0.416936 -0.166446  #> ------------------- #>  #> Word: green  #> Embedding shape: 100  #> First 5 values: -0.075467 -0.874228 0.20425 1.061623 -0.246111  #> ------------------- #>  #> Word: .  #> Embedding shape: 100  #> First 5 values: -0.214652 0.212236 -0.607079 0.512853 -0.325556  #> ------------------- embedding <- BytePairEmbeddings('multi')"},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"flair-embeddings","dir":"Articles","previous_headings":"The Overview of Embedding","what":"Flair Embeddings","title":"Tutorial","text":"following example manual translated R Flair NLP Zalando Research. Flair, use embedding quite straightforward. ’s example code snippet use Flair’s contextual string embeddings: Source: https://github.com/flairNLP/flair/blob/master/resources/docs/embeddings/FLAIR_EMBEDDINGS.md#flair-embeddings , want load embeddings German forward LM model, instantiate method follows: want load embeddings Bulgarian backward LM model, instantiate method follows:  ","code":"library(flaiR) FlairEmbeddings <- flair_embeddings()$FlairEmbeddings # init embedding flair_embedding_forward <- FlairEmbeddings('news-forward')  # create a sentence Sentence <- flair_data()$Sentence sentence = Sentence('The grass is green .')  # embed words in sentence flair_embedding_forward$embed(sentence) #> [[1]] #> Sentence[5]: \"The grass is green .\" flair_de_forward <- FlairEmbeddings('de-forward') flair_bg_backward <- FlairEmbeddings('bg-backward')"},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"recommended-flair-usage-in-flair-in-r","dir":"Articles","previous_headings":"The Overview of Embedding","what":"Recommended Flair Usage in flaiR in R","title":"Tutorial","text":"recommend combining forward backward Flair embeddings. Depending task, also recommend adding standard word embeddings mix. , recommended StackedEmbedding English tasks : ’s ! Now just use embedding like embeddings, .e. call embed() method sentences. Words now embedded using concatenation three different embeddings. combination often gives state---art accuracy.  ","code":"FlairEmbeddings <- flair_embeddings()$FlairEmbeddings WordEmbeddings <- flair_embeddings()$WordEmbeddings StackedEmbeddings <- flair_embeddings()$StackedEmbeddings  # create a StackedEmbedding object that combines glove and forward/backward flair embeddings stacked_embeddings <- StackedEmbeddings(list(WordEmbeddings(\"glove\"),                                              FlairEmbeddings(\"news-forward\"),                                              FlairEmbeddings(\"news-backward\"))) # create a sentence Sentence <- flair_data()$Sentence sentence = Sentence('The grass is green .') # just embed a sentence using the StackedEmbedding as you would with any single embedding. stacked_embeddings$embed(sentence) # now check out the embedded tokens. # Note that Python is indexing from 0. In an R for loop, using seq_along(sentence) - 1 achieves the same effect. for (i in  seq_along(sentence)-1) {   print(sentence[i])   print(sentence[i]$embedding) } #> Token[0]: \"The\" #> tensor([-0.0382, -0.2449,  0.7281,  ..., -0.0065, -0.0053,  0.0090]) #> Token[1]: \"grass\" #> tensor([-0.8135,  0.9404, -0.2405,  ...,  0.0354, -0.0255, -0.0143]) #> Token[2]: \"is\" #> tensor([-5.4264e-01,  4.1476e-01,  1.0322e+00,  ..., -5.3691e-04, #>         -9.6750e-03, -2.7541e-02]) #> Token[3]: \"green\" #> tensor([-0.6791,  0.3491, -0.2398,  ..., -0.0007, -0.1333,  0.0161]) #> Token[4]: \".\" #> tensor([-0.3398,  0.2094,  0.4635,  ...,  0.0005, -0.0177,  0.0032])"},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"pooled-flair-embeddings","dir":"Articles","previous_headings":"The Overview of Embedding","what":"Pooled Flair Embeddings","title":"Tutorial","text":"also developed pooled variant FlairEmbeddings. embeddings differ constantly evolve time, even prediction time (.e. training complete). means words sentence two different points time may different embeddings. PooledFlairEmbeddings manage ‘global’ representation distinct word using pooling operation past occurences. details works may found Akbik et al. (2019). can instantiate use PooledFlairEmbeddings like embedding: Note get best results PooledFlairEmbeddings ineffective memory-wise since keep past embeddings words memory. many cases, regular FlairEmbeddings nearly good much lower memory requirements.  ","code":"# initiate embedding from Flair NLP PooledFlairEmbeddings <- flair_embeddings()$PooledFlairEmbeddings flair_embedding_forward <- PooledFlairEmbeddings('news-forward')  # create a sentence object sentence <- Sentence('The grass is green .')  # embed words in sentence flair_embedding_forward$embed(sentence) #> [[1]] #> Sentence[5]: \"The grass is green .\""},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"transformer-embeddings","dir":"Articles","previous_headings":"The Overview of Embedding","what":"Transformer Embeddings","title":"Tutorial","text":"Please note content examples section extensively revised TransformerWordEmbeddings official documentation. Flair supports various Transformer-based architectures like BERT XLNet HuggingFace, two classes TransformerWordEmbeddings (embed words tokens) TransformerDocumentEmbeddings (embed documents).  ","code":""},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"embeddings-words-with-transformers","dir":"Articles","previous_headings":"The Overview of Embedding","what":"Embeddings Words with Transformers","title":"Tutorial","text":"instance, load standard BERT transformer model, : instead want use RoBERTa, : {flaiR} interacts Flair NLP (Zalando Research), allowing use pre-trained models HuggingFace , can search models use.","code":"library(flaiR) # initiate embedding and load BERT model from HugginFaces TransformerWordEmbeddings <- flair_embeddings()$TransformerWordEmbeddings embedding <- TransformerWordEmbeddings('bert-base-uncased')  # create a sentence Sentence <- flair_data()$Sentence sentence = Sentence('The grass is green .')  # embed words in sentence embedding$embed(sentence) #> [[1]] #> Sentence[5]: \"The grass is green .\" TransformerWordEmbeddings <- flair_embeddings()$TransformerWordEmbeddings embedding <- TransformerWordEmbeddings('roberta-base') sentence <- Sentence('The grass is green .') embedding$embed(sentence) #> [[1]] #> Sentence[5]: \"The grass is green .\""},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"embedding-documents-with-transformers","dir":"Articles","previous_headings":"The Overview of Embedding","what":"Embedding Documents with Transformers","title":"Tutorial","text":"embed whole sentence one (instead word sentence), simply use TransformerDocumentEmbeddings instead:","code":"TransformerDocumentEmbeddings <- flair_embeddings()$TransformerDocumentEmbeddings embedding <- TransformerDocumentEmbeddings('roberta-base') sentence <- Sentence('The grass is green .') embedding$embed(sentence) #> [[1]] #> Sentence[5]: \"The grass is green .\""},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"arguments","dir":"Articles","previous_headings":"The Overview of Embedding > Embeddings Words with Transformers","what":"Arguments","title":"Tutorial","text":"several options can set init TransformerWordEmbeddings TransformerDocumentEmbeddings classes:","code":""},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"layers","dir":"Articles","previous_headings":"The Overview of Embedding > Embeddings Words with Transformers","what":"Layers","title":"Tutorial","text":"layers argument controls transformer layers used embedding. set value ‘-1,-2,-3,-4’, top 4 layers used make embedding. set ‘-1’, last layer used. set “”, layers used. affects length embedding, since layers just concatenated. ’s example might done: can directly import torch reticulate since already installed flair dependency installed flair Python. Notice L numbers list? ensures R treats numbers integers. ’re generating numbers dynamically (e.g., computation), might want ensure integers attempting create tensor. .e. size embedding increases mode layers use (layer_mean set False, otherwise length always ).","code":"Sentence <- flair_data()$Sentence TransformerWordEmbeddings <- flair_embeddings()$TransformerWordEmbeddings sentence = Sentence('The grass is green.')  # use only last layers embeddings <- TransformerWordEmbeddings('bert-base-uncased', layers='-1', layer_mean = FALSE) embeddings$embed(sentence) #> [[1]] #> Sentence[5]: \"The grass is green.\" print(sentence[0]$embedding$size()) #> torch.Size([768])  sentence$clear_embeddings() sentence <- Sentence('The grass is green.')  # use only last layers embeddings <- TransformerWordEmbeddings('bert-base-uncased', layers = \"-1\", layer_mean = FALSE) embeddings$embed(sentence) #> [[1]] #> Sentence[5]: \"The grass is green.\" print(sentence[0]$embedding$size()) #> torch.Size([768])  sentence$clear_embeddings() # use last two layers embeddings <- TransformerWordEmbeddings('bert-base-uncased', layers='-1,-2', layer_mean = FALSE) embeddings$embed(sentence) #> [[1]] #> Sentence[5]: \"The grass is green.\" print(sentence[0]$embedding$size()) #> torch.Size([1536])  sentence$clear_embeddings() # use ALL layers embeddings = TransformerWordEmbeddings('bert-base-uncased', layers='all', layer_mean=FALSE) embeddings$embed(sentence) #> [[1]] #> Sentence[5]: \"The grass is green.\" print(sentence[0]$embedding$size()) #> torch.Size([9984]) # You can directly import torch from reticulate since it has already been installed through the flair dependency when you installed flair in Python. torch <- reticulate::import('torch')  # Attempting to create a tensor with integer dimensions torch$Size(list(768L)) #> torch.Size([768]) torch$Size(list(1536L)) #> torch.Size([1536]) torch$Size(list(9984L)) #> torch.Size([9984])"},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"pooling-operation","dir":"Articles","previous_headings":"The Overview of Embedding > Embeddings Words with Transformers","what":"Pooling Operation","title":"Tutorial","text":"Transformer-based models use subword tokenization. E.g. following token puppeteer tokenized subwords: pupp, ##ete ##er. implement different pooling operations subwords generate final token representation: first: embedding first subword used last: embedding last subword used first_last: embeddings first last subwords concatenated used mean: torch.mean subword embeddings calculated used can choose one use passing constructor:","code":"# use first and last subtoken for each word embeddings = TransformerWordEmbeddings('bert-base-uncased', subtoken_pooling='first_last') embeddings$embed(sentence) #> [[1]] #> Sentence[5]: \"The grass is green.\" print(sentence[0]$embedding$size()) #> torch.Size([9984])"},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"layer-mean","dir":"Articles","previous_headings":"The Overview of Embedding > Embeddings Words with Transformers","what":"Layer Mean","title":"Tutorial","text":"Transformer-based models certain number layers. default, layers select concatenated explained . Alternatively, can set layer_mean=True mean selected layers. resulting vector always dimensionality single layer:","code":"# initiate embedding from transformer. This model will be downloaded from Flair NLP huggingface. embeddings <- TransformerWordEmbeddings('bert-base-uncased', layers=\"all\", layer_mean=TRUE)  # create a sentence object sentence = Sentence(\"The Oktoberfest is the world's largest Volksfest .\")  # embed words in sentence embedding$embed(sentence) #> [[1]] #> Sentence[9]: \"The Oktoberfest is the world's largest Volksfest .\""},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"fine-tuneable-or-not","dir":"Articles","previous_headings":"The Overview of Embedding","what":"Fine-tuneable or Not","title":"Tutorial","text":"’s example might done: setups, may wish fine-tune transformer embeddings. case, set fine_tune=True init method. fine-tuning, also use topmost layer, best set layers='-1'. print tensor now gradient function can fine-tuned use training routine. Models Please look awesome HuggingFace supported pre-trained models!  ","code":"# use first and last subtoken for each word TransformerWordEmbeddings <- flair_embeddings()$TransformerWordEmbeddings embeddings <- TransformerWordEmbeddings('bert-base-uncased', fine_tune=TRUE, layers='-1') embeddings$embed(sentence) #> [[1]] #> Sentence[9]: \"The Oktoberfest is the world's largest Volksfest .\" print(sentence[0]$embedding) #> tensor([-6.5871e-01,  1.0410e-01,  3.4632e-01, -3.3775e-01, -2.1013e-01, #>         -1.3036e-02,  5.1998e-01,  1.6574e+00, -5.2519e-02, -4.8634e-02, #>         -7.8968e-01, -9.5546e-01, -1.9723e-01,  9.4999e-01, -1.0336e+00, #>          8.6670e-02,  9.8104e-02,  5.6512e-02,  3.1074e-02,  2.4157e-01, #>         -1.1427e-01, -2.3692e-01, -2.0700e-01,  7.7984e-01,  2.5460e-01, #>         -5.0826e-03, -2.4110e-01,  2.2436e-01, -7.3250e-02, -8.1094e-01, #>         -1.8778e-01,  2.1219e-01, -5.9514e-01,  6.3128e-02, -4.8880e-01, #>         -3.2300e-02, -1.9124e-02, -1.0991e-01, -1.5604e-02,  4.3068e-01, #>         -1.7968e-01, -5.4499e-01,  7.0608e-01, -4.0512e-01,  1.7761e-01, #>         -8.5820e-01,  2.3438e-02, -1.4981e-01, -9.0368e-01, -2.1097e-01, #>         -3.3535e-01,  1.4919e-01, -7.4523e-03,  1.0239e+00, -6.1777e-02, #>          3.3913e-01,  8.5811e-02,  6.9401e-01, -7.7482e-02,  3.1483e-01, #>         -4.3921e-01,  1.2933e+00,  5.8008e-03, -7.0992e-01,  2.7525e-01, #>          8.8792e-01,  2.6305e-03,  1.3640e+00,  5.6886e-01, -2.4904e-01, #>         -4.5158e-02, -1.7575e-01, -3.4730e-01,  5.8363e-02, -2.0346e-01, #>         -1.2505e+00, -3.0592e-01, -3.6104e-02, -2.4066e-01, -5.1250e-01, #>          2.6930e-01,  1.4068e-01,  3.4056e-01,  7.3297e-01,  2.6848e-01, #>          2.4303e-01, -9.4885e-01, -9.0367e-01, -1.3184e-01,  6.7348e-01, #>         -3.2995e-02,  4.7660e-01, -7.1619e-03, -3.4141e-01,  6.8473e-01, #>         -4.4869e-01, -4.9831e-01, -8.0143e-01,  1.4073e+00,  5.3251e-01, #>          2.4643e-01, -4.2528e-01,  9.1615e-02,  6.4495e-01,  1.7931e-01, #>         -2.1473e-01,  1.5447e-01, -3.2978e-01,  1.0799e-01, -1.9402e+00, #>         -5.0380e-01, -2.7636e-01, -1.1228e-01,  1.1576e-01,  2.5885e-01, #>         -1.7916e-01,  6.6166e-01, -9.6098e-01, -5.1242e-01, -3.5424e-01, #>          2.1383e-01,  6.6456e-01,  2.5498e-01,  3.7250e-01, -1.1821e+00, #>         -4.9551e-01, -2.0858e-01,  1.1511e+00, -1.0365e-02, -1.0682e+00, #>          3.7277e-01,  6.4048e-01,  2.3308e-01, -9.3824e-01,  9.5013e-02, #>          5.7904e-01,  6.3969e-01,  8.2360e-02, -1.4075e-01,  3.0107e-01, #>          3.5823e-03, -4.4684e-01, -2.6913e+00, -3.3933e-01,  2.8729e-03, #>         -1.3639e-01, -7.1054e-01, -1.1048e+00,  2.2374e-01,  1.1830e-01, #>          4.8416e-01, -2.9110e-01, -6.7650e-01,  2.3202e-01, -1.0123e-01, #>         -1.9174e-01,  4.9959e-02,  5.2067e-01,  1.3272e+00,  6.8250e-01, #>          5.5332e-01, -1.0886e+00,  4.5160e-01, -1.5010e-01, -9.8074e-01, #>          8.5111e-02,  1.6498e-01,  6.6032e-01,  1.0815e-02,  1.8952e-01, #>         -5.6608e-01, -1.3743e-02,  9.1170e-01,  2.7812e-01,  2.9551e-01, #>         -3.5637e-01,  3.2030e-01,  5.6738e-01, -1.5707e-01,  3.5326e-01, #>         -4.7747e-01,  7.8646e-01,  1.3765e-01,  2.2440e-01,  4.2422e-01, #>         -2.6504e-01,  2.2016e-02, -6.7154e-01, -8.7999e-02,  1.4284e-01, #>          4.0983e-01,  1.0931e-02, -1.0704e+00, -1.9350e-01,  6.0051e-01, #>          5.0544e-02,  1.1433e-02, -8.0243e-01, -6.6871e-01,  5.3953e-01, #>         -5.9856e-01, -1.6915e-01, -3.5307e-01,  4.4568e-01, -7.2761e-01, #>          1.1629e+00, -3.1553e-01, -7.9747e-01, -2.0582e-01,  3.7320e-01, #>          5.9379e-01, -3.1898e-01, -1.6932e-01, -6.2492e-01,  5.7047e-01, #>         -2.9779e-01, -5.9106e-01,  8.5436e-02, -2.1839e-01, -2.2214e-01, #>          7.9233e-01,  8.0536e-01, -5.9784e-01,  4.0474e-01,  3.9265e-01, #>          5.8169e-01, -5.2506e-01,  6.9786e-01,  1.1163e-01,  8.7434e-02, #>          1.7549e-01,  9.1439e-02,  5.8816e-01,  6.4338e-01, -2.7138e-01, #>         -5.3449e-01, -1.0168e+00, -5.1335e-02,  3.0099e-01, -7.6696e-02, #>         -2.1126e-01,  5.8143e-01,  1.3599e-01,  6.2759e-01, -6.2810e-01, #>          5.9966e-01,  3.5836e-01, -3.0706e-02,  1.5563e-01, -1.4016e-01, #>         -2.0155e-01, -1.3755e+00, -9.1877e-02, -6.9892e-01,  7.9439e-02, #>         -4.2926e-01,  3.7988e-01,  7.6741e-01,  5.3094e-01,  8.5981e-01, #>          4.4184e-02, -6.3507e-01,  3.9587e-01, -3.6635e-01, -7.0770e-01, #>          8.3651e-04, -3.0055e-01,  2.1360e-01, -4.1649e-01,  6.9457e-01, #>         -6.2715e-01, -5.1101e-01,  3.0331e-01, -2.3804e+00, -1.0567e-02, #>         -9.4488e-01,  4.3318e-02,  2.4188e-01,  1.9204e-02,  1.5705e-03, #>         -3.0374e-01,  3.1933e-01, -7.4432e-01,  1.4599e-01, -5.2101e-01, #>         -5.2269e-01,  1.3274e-01, -2.8936e-01,  4.1706e-02,  2.6143e-01, #>         -4.4796e-01,  7.3136e-01,  6.3894e-02,  4.7398e-01, -5.1062e-01, #>         -1.3705e-01,  2.0763e-01, -3.9115e-01,  2.8822e-01, -3.5283e-01, #>          3.4881e-02, -3.3602e-01,  1.7210e-01,  1.3537e-02, -5.3036e-01, #>          1.2847e-01, -4.5576e-01, -3.7251e-01, -3.2254e+00, -3.1650e-01, #>         -2.6144e-01, -9.4983e-02,  2.7650e-02, -2.3750e-01,  3.1001e-01, #>          1.1428e-01, -1.2870e-01, -4.7496e-01,  4.4594e-01, -3.6137e-01, #>         -3.1009e-01, -9.9612e-02,  5.3967e-01,  1.2840e-02,  1.4507e-01, #>         -2.5181e-01,  1.9310e-01,  4.1073e-01,  5.9776e-01, -2.5585e-01, #>          5.7184e-02, -5.1505e-01, -6.8709e-02,  4.7767e-01, -1.2078e-01, #>         -5.0894e-01, -9.2884e-01,  7.8471e-01,  2.0216e-01,  4.3242e-01, #>          3.2803e-01, -1.0122e-01,  3.3529e-01, -1.2183e-01, -5.5060e-01, #>          3.5427e-01,  7.4559e-02, -3.1411e-01, -1.7512e-01,  2.2485e-01, #>          4.2295e-01,  7.7110e-02,  1.8063e+00,  7.6644e-03, -1.1082e-02, #>         -2.8605e-02,  7.7144e-02,  8.2345e-02,  8.0270e-02, -1.1858e+00, #>          2.0523e-01,  3.4053e-01,  2.0424e-01, -2.0574e-02,  3.0466e-01, #>         -2.1858e-01,  6.3737e-01, -5.6264e-01,  1.4153e-01,  2.4319e-01, #>         -5.6688e-01,  7.2375e-02, -2.9329e-01,  4.6562e-02,  1.8977e-01, #>          2.4977e-01,  9.1892e-01,  1.1346e-01,  3.8588e-01, -3.5543e-01, #>         -1.3380e+00, -8.5645e-01, -5.5443e-01, -7.2317e-01, -2.9225e-01, #>         -1.4389e-01,  6.9714e-01, -5.9852e-01, -6.8932e-01, -6.0952e-01, #>          1.8234e-01, -7.5840e-02,  3.6445e-01, -3.8286e-01,  2.6545e-01, #>         -2.6569e-01, -4.9999e-01, -3.8354e-01, -2.2809e-01,  8.8314e-01, #>          2.9041e-01,  5.4803e-01, -1.0668e+00,  4.7405e-01,  7.8804e-02, #>         -1.1559e+00, -3.0649e-01,  6.0480e-02, -7.1279e-01, -4.3335e-01, #>         -8.2446e-04, -1.0236e-01,  3.5497e-01,  1.8665e-01,  1.2045e-01, #>          1.2071e-01,  6.2911e-01,  3.1421e-01, -2.1635e-01, -8.9416e-01, #>          6.6360e-01, -9.2980e-01,  6.9193e-01, -2.5403e-01, -2.5836e-02, #>          1.2342e+00, -6.5908e-01,  7.5741e-01,  2.9014e-01,  3.0760e-01, #>         -1.0249e+00, -2.7089e-01,  4.6132e-01,  6.1510e-02,  2.5385e-01, #>         -5.2075e-01, -3.5107e-01,  3.3694e-01, -2.5047e-01, -2.7855e-01, #>          2.0280e-01, -1.5703e-01,  4.1618e-02,  1.4451e-01, -1.6666e-01, #>         -3.0519e-01, -9.4271e-02, -1.7083e-01,  5.2454e-01,  2.4524e-01, #>          2.0731e-01,  3.7948e-01,  9.7359e-02, -3.2451e-02,  5.5792e-01, #>         -2.4703e-01,  5.2864e-01,  5.6343e-01, -1.9198e-01, -8.3369e-02, #>         -6.5377e-01, -5.4104e-01,  1.8289e-01, -4.9146e-01,  6.6423e-01, #>         -5.2809e-01, -1.4797e-01, -4.5526e-02, -3.9593e-01,  1.2841e-01, #>         -7.8591e-01, -3.7564e-02,  6.1912e-01,  3.2458e-01,  3.7858e-01, #>          1.8744e-01, -5.0738e-01,  8.0222e-02, -3.1468e-02, -1.5145e-01, #>          1.6657e-01, -5.2251e-01, -2.5940e-01, -3.8505e-01, -7.4942e-02, #>          3.9530e-01, -2.1742e-01, -1.7113e-01, -5.2492e-01, -7.7781e-02, #>         -6.9759e-01,  2.2570e-01, -1.2935e-01,  3.0750e-01, -1.3554e-01, #>          6.0182e-02, -1.1479e-01,  4.7263e-01,  3.7957e-01,  8.9523e-01, #>         -3.6411e-01, -6.6355e-01, -7.6647e-01, -1.4479e+00, -5.2238e-01, #>          2.3336e-02, -4.5736e-01,  5.9981e-01,  6.8700e-01,  4.2190e-02, #>          1.5894e-01,  2.0743e-02,  9.2333e-02, -7.2747e-01,  1.2388e-01, #>         -4.7257e-01, -2.9889e-01,  4.8955e-01, -9.1618e-01, -1.9497e-01, #>         -1.4157e-01, -1.7472e-01,  4.9250e-02, -2.2264e-01,  6.1700e-01, #>         -2.4691e-01,  6.0937e-01,  3.6134e-01,  4.3398e-01, -2.7615e-01, #>         -2.6582e-01, -1.3132e-01, -4.4155e-02,  5.3686e-01,  1.2956e-01, #>         -6.4218e-01, -1.5820e-01, -1.0249e+00, -9.3587e-03, -3.5060e-01, #>          3.6650e-01,  4.9503e-01,  7.4325e-01,  9.6525e-02,  4.3141e-01, #>          3.9512e-02, -7.0727e-02,  6.2696e-01,  1.3066e-01,  1.0243e-01, #>          3.3839e-01,  1.9224e-01,  4.8800e-01, -2.1052e-01,  3.9523e-02, #>          7.7567e-01, -1.2005e-01, -1.1262e-01,  8.7001e-02,  2.7273e-01, #>         -4.6830e-02, -2.4966e-01, -3.2083e-01, -2.6389e-01,  1.6225e-01, #>          2.8800e-01, -1.0799e-01, -1.0841e-01,  6.6873e-01,  3.4369e-01, #>          5.8675e-01,  9.2084e-01, -1.8131e-01,  5.6373e-02, -5.7125e-01, #>          3.1048e-01,  3.1629e-02,  1.2097e+00,  4.4492e-01, -2.3792e-01, #>         -9.9342e-02, -5.0657e-01, -3.1333e-02,  1.5045e-01,  3.1493e-01, #>         -4.1287e-01, -1.8618e-01, -4.2638e-02,  1.8266e+00,  4.8565e-01, #>          6.3892e-01, -2.9107e-01, -3.2557e-01,  1.1089e-01, -1.3212e+00, #>          7.1113e-01,  2.3618e-01,  2.1473e-01,  1.6360e-01, -5.2535e-01, #>          3.4322e-01,  9.0777e-01,  1.8697e-01, -3.0532e-01,  2.7574e-01, #>          5.1451e-01, -2.6733e-01,  2.4208e-01, -3.3234e-01,  6.3520e-01, #>          2.5884e-01, -5.7923e-01,  3.0204e-01,  4.1746e-02,  4.7539e-02, #>         -6.7038e-01,  4.6699e-01, -1.6951e-01, -1.5161e-01, -1.2805e-01, #>         -4.3990e-01,  1.0177e+00, -3.8138e-01,  4.3114e-01, -7.5435e-03, #>          2.7385e-01,  4.6314e-01, -8.6565e-02, -7.9458e-01,  1.4370e-02, #>          2.6016e-01,  9.2556e-03,  9.3968e-01,  7.9679e-01,  3.3140e-03, #>         -5.6733e-01,  2.9052e-01, -9.5894e-02,  1.8630e-01,  1.4475e-01, #>          1.8935e-01,  5.1735e-01, -1.2187e+00, -1.3298e-01, -4.3538e-01, #>         -6.5398e-01, -2.9286e-01,  1.3199e-01,  3.9075e-01,  9.0172e-01, #>          9.9439e-01,  6.2783e-01, -1.6103e-01,  1.4158e-03, -9.1476e-01, #>          7.7760e-01,  1.2264e+00,  8.1482e-02,  6.6732e-01, -7.4576e-01, #>         -1.0470e-01, -6.7781e-01,  8.0405e-01,  3.6676e-02,  3.6362e-01, #>          4.4962e-01,  8.9600e-01, -1.8276e+00,  6.7828e-01, -9.4125e-03, #>          3.8665e-01, -2.2149e-02,  7.4756e-02,  3.7438e-01, -1.2696e-01, #>         -5.3396e-01, -3.5782e-01,  3.0400e-01,  7.7663e-01, -1.9122e-01, #>         -1.3041e-01, -2.1522e-01,  1.1086e+00,  1.0237e+00, -4.7552e-02, #>         -3.9538e-01,  1.1568e+00, -4.2549e-01, -2.5640e-02,  2.1993e-01, #>         -4.7488e-01, -7.7624e-02, -5.5211e-01, -5.3169e-01, -5.3790e-02, #>         -6.0535e-01,  4.2789e-01, -3.8606e-01,  9.8630e-01,  4.3330e-01, #>          4.8414e-01, -1.3518e-01, -6.5505e-01, -2.2913e-01, -3.1254e-01, #>          1.2920e-01, -7.7763e-02, -3.1123e-01,  8.2576e-01,  8.6486e-01, #>         -3.4766e-01, -3.8491e-01,  3.5732e-02,  3.7518e-01, -3.7511e-01, #>          5.2371e-01, -7.9721e-01,  3.3401e-01,  8.3976e-01, -3.2525e-01, #>         -3.0268e-01, -1.3558e-01,  2.2812e-01,  1.5632e-01,  3.1584e-01, #>          9.3902e-02, -3.8647e-01, -1.0177e-01, -2.8833e-01,  3.6028e-01, #>          2.2565e-01, -1.5595e-01, -4.4974e-01, -5.0904e-01,  4.5058e-01, #>          7.9030e-01,  2.7041e-01, -3.6712e-01, -3.9090e-01,  2.3358e-01, #>          1.2162e+00, -1.1371e+00, -8.2702e-01, -9.2747e-02,  5.8958e-01, #>          4.4429e-02, -2.3344e-01, -5.6492e-01,  4.9406e-01, -4.0302e-01, #>          5.0951e-01, -1.6740e-01, -4.0176e+00, -8.2092e-01, -3.9132e-01, #>         -2.9754e-01, -2.6797e-01, -2.5174e-01,  6.6282e-01, -5.7532e-02, #>          7.7360e-01,  2.5238e-01,  2.5732e-02,  1.7694e-01,  9.4647e-02, #>          2.6885e-01,  9.3711e-01, -8.3929e-02])"},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"classic-word-embeddings","dir":"Articles","previous_headings":"The Overview of Embedding > Fine-tuneable or Not","what":"Classic Word Embeddings","title":"Tutorial","text":"Classic word embeddings static word-level, meaning distinct word gets exactly one pre-computed embedding. embeddings fall class, including popular GloVe Komninos embeddings. Simply instantiate WordEmbeddings class pass string identifier embedding wish load. , want use GloVe embeddings, pass string ‘glove’ constructor: Now, create example sentence call embedding’s embed() method. can also pass list sentences method since embedding types make use batching increase speed. prints tokens embeddings. GloVe embeddings Pytorch vectors dimensionality 100. choose pre-trained embeddings load passing appropriate id string constructor WordEmbeddings class. Typically, use two-letter language code init embedding, ‘en’ English ‘de’ German . default, initialize FastText embeddings trained Wikipedia. can also always use FastText embeddings Web crawls, instantiating ‘-crawl’. ‘de-crawl’ use embeddings trained German web crawls. English, provide options, can choose instantiating ‘en-glove’, ‘en-extvec’ .  ","code":"library(flaiR) # initiate embedding with glove WordEmbeddings <- flair_embeddings()$WordEmbeddings glove_embedding <-  WordEmbeddings('glove') library(flaiR) # initiate a sentence object Sentence <- flair_data()$Sentence  # create sentence object. sentence = Sentence('The grass is green .')  # embed a sentence using glove. glove_embedding$embed(sentence) #> [[1]] #> Sentence[5]: \"The grass is green .\" # view embedded tokens. for (token in seq_along(sentence)-1) {   print(sentence[token])   print(sentence[token]$embedding$numpy()) } #> Token[0]: \"The\" #>   [1] -0.038194 -0.244870  0.728120 -0.399610  0.083172  0.043953 #>   [7] -0.391410  0.334400 -0.575450  0.087459  0.287870 -0.067310 #>  [13]  0.309060 -0.263840 -0.132310 -0.207570  0.333950 -0.338480 #>  [19] -0.317430 -0.483360  0.146400 -0.373040  0.345770  0.052041 #>  [25]  0.449460 -0.469710  0.026280 -0.541550 -0.155180 -0.141070 #>  [31] -0.039722  0.282770  0.143930  0.234640 -0.310210  0.086173 #>  [37]  0.203970  0.526240  0.171640 -0.082378 -0.717870 -0.415310 #>  [43]  0.203350 -0.127630  0.413670  0.551870  0.579080 -0.334770 #>  [49] -0.365590 -0.548570 -0.062892  0.265840  0.302050  0.997750 #>  [55] -0.804810 -3.024300  0.012540 -0.369420  2.216700  0.722010 #>  [61] -0.249780  0.921360  0.034514  0.467450  1.107900 -0.193580 #>  [67] -0.074575  0.233530 -0.052062 -0.220440  0.057162 -0.158060 #>  [73] -0.307980 -0.416250  0.379720  0.150060 -0.532120 -0.205500 #>  [79] -1.252600  0.071624  0.705650  0.497440 -0.420630  0.261480 #>  [85] -1.538000 -0.302230 -0.073438 -0.283120  0.371040 -0.252170 #>  [91]  0.016215 -0.017099 -0.389840  0.874240 -0.725690 -0.510580 #>  [97] -0.520280 -0.145900  0.827800  0.270620 #> Token[1]: \"grass\" #>   [1] -0.8135300  0.9404200 -0.2404800 -0.1350100  0.0556780  0.3362500 #>   [7]  0.0802090 -0.1014800 -0.5477600 -0.3536500  0.0733820  0.2586800 #>  [13]  0.1986600 -0.1432800  0.2507000  0.4281400  0.1949800  0.5345600 #>  [19]  0.7424100  0.0578160 -0.3178100  0.9435900  0.8145000 -0.0823750 #>  [25]  0.6165800  0.7284400 -0.3262300 -1.3641000  0.1232000  0.5372800 #>  [31] -0.5122800  0.0245900  1.0822001 -0.2295900  0.6038500  0.5541500 #>  [37] -0.9609900  0.4803300  0.0022260  0.5591300 -0.1636500 -0.8468100 #>  [43]  0.0740790 -0.6215700  0.0259670 -0.5162100 -0.0524620 -0.1417700 #>  [49] -0.0161230 -0.4971900 -0.5534500 -0.4037100  0.5095600  1.0276000 #>  [55] -0.0840000 -1.1179000  0.3225700  0.4928100  0.9487600  0.2040300 #>  [61]  0.5388300  0.8397200 -0.0688830  0.3136100  1.0450000 -0.2266900 #>  [67] -0.0896010 -0.6427100  0.6442900 -1.1001000 -0.0095814  0.2668200 #>  [73] -0.3230200 -0.6065200  0.0479150 -0.1663700  0.8571200  0.2335500 #>  [79]  0.2539500  1.2546000  0.5471600 -0.1979600 -0.7186300  0.2076000 #>  [85] -0.2587500 -0.3649900  0.0834360  0.6931700  0.1573700  1.0931000 #>  [91]  0.0912950 -1.3773000 -0.2717000  0.7070800  0.1872000 -0.3307200 #>  [97] -0.2835900  0.1029600  1.2228000  0.8374100 #> Token[2]: \"is\" #>   [1] -0.5426400  0.4147600  1.0322000 -0.4024400  0.4669100  0.2181600 #>   [7] -0.0748640  0.4733200  0.0809960 -0.2207900 -0.1280800 -0.1144000 #>  [13]  0.5089100  0.1156800  0.0282110 -0.3628000  0.4382300  0.0475110 #>  [19]  0.2028200  0.4985700 -0.1006800  0.1326900  0.1697200  0.1165300 #>  [25]  0.3135500  0.2571300  0.0927830 -0.5682600 -0.5297500 -0.0514560 #>  [31] -0.6732600  0.9253300  0.2693000  0.2273400  0.6636500  0.2622100 #>  [37]  0.1971900  0.2609000  0.1877400 -0.3454000 -0.4263500  0.1397500 #>  [43]  0.5633800 -0.5690700  0.1239800 -0.1289400  0.7248400 -0.2610500 #>  [49] -0.2631400 -0.4360500  0.0789080 -0.8414600  0.5159500  1.3997000 #>  [55] -0.7646000 -3.1452999 -0.2920200 -0.3124700  1.5129000  0.5243500 #>  [61]  0.2145600  0.4245200 -0.0884110 -0.1780500  1.1876000  0.1057900 #>  [67]  0.7657100  0.2191400  0.3582400 -0.1163600  0.0932610 -0.6248300 #>  [73] -0.2189800  0.2179600  0.7405600 -0.4373500  0.1434300  0.1471900 #>  [79] -1.1605000 -0.0505080  0.1267700 -0.0143950 -0.9867600 -0.0912970 #>  [85] -1.2054000 -0.1197400  0.0478470 -0.5400100  0.5245700 -0.7096300 #>  [91] -0.3252800 -0.1346000 -0.4131400  0.3343500 -0.0072412  0.3225300 #>  [97] -0.0442190 -1.2969000  0.7621700  0.4634900 #> Token[3]: \"green\" #>   [1] -0.67907000  0.34908000 -0.23984000 -0.99651998  0.73782003 #>   [6] -0.00065911  0.28009999  0.01728700 -0.36063001  0.03695500 #>  [11] -0.40395001  0.02409200  0.28957999  0.40496999  0.69992000 #>  [16]  0.25268999  0.80350000  0.04937000  0.15561999 -0.00632860 #>  [21] -0.29414001  0.14727999  0.18977000 -0.51791000  0.36985999 #>  [26]  0.74581999  0.08268900 -0.72601002 -0.40939000 -0.09782200 #>  [31] -0.14095999  0.71121001  0.61932999 -0.25014001  0.42250001 #>  [36]  0.48458001 -0.51915002  0.77125001  0.36684999  0.49652001 #>  [41] -0.04129800 -1.46829998  0.20038000  0.18591000  0.04986000 #>  [46] -0.17523000 -0.35528001  0.94152999 -0.11898000 -0.51902997 #>  [51] -0.01188700 -0.39186001 -0.17478999  0.93450999 -0.58930999 #>  [56] -2.77010012  0.34522000  0.86532998  1.08080006 -0.10291000 #>  [61] -0.09122000  0.55092001 -0.39473000  0.53675997  1.03830004 #>  [66] -0.40658000  0.24590001 -0.26797000 -0.26036000 -0.14150999 #>  [71] -0.12022000  0.16234000 -0.74320000 -0.64727998  0.04713300 #>  [76]  0.51642001  0.19898000  0.23919000  0.12549999  0.22471000 #>  [81]  0.82612997  0.07832800 -0.57020003  0.02393400 -0.15410000 #>  [86] -0.25738999  0.41262001 -0.46967000  0.87914002  0.72628999 #>  [91]  0.05386200 -1.15750003 -0.47835001  0.20139000 -1.00510001 #>  [96]  0.11515000 -0.96609002  0.12960000  0.18388000 -0.03038300 #> Token[4]: \".\" #>   [1] -0.3397900  0.2094100  0.4634800 -0.6479200 -0.3837700  0.0380340 #>   [7]  0.1712700  0.1597800  0.4661900 -0.0191690  0.4147900 -0.3434900 #>  [13]  0.2687200  0.0446400  0.4213100 -0.4103200  0.1545900  0.0222390 #>  [19] -0.6465300  0.2525600  0.0431360 -0.1944500  0.4651600  0.4565100 #>  [25]  0.6858800  0.0912950  0.2187500 -0.7035100  0.1678500 -0.3507900 #>  [31] -0.1263400  0.6638400 -0.2582000  0.0365420 -0.1360500  0.4025300 #>  [37]  0.1428900  0.3813200 -0.1228300 -0.4588600 -0.2528200 -0.3043200 #>  [43] -0.1121500 -0.2618200 -0.2248200 -0.4455400  0.2991000 -0.8561200 #>  [49] -0.1450300 -0.4908600  0.0082973 -0.1749100  0.2752400  1.4401000 #>  [55] -0.2123900 -2.8434999 -0.2795800 -0.4572200  1.6386000  0.7880800 #>  [61] -0.5526200  0.6500000  0.0864260  0.3901200  1.0632000 -0.3537900 #>  [67]  0.4832800  0.3460000  0.8417400  0.0987070 -0.2421300 -0.2705300 #>  [73]  0.0452870 -0.4014700  0.1139500  0.0062226  0.0366730  0.0185180 #>  [79] -1.0213000 -0.2080600  0.6407200 -0.0687630 -0.5863500  0.3347600 #>  [85] -1.1432000 -0.1148000 -0.2509100 -0.4590700 -0.0968190 -0.1794600 #>  [91] -0.0633510 -0.6741200 -0.0688950  0.5360400 -0.8777300  0.3180200 #>  [97] -0.3924200 -0.2339400  0.4729800 -0.0288030"},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"suppored-models","dir":"Articles","previous_headings":"The Overview of Embedding > Fine-tuneable or Not","what":"Suppored Models:","title":"Tutorial","text":"following embeddings currently supported: , want load German FastText embeddings, instantiate follows: Alternatively, want load German FastText embeddings trained crawls, instantiate follows:","code":""},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"embedding-examples","dir":"Articles","previous_headings":"","what":"Embedding Examples","title":"Tutorial","text":"Flair popular natural language processing library, providing variety embedding methods text representation. Flair Embeddings word embedding framework developed Zalando. focuses word-level representation can capture contextual information words, allowing word different embeddings different contexts. Unlike traditional word embeddings (Word2Vec GloVe), Flair can dynamically generate word embeddings based context achieved excellent results various NLP tasks. key points Flair Embeddings: Context-Aware Flair dynamic word embedding technique can understand meaning words based context. contrast, static word embeddings, Word2Vec GloVe, provide fixed embedding word without considering context sentence. Therefore, context-sensitive embedding techniques, Flair, can capture meaning words specific sentences accurately, thus enhancing performance language models various tasks. Example: Consider following two English sentences: “interested bank river.” “need go bank withdraw money.” , word “bank” two different meanings. first sentence, refers edge shore river. second sentence, refers financial institution. static embeddings, word “bank” might embedding lies somewhere two meanings doesn’t consider context. dynamic embeddings like Flair, “bank” first sentence embedding related rivers, second sentence, embedding related finance. word, similar vector representation, essentially different. way, can see dynamic embeddings “bank” two sentences differ based context. Although printed embeddings , reality, high-dimensional vectors, might see lot numbers. want intuitive view differences, compute cosine similarity metrics two embeddings. just simple demonstration. practice, can also combine multiple embedding techniques, WordEmbeddings FlairEmbeddings, get richer word vectors. Character-Based Flair uses character-level language model, meaning can generate embeddings rare words even misspelled words. important feature allows model understand process words never appeared training data. Flair uses bidirectional LSTM (Long Short-Term Memory) network operates character level. allows feed individual characters LSTM instead words. Multilingual Support Flair provides various pre-trained character-level language models, supporting contextual word embeddings multiple languages. allows easily combine different word embeddings (e.g., Flair Embeddings, Word2Vec, GloVe, etc.) create powerful stacked embeddings.","code":"# Initialize Flair embeddings FlairEmbeddings <- flair_embeddings()$FlairEmbeddings Sentence <- flair_data()$Sentence flair_embedding_forward <- FlairEmbeddings('news-forward')  # Define the two sentences sentence1 <-  Sentence(\"I am interested in the bank of the river.\") sentence2 <-  Sentence(\"I need to go to the bank to withdraw money.\")  # Get the embeddings  flair_embedding_forward$embed(sentence1) #> [[1]] #> Sentence[10]: \"I am interested in the bank of the river.\" flair_embedding_forward$embed(sentence2) #> [[1]] #> Sentence[11]: \"I need to go to the bank to withdraw money.\"  # Extract the embedding for \"bank\" from the sentences bank_embedding_sentence1 = sentence1[5]$embedding  # \"bank\" is the seventh word bank_embedding_sentence2 = sentence2[6]$embedding  # \"bank\" is the sixth word library(lsa) #> Loading required package: SnowballC cosine(as.numeric( bank_embedding_sentence1$numpy()),         as.numeric( bank_embedding_sentence2$numpy())) #>           [,1] #> [1,] 0.7329551"},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"classic-wordembeddings","dir":"Articles","previous_headings":"Embedding Examples","what":"Classic Wordembeddings","title":"Tutorial","text":"Flair, simplest form embeddings still contains semantic information word called classic word embeddings. embeddings pre-trained non-contextual. Let’s retrieve word embeddings use FastText embeddings following code. , simply instantiate WordEmbeddings class passing ID embedding choice. , simply wrap text Sentence object, call embed(sentence) method WordEmbeddings class. Flair supports range classic word embeddings, offering unique features application scopes. overview, detailing ID required load embedding corresponding language.","code":"WordEmbeddings <- flair_embeddings()$WordEmbeddings Sentence <- flair_data()$Sentence embedding <- WordEmbeddings('crawl') sentence <- Sentence(\"one two three one\")  embedding$embed(sentence)  #> [[1]] #> Sentence[4]: \"one two three one\"  for (i in seq_along(sentence$tokens)) {   print(head(sentence$tokens[[i]]$embedding), n =5) } #> tensor([-0.0535, -0.0368, -0.2851, -0.0381, -0.0486,  0.2383]) #> tensor([ 0.0282, -0.0786, -0.1236,  0.1756, -0.1199,  0.0964]) #> tensor([-0.0920, -0.0690, -0.1475,  0.2313, -0.0872,  0.0799]) #> tensor([-0.0535, -0.0368, -0.2851, -0.0381, -0.0486,  0.2383])"},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"contexual-embeddings","dir":"Articles","previous_headings":"Embedding Examples","what":"Contexual Embeddings","title":"Tutorial","text":"idea behind contextual string embeddings word embedding defined syntactic-semantic meaning also context appears . means word different embedding every context appears . pre-trained Flair model offers forward version backward version. Let’s assume processing language , just like text, uses left--right script. forward version takes account context happens word – left-hand side. backward version works opposite direction. takes account context word – right-hand side word. true, two words appear beginning two different sentences identical forward embeddings, context null. Let’s test : using forward model, takes account context occurs word. Additionally, since word context left-hand side position sentence, two embeddings identical, code assumes identical, indeed output True. test whether sum two 2048 embeddings nice equal 2048. true, indicates embedding results consistent, theoretically case. Now separately add words, pretty, two sentence objects. two sets embeddings identical words different, returns FALSE. measure similarity two vectors inner product space known cosine similarity. formula calculating cosine similarity two vectors, vectors B, follows: CosineSimilarity=∑(Ai⋅Bi)∑(Ai2)⋅∑(Bi2)Cosine Similarity = \\frac{\\sum_{} (A_i \\cdot B_i)}{\\sqrt{\\sum_{} (A_i^2)} \\cdot \\sqrt{\\sum_{} (B_i^2)}} can observe similarity two words 0.55.","code":"FlairEmbeddings <- flair_embeddings()$FlairEmbeddings embedding <- FlairEmbeddings('news-forward') s1 <- Sentence(\"nice shirt\")  s2 <- Sentence(\"nice pants\")   embedding$embed(s1)  #> [[1]] #> Sentence[2]: \"nice shirt\" embedding$embed(s2)  #> [[1]] #> Sentence[2]: \"nice pants\" cat(\" s1 sentence:\", paste(s1[0], sep = \"\"), \"\\n\", \"s2 sentence:\", paste(s2[0], sep = \"\")) #>  s1 sentence: Token[0]: \"nice\"  #>  s2 sentence: Token[0]: \"nice\" length(s1[0]$embedding$numpy()) == sum(s1[0]$embedding$numpy() ==  s2[0]$embedding$numpy()) #> [1] TRUE s1 <- Sentence(\"very nice shirt\")  s2 <- Sentence(\"pretty nice pants\")   embedding$embed(s1)  #> [[1]] #> Sentence[3]: \"very nice shirt\" embedding$embed(s2)  #> [[1]] #> Sentence[3]: \"pretty nice pants\" length(s1[0]$embedding$numpy()) == sum(s1[0]$embedding$numpy() ==  s2[0]$embedding$numpy()) #> [1] FALSE library(lsa) vector1 <- as.numeric(s1[0]$embedding$numpy()) vector2 <- as.numeric(s2[0]$embedding$numpy()) cosine_similarity <- cosine(vector1, vector2) print(cosine_similarity) #>           [,1] #> [1,] 0.5571664"},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"extracting-embeddings-from-bert","dir":"Articles","previous_headings":"Embedding Examples","what":"Extracting Embeddings from BERT","title":"Tutorial","text":"First, utilize TransformerWordEmbeddings function download BERT, transformer models can also found Flair NLP’s Hugging Face. Next, traverse token sentence print .","code":"library(flaiR) TransformerWordEmbeddings <- flair_embeddings()$TransformerWordEmbeddings(\"bert-base-uncased\") embedding <- TransformerWordEmbeddings$embed(sentence) # Iterate through each token in the sentence, printing them.  # Utilize reticulate::py_str(token) to view each token, given that the sentence is a Python object. for (i in seq_along(sentence$tokens)) {   cat(\"Token: \", reticulate::py_str(sentence$tokens[[i]]), \"\\n\")   # Access the embedding of the token, converting it to an R object,    # and print the first 10 elements of the vector.   token_embedding <- sentence$tokens[[i]]$embedding   print(head(token_embedding, 10)) } #> Token:  Token[0]: \"one\"  #> tensor([-0.0535, -0.0368, -0.2851, -0.0381, -0.0486,  0.2383, -0.1200,  0.2620, #>         -0.0575,  0.0228]) #> Token:  Token[1]: \"two\"  #> tensor([ 0.0282, -0.0786, -0.1236,  0.1756, -0.1199,  0.0964, -0.1327,  0.4449, #>         -0.0264, -0.1168]) #> Token:  Token[2]: \"three\"  #> tensor([-0.0920, -0.0690, -0.1475,  0.2313, -0.0872,  0.0799, -0.0901,  0.4403, #>         -0.0103, -0.1494]) #> Token:  Token[3]: \"one\"  #> tensor([-0.0535, -0.0368, -0.2851, -0.0381, -0.0486,  0.2383, -0.1200,  0.2620, #>         -0.0575,  0.0228])"},{"path":[]},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"word-embeddings-glove","dir":"Articles","previous_headings":"Embedding Examples > Visialized Embeddings","what":"Word Embeddings (GloVe)","title":"Tutorial","text":"GloVe embeddings Pytorch vectors dimensionality 100. English, Flair provides options. , can use en-glove en-extvec WordEmbeddings class.","code":"# Initialize Text Processing Tools --------------------------- # Import Sentence class for text operations Sentence <- flair_data()$Sentence  # Configure GloVe Embeddings -------------------------------- # Load WordEmbeddings class and initialize GloVe model WordEmbeddings <- flair_embeddings()$WordEmbeddings embedding <- WordEmbeddings(\"glove\")   # Text Processing and Embedding ----------------------------- # Create sentence with semantic relationship pairs sentence <- Sentence(\"King Queen man woman Paris London apple orange Taiwan Dublin Bamberg\")   # Apply GloVe embeddings to the sentence embedding$embed(sentence) #> [[1]] #> Sentence[11]: \"King Queen man woman Paris London apple orange Taiwan Dublin Bamberg\"  # Extract embeddings into matrix format sen_df <- process_embeddings(sentence,                            verbose = TRUE) #> Extracting token embeddings... #> Converting embeddings to matrix format...Processing completed in 0.004 seconds #> Generated embedding matrix with 11 tokens and 100 dimensions  # Dimensionality Reduction --------------------------------- # Set random seed for reproducibility set.seed(123)  # Apply PCA to reduce dimensions to 3 components pca_result <- prcomp(sen_df, center = TRUE, scale. = TRUE)  # Extract first three principal components word_embeddings_matrix <- as.data.frame(pca_result$x[,1:3]) word_embeddings_matrix #>                PC1       PC2         PC3 #> King    -2.9120910  1.285200 -1.95053854 #> Queen   -2.2413804  2.266714 -1.09020972 #> man     -5.6381902  2.984461  3.55462010 #> woman   -6.4891003  2.458607  3.56693660 #> Paris    3.0702212  5.039061 -2.65962020 #> London   5.3196216  4.368433 -2.60726627 #> apple    0.3362535 -8.679358 -0.44752722 #> orange  -0.0485467 -4.404101  0.77151480 #> Taiwan  -2.7993829 -4.149287 -6.33296039 #> Dublin   5.8994096  1.063291 -0.09271925 #> Bamberg  5.5031854 -2.233020  7.28777009"},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"d-plot","dir":"Articles","previous_headings":"Embedding Examples > Visialized Embeddings > Word Embeddings (GloVe)","what":"2D Plot","title":"Tutorial","text":"","code":"library(ggplot2) #> Error in get(paste0(generic, \".\", class), envir = get_method_env()) :  #>   object 'type_sum.accel' not found glove_plot2D <- ggplot(word_embeddings_matrix, aes(x = PC1, y = PC2, color = PC3,                                               label = rownames(word_embeddings_matrix))) +   geom_point(size = 3) +    geom_text(vjust = 1.5, hjust = 0.5) +     scale_color_gradient(low = \"blue\", high = \"red\") +    theme_minimal() +     labs(title = \"\", x = \"PC1\", y = \"PC2\", color = \"PC3\")    # guides(color = \"none\")   glove_plot2D"},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"d-plot-1","dir":"Articles","previous_headings":"Embedding Examples > Visialized Embeddings > Word Embeddings (GloVe)","what":"3D Plot","title":"Tutorial","text":"plotly R API: https://plotly.com/r/","code":"library(plotly) glove_plot3D <- plot_ly(data = word_embeddings_matrix,                    x = ~PC1, y = ~PC2, z = ~PC3,                    type = \"scatter3d\", mode = \"markers\",                   marker = list(size = 5),                    text = rownames(word_embeddings_matrix), hoverinfo = 'text')  glove_plot3D"},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"stack-embeddings-method-glove-backforwad-flairembeddings-or-more","dir":"Articles","previous_headings":"Embedding Examples > Visialized Embeddings","what":"Stack Embeddings Method (GloVe + Back/forwad FlairEmbeddings or More)","title":"Tutorial","text":"","code":"# Initialize Embeddings ----------------------------- # Load embedding types from flaiR WordEmbeddings <- flair_embeddings()$WordEmbeddings FlairEmbeddings <- flair_embeddings()$FlairEmbeddings StackedEmbeddings <- flair_embeddings()$StackedEmbeddings  # Configure Embeddings ---------------------------- # Initialize GloVe word embeddings glove_embedding <- WordEmbeddings('glove')  # Initialize Flair contextual embeddings flair_embedding_forward <- FlairEmbeddings('news-forward') flair_embedding_backward <- FlairEmbeddings('news-backward')  # Initialize GloVe for individual use embedding <- WordEmbeddings(\"glove\")   # Create stacked embeddings combining GloVe and bidirectional Flair stacked_embeddings <- StackedEmbeddings(c(glove_embedding,                                          flair_embedding_forward,                                          flair_embedding_backward))  # Text Processing -------------------------------- # Load Sentence class from flaiR Sentence <- flair_data()$Sentence  # Create test sentence with semantic relationships sentence <- Sentence(\"King Queen man woman Paris London apple orange Taiwan Dublin Bamberg\")   # Apply embeddings and extract features ---------- # Embed text using stacked embeddings stacked_embeddings$embed(sentence)  # Extract embeddings matrix with processing details sen_df <- process_embeddings(sentence,                             verbose = TRUE) #> Extracting token embeddings... #> Converting embeddings to matrix format...Processing completed in 0.005 seconds #> Generated embedding matrix with 11 tokens and 4196 dimensions  # Dimensionality Reduction ----------------------- set.seed(123)  # Perform PCA for visualization pca_result <- prcomp(sen_df, center = TRUE, scale. = TRUE)  # Extract first three principal components word_embeddings_matrix <- as.data.frame(pca_result$x[,1:3]) word_embeddings_matrix #>                PC1         PC2         PC3 #> King     -8.607474  67.2291112  32.4862807 #> Queen     1.757707  12.0477210 -26.8302480 #> man      70.603191  -6.6184707  13.1651688 #> woman    22.532043  -8.1126267  -0.9073998 #> Paris   -11.395619  -0.3051693 -17.5197067 #> London   -8.709174  -2.7450626 -14.1780531 #> apple    -8.739477 -15.7725211  -6.3796349 #> orange  -25.178329 -38.8501308  51.4907636 #> Taiwan   -9.132397  -5.0252091 -11.0918877 #> Dublin  -10.925014  -3.3407329 -10.1367729 #> Bamberg -12.205457   1.4930909 -10.0985100 # 2D Plot library(ggplot2)  stacked_plot2D <- ggplot(word_embeddings_matrix, aes(x = PC1, y = PC2, color = PC3,                                               label = rownames(word_embeddings_matrix))) +   geom_point(size = 2) +    geom_text(vjust = 1.5, hjust = 0.5) +     scale_color_gradient(low = \"blue\", high = \"red\") +    theme_minimal() +     labs(title = \"\", x = \"PC1\", y = \"PC2\", color = \"PC3\")   stacked_plot2D"},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"transformer-embeddings-bert-or-more","dir":"Articles","previous_headings":"Embedding Examples > Visialized Embeddings","what":"Transformer Embeddings (BERT or More)","title":"Tutorial","text":"","code":"# Load Required Package ---------------------------- library(flaiR)  # Initialize BERT and Text Processing -------------- # Import Sentence class for text operations Sentence <- flair_data()$Sentence  # Initialize BERT model (base uncased version) TransformerWordEmbeddings <- flair_embeddings()$TransformerWordEmbeddings(\"bert-base-uncased\")  # Text Processing and Embedding -------------------- # Create sentence with semantic relationship pairs sentence <- Sentence(\"King Queen man woman Paris London apple orange Taiwan Dublin Bamberg\")   # Apply BERT embeddings to the sentence TransformerWordEmbeddings$embed(sentence) #> [[1]] #> Sentence[11]: \"King Queen man woman Paris London apple orange Taiwan Dublin Bamberg\"  # Extract embeddings into matrix format sen_df <- process_embeddings(sentence, verbose = TRUE) #> Extracting token embeddings... #> Converting embeddings to matrix format...Processing completed in 0.004 seconds #> Generated embedding matrix with 11 tokens and 768 dimensions  # Dimensionality Reduction ------------------------ # Set random seed for reproducibility set.seed(123)  # Apply PCA to reduce dimensions to 3 components pca_result <- prcomp(sen_df, center = TRUE, scale. = TRUE)  # Extract first three principal components word_embeddings_matrix <- as.data.frame(pca_result$x[,1:3]) word_embeddings_matrix #>                 PC1        PC2        PC3 #> King    -11.6842347   4.264808  -2.539324 #> Queen   -18.6452298  13.278101  -9.781921 #> man     -18.3565835  10.571228  -1.609781 #> woman   -10.6397328  -2.072400   2.264161 #> Paris     6.9078801  -9.409341 -10.378025 #> London   10.7817432  -8.882279 -11.447068 #> apple    -0.6539988  -8.305127  12.104269 #> orange   -3.4409945  -4.756969  19.216404 #> Taiwan    4.5377624 -12.949620   4.782958 #> Dublin   13.4844947 -11.327335  -7.191557 #> Bamberg  27.7088939  29.588933   4.579885 # 2D Plot library(ggplot2)  bert_plot2D <- ggplot(word_embeddings_matrix, aes(x = PC1, y = PC2, color = PC3,                                               label = rownames(word_embeddings_matrix))) +   geom_point(size = 2) +    geom_text(vjust = 1.5, hjust = 0.5) +     scale_color_gradient(low = \"blue\", high = \"red\") +    theme_minimal() +     labs(title = \"\", x = \"PC1\", y = \"PC2\", color = \"PC3\")    # guides(color = \"none\")   stacked_plot2D"},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"embedding-models-comparison","dir":"Articles","previous_headings":"Embedding Examples > Visialized Embeddings","what":"Embedding Models Comparison","title":"Tutorial","text":" ","code":"library(ggpubr)  figure <- ggarrange(glove_plot2D, stacked_plot2D, bert_plot2D,                    labels = c(\"Glove\", \"Stacked Embedding\", \"BERT\"),                    ncol = 3, nrow = 1,                    common.legend = TRUE,                    legend = \"bottom\",                    font.label = list(size = 8))  figure"},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"training-a-binary-classifier","dir":"Articles","previous_headings":"","what":"Training a Binary Classifier","title":"Tutorial","text":"section, ’ll train sentiment analysis model can categorize text either positive negative. case study adapted pages 116 130 Tadej Magajna’s book, ‘Natural Language Processing Flair’. process training text classifiers Flair mirrors process followed sequence labeling models. Specifically, steps train text classifiers : Load tagged corpus compute label dictionary map. Prepare document embeddings. Initialize TextClassifier class. Train model.","code":""},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"loading-a-tagged-corpus","dir":"Articles","previous_headings":"Training a Binary Classifier","what":"Loading a Tagged Corpus","title":"Tutorial","text":"Training text classification models requires set text documents (typically, sentences paragraphs) document associated one classification labels. train sentiment analysis text classification model, using famous Internet Movie Database (IMDb) dataset, contains 50,000 movie reviews IMDB, review labeled either positive negative. References dataset already baked Flair, loading dataset couldn’t easier: Print sizes corpus object follows - test: %d | train: %d | dev: %d”","code":"library(flaiR) # load IMDB from flair_datasets module Corpus <- flair_data()$Corpus IMDB <- flair_datasets()$IMDB # downsize to 0.05 corpus = IMDB() #> 2025-01-06 02:15:29,709 Reading data from /Users/yenchiehliao/.flair/datasets/imdb_v4-rebalanced #> 2025-01-06 02:15:29,709 Train: /Users/yenchiehliao/.flair/datasets/imdb_v4-rebalanced/train.txt #> 2025-01-06 02:15:29,709 Dev: None #> 2025-01-06 02:15:29,709 Test: None #> 2025-01-06 02:15:30,261 No test split found. Using 10% (i.e. 5000 samples) of the train split as test data #> 2025-01-06 02:15:30,273 No dev split found. Using 10% (i.e. 4500 samples) of the train split as dev data #> 2025-01-06 02:15:30,273 Initialized corpus /Users/yenchiehliao/.flair/datasets/imdb_v4-rebalanced (label type name is 'sentiment') corpus$downsample(0.05) #> <flair.datasets.document_classification.IMDB object at 0x33536e350> test_size <- length(corpus$test) train_size <- length(corpus$train) dev_size <- length(corpus$dev) output <- sprintf(\"Corpus object sizes - Test: %d | Train: %d | Dev: %d\", test_size, train_size, dev_size) print(output) #> [1] \"Corpus object sizes - Test: 250 | Train: 2025 | Dev: 225\" lbl_type = 'sentiment' label_dict = corpus$make_label_dictionary(label_type=lbl_type) #> 2025-01-06 02:15:30,375 Computing label dictionary. Progress: #> 2025-01-06 02:15:33,751 Dictionary created for label 'sentiment' with 2 values: POSITIVE (seen 1014 times), NEGATIVE (seen 1011 times)"},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"loading-the-embeddings","dir":"Articles","previous_headings":"Training a Binary Classifier","what":"Loading the Embeddings","title":"Tutorial","text":"flaiR covers different types document embeddings can use. , simply use DocumentPoolEmbeddings. require training prior training classification model :","code":"DocumentPoolEmbeddings <- flair_embeddings()$DocumentPoolEmbeddings WordEmbeddings <- flair_embeddings()$WordEmbeddings glove = WordEmbeddings('glove') document_embeddings = DocumentPoolEmbeddings(glove)"},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"initializing-the-textclassifier","dir":"Articles","previous_headings":"Training a Binary Classifier","what":"Initializing the TextClassifier","title":"Tutorial","text":"$allows set device use CPU, GPU, specific MPS devices Mac (mps:0, mps:1, mps:2).","code":"# initiate TextClassifier TextClassifier <- flair_models()$TextClassifier classifier <- TextClassifier(document_embeddings,                              label_dictionary = label_dict,                              label_type = lbl_type) classifier$to(flair_device(\"mps\")) TextClassifier(   (embeddings): DocumentPoolEmbeddings(     fine_tune_mode=none, pooling=mean     (embeddings): StackedEmbeddings(       (list_embedding_0): WordEmbeddings(         'glove'         (embedding): Embedding(400001, 100)       )     )   )   (decoder): Linear(in_features=100, out_features=3, bias=True)   (dropout): Dropout(p=0.0, inplace=False)   (locked_dropout): LockedDropout(p=0.0)   (word_dropout): WordDropout(p=0.0)   (loss_function): CrossEntropyLoss() )"},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"training-the-model","dir":"Articles","previous_headings":"Training a Binary Classifier","what":"Training the Model","title":"Tutorial","text":"Training text classifier model involves two simple steps: Defining model trainer class passing classifier model corpus Setting training process passing required training hyper-parameters. worth noting ‘L’ numbers like 32L 5L used R denote number integer. Without ‘L’ suffix, numbers R treated numeric, default double-precision floating-point numbers. contrast, Python determines type based value number . Whole numbers (e.g., 5 32) type int, numbers decimal points (e.g., 5.0) type float. Floating-point numbers languages representations real numbers can approximation due way stored memory.","code":"# initiate ModelTrainer ModelTrainer <- flair_trainers()$ModelTrainer  # fit the model trainer <- ModelTrainer(classifier, corpus)  # start to train # note: the 'L' in 32L is used in R to denote that the number is an integer. trainer$train('classifier',               learning_rate=0.1,               mini_batch_size=32L,               # specifies how embeddings are stored in RAM, ie.\"cpu\", \"cuda\", \"gpu\", \"mps\".               # embeddings_storage_mode = \"mps\",               max_epochs=10L) #> 2025-01-06 02:15:35,883 ---------------------------------------------------------------------------------------------------- #> 2025-01-06 02:15:35,883 Model: \"TextClassifier( #>   (embeddings): DocumentPoolEmbeddings( #>     fine_tune_mode=none, pooling=mean #>     (embeddings): StackedEmbeddings( #>       (list_embedding_0): WordEmbeddings( #>         'glove' #>         (embedding): Embedding(400001, 100) #>       ) #>     ) #>   ) #>   (decoder): Linear(in_features=100, out_features=2, bias=True) #>   (dropout): Dropout(p=0.0, inplace=False) #>   (locked_dropout): LockedDropout(p=0.0) #>   (word_dropout): WordDropout(p=0.0) #>   (loss_function): CrossEntropyLoss() #>   (weights): None #>   (weight_tensor) None #> )\" #> 2025-01-06 02:15:35,883 ---------------------------------------------------------------------------------------------------- #> 2025-01-06 02:15:35,883 Corpus: 2025 train + 225 dev + 250 test sentences #> 2025-01-06 02:15:35,883 ---------------------------------------------------------------------------------------------------- #> 2025-01-06 02:15:35,883 Train:  2025 sentences #> 2025-01-06 02:15:35,883         (train_with_dev=False, train_with_test=False) #> 2025-01-06 02:15:35,883 ---------------------------------------------------------------------------------------------------- #> 2025-01-06 02:15:35,883 Training Params: #> 2025-01-06 02:15:35,883  - learning_rate: \"0.1\"  #> 2025-01-06 02:15:35,883  - mini_batch_size: \"32\" #> 2025-01-06 02:15:35,883  - max_epochs: \"10\" #> 2025-01-06 02:15:35,883  - shuffle: \"True\" #> 2025-01-06 02:15:35,884 ---------------------------------------------------------------------------------------------------- #> 2025-01-06 02:15:35,884 Plugins: #> 2025-01-06 02:15:35,884  - AnnealOnPlateau | patience: '3', anneal_factor: '0.5', min_learning_rate: '0.0001' #> 2025-01-06 02:15:35,884 ---------------------------------------------------------------------------------------------------- #> 2025-01-06 02:15:35,884 Final evaluation on model from best epoch (best-model.pt) #> 2025-01-06 02:15:35,884  - metric: \"('micro avg', 'f1-score')\" #> 2025-01-06 02:15:35,884 ---------------------------------------------------------------------------------------------------- #> 2025-01-06 02:15:35,884 Computation: #> 2025-01-06 02:15:35,884  - compute on device: cpu #> 2025-01-06 02:15:35,884  - embedding storage: cpu #> 2025-01-06 02:15:35,884 ---------------------------------------------------------------------------------------------------- #> 2025-01-06 02:15:35,884 Model training base path: \"classifier\" #> 2025-01-06 02:15:35,884 ---------------------------------------------------------------------------------------------------- #> 2025-01-06 02:15:35,884 ---------------------------------------------------------------------------------------------------- #> 2025-01-06 02:15:36,570 epoch 1 - iter 6/64 - loss 0.89432194 - time (sec): 0.69 - samples/sec: 279.80 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:15:37,291 epoch 1 - iter 12/64 - loss 0.95378078 - time (sec): 1.41 - samples/sec: 272.97 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:15:37,964 epoch 1 - iter 18/64 - loss 0.92937691 - time (sec): 2.08 - samples/sec: 276.89 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:15:38,852 epoch 1 - iter 24/64 - loss 0.91604880 - time (sec): 2.97 - samples/sec: 258.79 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:15:39,559 epoch 1 - iter 30/64 - loss 0.91821102 - time (sec): 3.68 - samples/sec: 261.21 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:15:40,314 epoch 1 - iter 36/64 - loss 0.91657477 - time (sec): 4.43 - samples/sec: 260.08 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:15:41,294 epoch 1 - iter 42/64 - loss 0.92209762 - time (sec): 5.41 - samples/sec: 248.43 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:15:42,011 epoch 1 - iter 48/64 - loss 0.91459117 - time (sec): 6.13 - samples/sec: 250.71 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:15:42,757 epoch 1 - iter 54/64 - loss 0.91163364 - time (sec): 6.87 - samples/sec: 251.44 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:15:43,470 epoch 1 - iter 60/64 - loss 0.90652501 - time (sec): 7.59 - samples/sec: 253.10 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:15:43,953 ---------------------------------------------------------------------------------------------------- #> 2025-01-06 02:15:43,953 EPOCH 1 done: loss 0.9054 - lr: 0.100000 #> 2025-01-06 02:15:44,887 DEV : loss 0.7963227033615112 - f1-score (micro avg)  0.5467 #> 2025-01-06 02:15:45,532  - 0 epochs without improvement #> 2025-01-06 02:15:45,535 saving best model #> 2025-01-06 02:15:45,907 ---------------------------------------------------------------------------------------------------- #> 2025-01-06 02:15:46,632 epoch 2 - iter 6/64 - loss 0.89866542 - time (sec): 0.72 - samples/sec: 264.97 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:15:47,277 epoch 2 - iter 12/64 - loss 0.92867236 - time (sec): 1.37 - samples/sec: 280.42 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:15:48,249 epoch 2 - iter 18/64 - loss 0.93459886 - time (sec): 2.34 - samples/sec: 246.01 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:15:49,007 epoch 2 - iter 24/64 - loss 0.92933469 - time (sec): 3.10 - samples/sec: 247.77 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:15:49,733 epoch 2 - iter 30/64 - loss 0.92514317 - time (sec): 3.83 - samples/sec: 250.94 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:15:50,498 epoch 2 - iter 36/64 - loss 0.92605628 - time (sec): 4.59 - samples/sec: 250.94 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:15:51,158 epoch 2 - iter 42/64 - loss 0.91553296 - time (sec): 5.25 - samples/sec: 255.98 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:15:51,891 epoch 2 - iter 48/64 - loss 0.90254694 - time (sec): 5.98 - samples/sec: 256.72 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:15:52,869 epoch 2 - iter 54/64 - loss 0.90277363 - time (sec): 6.96 - samples/sec: 248.22 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:15:53,643 epoch 2 - iter 60/64 - loss 0.90217373 - time (sec): 7.74 - samples/sec: 248.20 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:15:54,129 ---------------------------------------------------------------------------------------------------- #> 2025-01-06 02:15:54,129 EPOCH 2 done: loss 0.8993 - lr: 0.100000 #> 2025-01-06 02:15:55,070 DEV : loss 0.7813745737075806 - f1-score (micro avg)  0.5467 #> 2025-01-06 02:15:55,723  - 0 epochs without improvement #> 2025-01-06 02:15:55,725 ---------------------------------------------------------------------------------------------------- #> 2025-01-06 02:15:56,507 epoch 3 - iter 6/64 - loss 0.90047341 - time (sec): 0.78 - samples/sec: 245.62 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:15:57,223 epoch 3 - iter 12/64 - loss 0.84552309 - time (sec): 1.50 - samples/sec: 256.42 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:15:57,961 epoch 3 - iter 18/64 - loss 0.87219985 - time (sec): 2.24 - samples/sec: 257.62 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:15:58,926 epoch 3 - iter 24/64 - loss 0.88749881 - time (sec): 3.20 - samples/sec: 239.95 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:15:59,653 epoch 3 - iter 30/64 - loss 0.87357182 - time (sec): 3.93 - samples/sec: 244.42 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:16:00,388 epoch 3 - iter 36/64 - loss 0.86243516 - time (sec): 4.66 - samples/sec: 247.06 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:16:01,111 epoch 3 - iter 42/64 - loss 0.86849659 - time (sec): 5.39 - samples/sec: 249.55 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:16:01,784 epoch 3 - iter 48/64 - loss 0.86500574 - time (sec): 6.06 - samples/sec: 253.51 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:16:02,699 epoch 3 - iter 54/64 - loss 0.87597494 - time (sec): 6.97 - samples/sec: 247.79 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:16:03,448 epoch 3 - iter 60/64 - loss 0.87600966 - time (sec): 7.72 - samples/sec: 248.61 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:16:03,961 ---------------------------------------------------------------------------------------------------- #> 2025-01-06 02:16:03,962 EPOCH 3 done: loss 0.8761 - lr: 0.100000 #> 2025-01-06 02:16:04,901 DEV : loss 0.7775111794471741 - f1-score (micro avg)  0.5467 #> 2025-01-06 02:16:05,268  - 0 epochs without improvement #> 2025-01-06 02:16:05,270 ---------------------------------------------------------------------------------------------------- #> 2025-01-06 02:16:06,358 epoch 4 - iter 6/64 - loss 0.91311837 - time (sec): 1.09 - samples/sec: 176.52 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:16:07,076 epoch 4 - iter 12/64 - loss 0.90012282 - time (sec): 1.81 - samples/sec: 212.67 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:16:07,726 epoch 4 - iter 18/64 - loss 0.90840534 - time (sec): 2.46 - samples/sec: 234.57 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:16:08,459 epoch 4 - iter 24/64 - loss 0.88671272 - time (sec): 3.19 - samples/sec: 240.86 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:16:09,415 epoch 4 - iter 30/64 - loss 0.88862656 - time (sec): 4.15 - samples/sec: 231.60 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:16:10,103 epoch 4 - iter 36/64 - loss 0.88521691 - time (sec): 4.83 - samples/sec: 238.39 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:16:10,772 epoch 4 - iter 42/64 - loss 0.88335732 - time (sec): 5.50 - samples/sec: 244.26 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:16:11,459 epoch 4 - iter 48/64 - loss 0.87461141 - time (sec): 6.19 - samples/sec: 248.20 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:16:12,228 epoch 4 - iter 54/64 - loss 0.87857685 - time (sec): 6.96 - samples/sec: 248.35 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:16:12,998 epoch 4 - iter 60/64 - loss 0.88719228 - time (sec): 7.73 - samples/sec: 248.45 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:16:13,505 ---------------------------------------------------------------------------------------------------- #> 2025-01-06 02:16:13,506 EPOCH 4 done: loss 0.8858 - lr: 0.100000 #> 2025-01-06 02:16:14,642 DEV : loss 0.7681671380996704 - f1-score (micro avg)  0.5511 #> 2025-01-06 02:16:15,010  - 0 epochs without improvement #> 2025-01-06 02:16:15,012 saving best model #> 2025-01-06 02:16:15,378 ---------------------------------------------------------------------------------------------------- #> 2025-01-06 02:16:16,225 epoch 5 - iter 6/64 - loss 0.90661851 - time (sec): 0.85 - samples/sec: 226.74 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:16:16,954 epoch 5 - iter 12/64 - loss 0.89003711 - time (sec): 1.58 - samples/sec: 243.71 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:16:17,665 epoch 5 - iter 18/64 - loss 0.86469275 - time (sec): 2.29 - samples/sec: 251.89 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:16:18,637 epoch 5 - iter 24/64 - loss 0.87048509 - time (sec): 3.26 - samples/sec: 235.70 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:16:19,293 epoch 5 - iter 30/64 - loss 0.87899440 - time (sec): 3.91 - samples/sec: 245.23 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:16:19,972 epoch 5 - iter 36/64 - loss 0.86608321 - time (sec): 4.59 - samples/sec: 250.77 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:16:20,683 epoch 5 - iter 42/64 - loss 0.84847777 - time (sec): 5.30 - samples/sec: 253.36 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:16:21,396 epoch 5 - iter 48/64 - loss 0.84302863 - time (sec): 6.02 - samples/sec: 255.26 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:16:22,310 epoch 5 - iter 54/64 - loss 0.83843940 - time (sec): 6.93 - samples/sec: 249.29 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:16:22,990 epoch 5 - iter 60/64 - loss 0.84231875 - time (sec): 7.61 - samples/sec: 252.24 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:16:23,529 ---------------------------------------------------------------------------------------------------- #> 2025-01-06 02:16:23,529 EPOCH 5 done: loss 0.8392 - lr: 0.100000 #> 2025-01-06 02:16:24,456 DEV : loss 0.9789121747016907 - f1-score (micro avg)  0.4533 #> 2025-01-06 02:16:24,824  - 1 epochs without improvement #> 2025-01-06 02:16:24,826 ---------------------------------------------------------------------------------------------------- #> 2025-01-06 02:16:25,878 epoch 6 - iter 6/64 - loss 0.82106160 - time (sec): 1.05 - samples/sec: 182.57 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:16:26,590 epoch 6 - iter 12/64 - loss 0.82513742 - time (sec): 1.76 - samples/sec: 217.70 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:16:27,316 epoch 6 - iter 18/64 - loss 0.84711787 - time (sec): 2.49 - samples/sec: 231.29 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:16:28,034 epoch 6 - iter 24/64 - loss 0.84226146 - time (sec): 3.21 - samples/sec: 239.39 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:16:28,784 epoch 6 - iter 30/64 - loss 0.85641218 - time (sec): 3.96 - samples/sec: 242.53 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:16:29,757 epoch 6 - iter 36/64 - loss 0.84584417 - time (sec): 4.93 - samples/sec: 233.64 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:16:30,537 epoch 6 - iter 42/64 - loss 0.84522835 - time (sec): 5.71 - samples/sec: 235.33 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:16:31,246 epoch 6 - iter 48/64 - loss 0.83898696 - time (sec): 6.42 - samples/sec: 239.25 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:16:31,958 epoch 6 - iter 54/64 - loss 0.83194279 - time (sec): 7.13 - samples/sec: 242.30 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:16:32,641 epoch 6 - iter 60/64 - loss 0.82938180 - time (sec): 7.82 - samples/sec: 245.67 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:16:33,168 ---------------------------------------------------------------------------------------------------- #> 2025-01-06 02:16:33,168 EPOCH 6 done: loss 0.8262 - lr: 0.100000 #> 2025-01-06 02:16:34,103 DEV : loss 0.9283422827720642 - f1-score (micro avg)  0.4533 #> 2025-01-06 02:16:34,746  - 2 epochs without improvement #> 2025-01-06 02:16:34,748 ---------------------------------------------------------------------------------------------------- #> 2025-01-06 02:16:35,469 epoch 7 - iter 6/64 - loss 0.76819125 - time (sec): 0.72 - samples/sec: 266.64 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:16:36,406 epoch 7 - iter 12/64 - loss 0.79476220 - time (sec): 1.66 - samples/sec: 231.69 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:16:37,130 epoch 7 - iter 18/64 - loss 0.81161556 - time (sec): 2.38 - samples/sec: 241.89 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:16:37,838 epoch 7 - iter 24/64 - loss 0.79558293 - time (sec): 3.09 - samples/sec: 248.59 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:16:38,550 epoch 7 - iter 30/64 - loss 0.80581141 - time (sec): 3.80 - samples/sec: 252.56 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:16:39,267 epoch 7 - iter 36/64 - loss 0.80861445 - time (sec): 4.52 - samples/sec: 254.92 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:16:39,985 epoch 7 - iter 42/64 - loss 0.80557496 - time (sec): 5.24 - samples/sec: 256.64 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:16:40,956 epoch 7 - iter 48/64 - loss 0.81406290 - time (sec): 6.21 - samples/sec: 247.46 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:16:41,737 epoch 7 - iter 54/64 - loss 0.81088759 - time (sec): 6.99 - samples/sec: 247.26 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:16:42,460 epoch 7 - iter 60/64 - loss 0.80919699 - time (sec): 7.71 - samples/sec: 248.99 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:16:42,953 ---------------------------------------------------------------------------------------------------- #> 2025-01-06 02:16:42,953 EPOCH 7 done: loss 0.8065 - lr: 0.100000 #> 2025-01-06 02:16:43,881 DEV : loss 0.9039661884307861 - f1-score (micro avg)  0.4533 #> 2025-01-06 02:16:44,533  - 3 epochs without improvement #> 2025-01-06 02:16:44,535 ---------------------------------------------------------------------------------------------------- #> 2025-01-06 02:16:45,310 epoch 8 - iter 6/64 - loss 0.73954487 - time (sec): 0.77 - samples/sec: 247.85 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:16:46,051 epoch 8 - iter 12/64 - loss 0.76525877 - time (sec): 1.52 - samples/sec: 253.35 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:16:46,740 epoch 8 - iter 18/64 - loss 0.76589356 - time (sec): 2.20 - samples/sec: 261.28 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:16:47,723 epoch 8 - iter 24/64 - loss 0.77570624 - time (sec): 3.19 - samples/sec: 240.94 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:16:48,426 epoch 8 - iter 30/64 - loss 0.79296046 - time (sec): 3.89 - samples/sec: 246.70 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:16:49,138 epoch 8 - iter 36/64 - loss 0.78987739 - time (sec): 4.60 - samples/sec: 250.29 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:16:49,864 epoch 8 - iter 42/64 - loss 0.80644145 - time (sec): 5.33 - samples/sec: 252.18 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:16:50,797 epoch 8 - iter 48/64 - loss 0.80628937 - time (sec): 6.26 - samples/sec: 245.29 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:16:51,507 epoch 8 - iter 54/64 - loss 0.80953304 - time (sec): 6.97 - samples/sec: 247.86 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:16:52,219 epoch 8 - iter 60/64 - loss 0.79553014 - time (sec): 7.68 - samples/sec: 249.87 - lr: 0.100000 - momentum: 0.000000 #> 2025-01-06 02:16:52,695 ---------------------------------------------------------------------------------------------------- #> 2025-01-06 02:16:52,696 EPOCH 8 done: loss 0.7929 - lr: 0.100000 #> 2025-01-06 02:16:53,628 DEV : loss 0.8725866079330444 - f1-score (micro avg)  0.4578 #> 2025-01-06 02:16:53,999  - 4 epochs without improvement (above 'patience')-> annealing learning_rate to [0.05] #> 2025-01-06 02:16:54,001 ---------------------------------------------------------------------------------------------------- #> 2025-01-06 02:16:55,057 epoch 9 - iter 6/64 - loss 0.64390024 - time (sec): 1.06 - samples/sec: 181.83 - lr: 0.050000 - momentum: 0.000000 #> 2025-01-06 02:16:55,712 epoch 9 - iter 12/64 - loss 0.64045698 - time (sec): 1.71 - samples/sec: 224.42 - lr: 0.050000 - momentum: 0.000000 #> 2025-01-06 02:16:56,467 epoch 9 - iter 18/64 - loss 0.65345176 - time (sec): 2.47 - samples/sec: 233.59 - lr: 0.050000 - momentum: 0.000000 #> 2025-01-06 02:16:57,161 epoch 9 - iter 24/64 - loss 0.64245924 - time (sec): 3.16 - samples/sec: 243.00 - lr: 0.050000 - momentum: 0.000000 #> 2025-01-06 02:16:58,116 epoch 9 - iter 30/64 - loss 0.65497465 - time (sec): 4.12 - samples/sec: 233.28 - lr: 0.050000 - momentum: 0.000000 #> 2025-01-06 02:16:58,830 epoch 9 - iter 36/64 - loss 0.65880741 - time (sec): 4.83 - samples/sec: 238.53 - lr: 0.050000 - momentum: 0.000000 #> 2025-01-06 02:16:59,536 epoch 9 - iter 42/64 - loss 0.65892425 - time (sec): 5.54 - samples/sec: 242.80 - lr: 0.050000 - momentum: 0.000000 #> 2025-01-06 02:17:00,242 epoch 9 - iter 48/64 - loss 0.65554699 - time (sec): 6.24 - samples/sec: 246.09 - lr: 0.050000 - momentum: 0.000000 #> 2025-01-06 02:17:00,983 epoch 9 - iter 54/64 - loss 0.66809738 - time (sec): 6.98 - samples/sec: 247.50 - lr: 0.050000 - momentum: 0.000000 #> 2025-01-06 02:17:01,968 epoch 9 - iter 60/64 - loss 0.66804753 - time (sec): 7.97 - samples/sec: 240.98 - lr: 0.050000 - momentum: 0.000000 #> 2025-01-06 02:17:02,297 ---------------------------------------------------------------------------------------------------- #> 2025-01-06 02:17:02,297 EPOCH 9 done: loss 0.6708 - lr: 0.050000 #> 2025-01-06 02:17:03,467 DEV : loss 0.8140835165977478 - f1-score (micro avg)  0.4711 #> 2025-01-06 02:17:03,840  - 1 epochs without improvement #> 2025-01-06 02:17:03,842 ---------------------------------------------------------------------------------------------------- #> 2025-01-06 02:17:04,860 epoch 10 - iter 6/64 - loss 0.60182520 - time (sec): 1.02 - samples/sec: 188.75 - lr: 0.050000 - momentum: 0.000000 #> 2025-01-06 02:17:05,574 epoch 10 - iter 12/64 - loss 0.65083574 - time (sec): 1.73 - samples/sec: 221.71 - lr: 0.050000 - momentum: 0.000000 #> 2025-01-06 02:17:06,313 epoch 10 - iter 18/64 - loss 0.66171811 - time (sec): 2.47 - samples/sec: 233.14 - lr: 0.050000 - momentum: 0.000000 #> 2025-01-06 02:17:07,040 epoch 10 - iter 24/64 - loss 0.65951264 - time (sec): 3.20 - samples/sec: 240.20 - lr: 0.050000 - momentum: 0.000000 #> 2025-01-06 02:17:07,751 epoch 10 - iter 30/64 - loss 0.66091878 - time (sec): 3.91 - samples/sec: 245.65 - lr: 0.050000 - momentum: 0.000000 #> 2025-01-06 02:17:08,708 epoch 10 - iter 36/64 - loss 0.64727579 - time (sec): 4.87 - samples/sec: 236.78 - lr: 0.050000 - momentum: 0.000000 #> 2025-01-06 02:17:09,400 epoch 10 - iter 42/64 - loss 0.65162275 - time (sec): 5.56 - samples/sec: 241.84 - lr: 0.050000 - momentum: 0.000000 #> 2025-01-06 02:17:10,104 epoch 10 - iter 48/64 - loss 0.65844808 - time (sec): 6.26 - samples/sec: 245.31 - lr: 0.050000 - momentum: 0.000000 #> 2025-01-06 02:17:10,874 epoch 10 - iter 54/64 - loss 0.65979258 - time (sec): 7.03 - samples/sec: 245.75 - lr: 0.050000 - momentum: 0.000000 #> 2025-01-06 02:17:11,802 epoch 10 - iter 60/64 - loss 0.66946246 - time (sec): 7.96 - samples/sec: 241.21 - lr: 0.050000 - momentum: 0.000000 #> 2025-01-06 02:17:12,101 ---------------------------------------------------------------------------------------------------- #> 2025-01-06 02:17:12,101 EPOCH 10 done: loss 0.6684 - lr: 0.050000 #> 2025-01-06 02:17:13,266 DEV : loss 0.7090357542037964 - f1-score (micro avg)  0.5511 #> 2025-01-06 02:17:13,637  - 0 epochs without improvement #> 2025-01-06 02:17:14,009 ---------------------------------------------------------------------------------------------------- #> 2025-01-06 02:17:14,010 Loading model from best epoch ... #> 2025-01-06 02:17:15,205  #> Results: #> - F-score (micro) 0.492 #> - F-score (macro) 0.3495 #> - Accuracy 0.492 #>  #> By class: #>               precision    recall  f1-score   support #>  #>     NEGATIVE     0.4878    0.9917    0.6540       121 #>     POSITIVE     0.7500    0.0233    0.0451       129 #>  #>     accuracy                         0.4920       250 #>    macro avg     0.6189    0.5075    0.3495       250 #> weighted avg     0.6231    0.4920    0.3398       250 #>  #> 2025-01-06 02:17:15,205 ---------------------------------------------------------------------------------------------------- #> $test_score #> [1] 0.492"},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"loading-and-using-the-classifiers","dir":"Articles","previous_headings":"Training a Binary Classifier","what":"Loading and Using the Classifiers","title":"Tutorial","text":"training text classification model, resulting classifier already stored memory part classifier variable. possible, however, Python session exited training. , ’ll need load model memory following: import Sentence object. Now, can generate predictions example text inputs.  ","code":"TextClassifier <- flair_models()$TextClassifier classifier <- TextClassifier$load('classifier/best-model.pt') Sentence <- flair_data()$Sentence sentence <- Sentence(\"great\") classifier$predict(sentence) print(sentence$labels) #> [[1]] #> 'Sentence[1]: \"great\"'/'POSITIVE' (0.9812) sentence <- Sentence(\"sad\") classifier$predict(sentence) print(sentence$labels) #> [[1]] #> 'Sentence[1]: \"sad\"'/'NEGATIVE' (0.8999)"},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"training-rnns","dir":"Articles","previous_headings":"","what":"Training RNNs","title":"Tutorial","text":", train sentiment analysis model categorize text. case, also include pipeline implements use Recurrent Neural Networks (RNN). makes particularly effective tasks involving sequential data. section also show implement one powerful features flaiR, stacked embeddings. can stack multiple embeddings different layers let classifier learn different types features. Flair NLP, flaiR package, ’s easy accomplish task.","code":""},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"import-necessary-modules","dir":"Articles","previous_headings":"Training RNNs","what":"Import Necessary Modules","title":"Tutorial","text":"","code":"library(flaiR) WordEmbeddings <- flair_embeddings()$WordEmbeddings FlairEmbeddings <- flair_embeddings()$FlairEmbeddings DocumentRNNEmbeddings <- flair_embeddings()$DocumentRNNEmbeddings TextClassifier <- flair_models()$TextClassifier ModelTrainer <- flair_trainers()$ModelTrainer"},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"get-the-imdb-corpus","dir":"Articles","previous_headings":"Training RNNs","what":"Get the IMDB Corpus","title":"Tutorial","text":"IMDB movie review dataset used , commonly utilized dataset sentiment analysis. $downsample(0.1) method means 10% dataset used, allowing faster demonstration.","code":"# load the IMDB file and downsize it to 0.1 IMDB <- flair_datasets()$IMDB corpus <- IMDB()$downsample(0.1)  #> 2025-01-06 02:17:15,624 Reading data from /Users/yenchiehliao/.flair/datasets/imdb_v4-rebalanced #> 2025-01-06 02:17:15,624 Train: /Users/yenchiehliao/.flair/datasets/imdb_v4-rebalanced/train.txt #> 2025-01-06 02:17:15,624 Dev: None #> 2025-01-06 02:17:15,624 Test: None #> 2025-01-06 02:17:16,167 No test split found. Using 10% (i.e. 5000 samples) of the train split as test data #> 2025-01-06 02:17:16,181 No dev split found. Using 10% (i.e. 4500 samples) of the train split as dev data #> 2025-01-06 02:17:16,181 Initialized corpus /Users/yenchiehliao/.flair/datasets/imdb_v4-rebalanced (label type name is 'sentiment') # create the label dictionary lbl_type <- 'sentiment' label_dict <- corpus$make_label_dictionary(label_type=lbl_type) #> 2025-01-06 02:17:16,197 Computing label dictionary. Progress: #> 2025-01-06 02:17:23,070 Dictionary created for label 'sentiment' with 2 values: POSITIVE (seen 2056 times), NEGATIVE (seen 1994 times)"},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"stacked-embeddings","dir":"Articles","previous_headings":"Training RNNs","what":"Stacked Embeddings","title":"Tutorial","text":"one Flair’s powerful features: allows integration embeddings enable model learn sparse features. Three types embeddings utilized : GloVe embeddings, two types Flair embeddings (forward backward). Word embeddings used convert words vectors.","code":"# make a list of word embeddings word_embeddings <- list(WordEmbeddings('glove'),                         FlairEmbeddings('news-forward-fast'),                         FlairEmbeddings('news-backward-fast'))  # initialize the document embeddings document_embeddings <- DocumentRNNEmbeddings(word_embeddings,                                               hidden_size = 512L,                                              reproject_words = TRUE,                                              reproject_words_dimension = 256L) # create a Text Classifier with the embeddings and label dictionary classifier <- TextClassifier(document_embeddings,                              label_dictionary=label_dict, label_type='class')  # initialize the text classifier trainer with our corpus trainer <- ModelTrainer(classifier, corpus)"},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"start-the-training","dir":"Articles","previous_headings":"Training RNNs","what":"Start the Training","title":"Tutorial","text":"sake example, setting max_epochs 5. might want increase better performance. worth noting learning rate parameter determines step size iteration moving towards minimum loss function. smaller learning rate slow learning process, lead precise convergence. mini_batch_size determines number samples used compute gradient step. ‘L’ 32L used R denote number integer. patience (aka early stop) hyper-parameter used conjunction early stopping avoid overfitting. determines number epochs training process tolerate without improvements stopping training. Setting max_epochs 5 means algorithm make five passes dataset.","code":"# note: the 'L' in 32L is used in R to denote that the number is an integer. trainer$train('models/sentiment',               learning_rate=0.1,               mini_batch_size=32L,               patience=5L,               max_epochs=5L)"},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"to-apply-the-trained-model-for-prediction","dir":"Articles","previous_headings":"Training RNNs","what":"To Apply the Trained Model for Prediction","title":"Tutorial","text":"","code":"sentence <- \"This movie was really exciting!\" classifier$predict(sentence) print(sentence.labels)"},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"finetune-transformers","dir":"Articles","previous_headings":"","what":"Finetune Transformers","title":"Tutorial","text":"use data Temporal Focus Campaign Communication (2020 JOP) example. Let’s assume receive data training different times. First, suppose dataset 1000 entries called cc_muller_old. another day, help nice friends, receive another set data, adding 2000 entries dataset called cc_muller_new. subsets data(cc_muller). show fine-tune transformer model cc_muller_old, continue another round fine-tuning using cc_muller_new.","code":"library(flaiR)"},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"fine-tuning-a-transformers-model","dir":"Articles","previous_headings":"Finetune Transformers","what":"Fine-tuning a Transformers Model","title":"Tutorial","text":"Step 1 Load Necessary Modules Flair Load necessary classes flair package. use purrr help us split sentences using Sentence flair_data(), use map2 add labels, finally use Corpus segment data. provide development set (dev set) using Flair, automatically split training data training development datasets. test set used training model evaluating final performance, whereas development set used adjusting model parameters preventing overfitting, words, early stopping model. Step 3 Load distilbert Transformer First, $make_label_dictionary function used automatically create label dictionary classification task. label dictionary mapping label index, used map labels tensor label indices. Besides classification tasks, flaiR also supports label types training custom model. cc_muller dataset: Future (seen 423 times), Present (seen 262 times), Past (seen 131 times). TextClassifier used create text classifier. classifier takes document embeddings (importing 'distilbert-base-uncased' Hugging Face) label dictionary input. label type also specified classification. Step 4 Start Training ModelTrainer used train model.","code":"# Sentence is a class for holding a text sentence Sentence <- flair_data()$Sentence  # Corpus is a class for text corpora Corpus <- flair_data()$Corpus  # TransformerDocumentEmbeddings is a class for loading transformer  TransformerDocumentEmbeddings <- flair_embeddings()$TransformerDocumentEmbeddings  # TextClassifier is a class for text classification TextClassifier <- flair_models()$TextClassifier  # ModelTrainer is a class for training and evaluating models ModelTrainer <- flair_trainers()$ModelTrainer library(purrr)  data(cc_muller) cc_muller_old <- cc_muller[1:1000,]  old_text <- map(cc_muller_old$text, Sentence) old_labels <- as.character(cc_muller_old$class)  old_text <- map2(old_text, old_labels, ~ {   .x$add_label(\"classification\", .y)   .x }) print(length(old_text)) #> [1] 1000 set.seed(2046) sample <- sample(c(TRUE, FALSE), length(old_text), replace=TRUE, prob=c(0.8, 0.2)) old_train  <- old_text[sample] old_test   <- old_text[!sample]  test_id <- sample(c(TRUE, FALSE), length(old_test), replace=TRUE, prob=c(0.5, 0.5)) old_test   <- old_test[test_id] old_dev   <- old_test[!test_id] old_corpus <- Corpus(train = old_train, test = old_test) #> 2025-01-06 02:17:25,677 No dev split found. Using 10% (i.e. 80 samples) of the train split as dev data document_embeddings <- TransformerDocumentEmbeddings('distilbert-base-uncased', fine_tune=TRUE) old_label_dict <- old_corpus$make_label_dictionary(label_type=\"classification\") #> 2025-01-06 02:17:30,308 Computing label dictionary. Progress: #> 2025-01-06 02:17:30,313 Dictionary created for label 'classification' with 3 values: Future (seen 380 times), Present (seen 232 times), Past (seen 111 times) old_classifier <- TextClassifier(document_embeddings,                                  label_dictionary = old_label_dict,                                   label_type='classification') old_trainer <- ModelTrainer(model = old_classifier, corpus = old_corpus) old_trainer$train(\"vignettes/inst/muller-campaign-communication\",                     learning_rate=0.02,                                 mini_batch_size=8L,                                 anneal_with_restarts = TRUE,                   save_final_model=TRUE,                   max_epochs=1L)    #> 2025-01-06 02:17:30,446 ---------------------------------------------------------------------------------------------------- #> 2025-01-06 02:17:30,446 Model: \"TextClassifier( #>   (embeddings): TransformerDocumentEmbeddings( #>     (model): DistilBertModel( #>       (embeddings): Embeddings( #>         (word_embeddings): Embedding(30523, 768, padding_idx=0) #>         (position_embeddings): Embedding(512, 768) #>         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True) #>         (dropout): Dropout(p=0.1, inplace=False) #>       ) #>       (transformer): Transformer( #>         (layer): ModuleList( #>           (0-5): 6 x TransformerBlock( #>             (attention): MultiHeadSelfAttention( #>               (dropout): Dropout(p=0.1, inplace=False) #>               (q_lin): Linear(in_features=768, out_features=768, bias=True) #>               (k_lin): Linear(in_features=768, out_features=768, bias=True) #>               (v_lin): Linear(in_features=768, out_features=768, bias=True) #>               (out_lin): Linear(in_features=768, out_features=768, bias=True) #>             ) #>             (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True) #>             (ffn): FFN( #>               (dropout): Dropout(p=0.1, inplace=False) #>               (lin1): Linear(in_features=768, out_features=3072, bias=True) #>               (lin2): Linear(in_features=3072, out_features=768, bias=True) #>               (activation): GELUActivation() #>             ) #>             (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True) #>           ) #>         ) #>       ) #>     ) #>   ) #>   (decoder): Linear(in_features=768, out_features=3, bias=True) #>   (dropout): Dropout(p=0.0, inplace=False) #>   (locked_dropout): LockedDropout(p=0.0) #>   (word_dropout): WordDropout(p=0.0) #>   (loss_function): CrossEntropyLoss() #>   (weights): None #>   (weight_tensor) None #> )\" #> 2025-01-06 02:17:30,446 ---------------------------------------------------------------------------------------------------- #> 2025-01-06 02:17:30,446 Corpus: 723 train + 80 dev + 85 test sentences #> 2025-01-06 02:17:30,446 ---------------------------------------------------------------------------------------------------- #> 2025-01-06 02:17:30,446 Train:  723 sentences #> 2025-01-06 02:17:30,446         (train_with_dev=False, train_with_test=False) #> 2025-01-06 02:17:30,446 ---------------------------------------------------------------------------------------------------- #> 2025-01-06 02:17:30,446 Training Params: #> 2025-01-06 02:17:30,446  - learning_rate: \"0.02\"  #> 2025-01-06 02:17:30,446  - mini_batch_size: \"8\" #> 2025-01-06 02:17:30,446  - max_epochs: \"1\" #> 2025-01-06 02:17:30,446  - shuffle: \"True\" #> 2025-01-06 02:17:30,447 ---------------------------------------------------------------------------------------------------- #> 2025-01-06 02:17:30,447 Plugins: #> 2025-01-06 02:17:30,447  - AnnealOnPlateau | patience: '3', anneal_factor: '0.5', min_learning_rate: '0.0001' #> 2025-01-06 02:17:30,447 ---------------------------------------------------------------------------------------------------- #> 2025-01-06 02:17:30,447 Final evaluation on model from best epoch (best-model.pt) #> 2025-01-06 02:17:30,447  - metric: \"('micro avg', 'f1-score')\" #> 2025-01-06 02:17:30,447 ---------------------------------------------------------------------------------------------------- #> 2025-01-06 02:17:30,447 Computation: #> 2025-01-06 02:17:30,447  - compute on device: cpu #> 2025-01-06 02:17:30,447  - embedding storage: cpu #> 2025-01-06 02:17:30,447 ---------------------------------------------------------------------------------------------------- #> 2025-01-06 02:17:30,447 Model training base path: \"vignettes/inst/muller-campaign-communication\" #> 2025-01-06 02:17:30,447 ---------------------------------------------------------------------------------------------------- #> 2025-01-06 02:17:30,447 ---------------------------------------------------------------------------------------------------- #> 2025-01-06 02:17:33,374 epoch 1 - iter 9/91 - loss 1.16031746 - time (sec): 2.93 - samples/sec: 24.60 - lr: 0.020000 - momentum: 0.000000 #> 2025-01-06 02:17:35,916 epoch 1 - iter 18/91 - loss 1.02841106 - time (sec): 5.47 - samples/sec: 26.33 - lr: 0.020000 - momentum: 0.000000 #> 2025-01-06 02:17:38,727 epoch 1 - iter 27/91 - loss 0.93399640 - time (sec): 8.28 - samples/sec: 26.09 - lr: 0.020000 - momentum: 0.000000 #> 2025-01-06 02:17:42,432 epoch 1 - iter 36/91 - loss 0.84910158 - time (sec): 11.99 - samples/sec: 24.03 - lr: 0.020000 - momentum: 0.000000 #> 2025-01-06 02:17:45,394 epoch 1 - iter 45/91 - loss 0.78349993 - time (sec): 14.95 - samples/sec: 24.09 - lr: 0.020000 - momentum: 0.000000 #> 2025-01-06 02:17:48,378 epoch 1 - iter 54/91 - loss 0.74254180 - time (sec): 17.93 - samples/sec: 24.09 - lr: 0.020000 - momentum: 0.000000 #> 2025-01-06 02:17:51,622 epoch 1 - iter 63/91 - loss 0.71888689 - time (sec): 21.17 - samples/sec: 23.80 - lr: 0.020000 - momentum: 0.000000 #> 2025-01-06 02:17:54,369 epoch 1 - iter 72/91 - loss 0.69288619 - time (sec): 23.92 - samples/sec: 24.08 - lr: 0.020000 - momentum: 0.000000 #> 2025-01-06 02:17:57,403 epoch 1 - iter 81/91 - loss 0.67988467 - time (sec): 26.96 - samples/sec: 24.04 - lr: 0.020000 - momentum: 0.000000 #> 2025-01-06 02:18:00,343 epoch 1 - iter 90/91 - loss 0.66360266 - time (sec): 29.90 - samples/sec: 24.08 - lr: 0.020000 - momentum: 0.000000 #> 2025-01-06 02:18:00,532 ---------------------------------------------------------------------------------------------------- #> 2025-01-06 02:18:00,532 EPOCH 1 done: loss 0.6637 - lr: 0.020000 #> 2025-01-06 02:18:04,472 DEV : loss 0.41622668504714966 - f1-score (micro avg)  0.85 #> 2025-01-06 02:18:04,474  - 0 epochs without improvement #> 2025-01-06 02:18:04,475 saving best model #> 2025-01-06 02:18:05,452 ---------------------------------------------------------------------------------------------------- #> 2025-01-06 02:18:05,453 Loading model from best epoch ... #> 2025-01-06 02:18:08,139  #> Results: #> - F-score (micro) 0.8471 #> - F-score (macro) 0.854 #> - Accuracy 0.8471 #>  #> By class: #>               precision    recall  f1-score   support #>  #>       Future     0.9444    0.7907    0.8608        43 #>      Present     0.7027    0.9630    0.8125        27 #>         Past     1.0000    0.8000    0.8889        15 #>  #>     accuracy                         0.8471        85 #>    macro avg     0.8824    0.8512    0.8540        85 #> weighted avg     0.8775    0.8471    0.8504        85 #>  #> 2025-01-06 02:18:08,139 ---------------------------------------------------------------------------------------------------- #> $test_score #> [1] 0.8470588"},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"continue-fine-tuning-with-new-dataset","dir":"Articles","previous_headings":"Finetune Transformers","what":"Continue Fine-tuning with New Dataset","title":"Tutorial","text":"Now, can continue fine tune already fine tuned model additional 2000 pieces data. First, let’s say another 2000 entries called cc_muller_new. can fine-tune previous model 2000 entries. steps . case, don’t need split dataset . can use entire 2000 entries training set use old_test set evaluate well refined model performs. Step 1 Load muller-campaign-communication Model Load model (old_model) already fine tuned previous stage let’s fine tune new data, new_corpus. Step 2 Convert New Data Sentence Corpus Step 3 Create New Model Trainer Old Model New Corpus Step 4 Train New Model","code":"old_model <- TextClassifier$load(\"vignettes/inst/muller-campaign-communication/best-model.pt\") library(purrr) cc_muller_new <- cc_muller[1001:3000,] new_text <- map(cc_muller_new$text, Sentence) new_labels <- as.character(cc_muller_new$class)  new_text <- map2(new_text, new_labels, ~ {   .x$add_label(\"classification\", .y)   .x }) new_corpus <- Corpus(train=new_text, test=old_test) #> 2025-01-06 02:18:10,164 No dev split found. Using 10% (i.e. 200 samples) of the train split as dev data new_trainer <- ModelTrainer(old_model, new_corpus) new_trainer$train(\"vignettes/inst/new-muller-campaign-communication\",                   learning_rate=0.002,                    mini_batch_size=8L,                     max_epochs=1L)     #> 2025-01-06 02:18:10,272 ---------------------------------------------------------------------------------------------------- #> 2025-01-06 02:18:10,273 Model: \"TextClassifier( #>   (embeddings): TransformerDocumentEmbeddings( #>     (model): DistilBertModel( #>       (embeddings): Embeddings( #>         (word_embeddings): Embedding(30523, 768, padding_idx=0) #>         (position_embeddings): Embedding(512, 768) #>         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True) #>         (dropout): Dropout(p=0.1, inplace=False) #>       ) #>       (transformer): Transformer( #>         (layer): ModuleList( #>           (0-5): 6 x TransformerBlock( #>             (attention): MultiHeadSelfAttention( #>               (dropout): Dropout(p=0.1, inplace=False) #>               (q_lin): Linear(in_features=768, out_features=768, bias=True) #>               (k_lin): Linear(in_features=768, out_features=768, bias=True) #>               (v_lin): Linear(in_features=768, out_features=768, bias=True) #>               (out_lin): Linear(in_features=768, out_features=768, bias=True) #>             ) #>             (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True) #>             (ffn): FFN( #>               (dropout): Dropout(p=0.1, inplace=False) #>               (lin1): Linear(in_features=768, out_features=3072, bias=True) #>               (lin2): Linear(in_features=3072, out_features=768, bias=True) #>               (activation): GELUActivation() #>             ) #>             (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True) #>           ) #>         ) #>       ) #>     ) #>   ) #>   (decoder): Linear(in_features=768, out_features=3, bias=True) #>   (dropout): Dropout(p=0.0, inplace=False) #>   (locked_dropout): LockedDropout(p=0.0) #>   (word_dropout): WordDropout(p=0.0) #>   (loss_function): CrossEntropyLoss() #>   (weights): None #>   (weight_tensor) None #> )\" #> 2025-01-06 02:18:10,273 ---------------------------------------------------------------------------------------------------- #> 2025-01-06 02:18:10,273 Corpus: 1800 train + 200 dev + 85 test sentences #> 2025-01-06 02:18:10,273 ---------------------------------------------------------------------------------------------------- #> 2025-01-06 02:18:10,273 Train:  1800 sentences #> 2025-01-06 02:18:10,273         (train_with_dev=False, train_with_test=False) #> 2025-01-06 02:18:10,273 ---------------------------------------------------------------------------------------------------- #> 2025-01-06 02:18:10,273 Training Params: #> 2025-01-06 02:18:10,273  - learning_rate: \"0.002\"  #> 2025-01-06 02:18:10,273  - mini_batch_size: \"8\" #> 2025-01-06 02:18:10,273  - max_epochs: \"1\" #> 2025-01-06 02:18:10,273  - shuffle: \"True\" #> 2025-01-06 02:18:10,273 ---------------------------------------------------------------------------------------------------- #> 2025-01-06 02:18:10,273 Plugins: #> 2025-01-06 02:18:10,273  - AnnealOnPlateau | patience: '3', anneal_factor: '0.5', min_learning_rate: '0.0001' #> 2025-01-06 02:18:10,273 ---------------------------------------------------------------------------------------------------- #> 2025-01-06 02:18:10,273 Final evaluation on model from best epoch (best-model.pt) #> 2025-01-06 02:18:10,273  - metric: \"('micro avg', 'f1-score')\" #> 2025-01-06 02:18:10,273 ---------------------------------------------------------------------------------------------------- #> 2025-01-06 02:18:10,273 Computation: #> 2025-01-06 02:18:10,273  - compute on device: cpu #> 2025-01-06 02:18:10,273  - embedding storage: cpu #> 2025-01-06 02:18:10,274 ---------------------------------------------------------------------------------------------------- #> 2025-01-06 02:18:10,274 Model training base path: \"vignettes/inst/new-muller-campaign-communication\" #> 2025-01-06 02:18:10,274 ---------------------------------------------------------------------------------------------------- #> 2025-01-06 02:18:10,274 ---------------------------------------------------------------------------------------------------- #> 2025-01-06 02:18:18,665 epoch 1 - iter 22/225 - loss 0.35103212 - time (sec): 8.39 - samples/sec: 20.98 - lr: 0.002000 - momentum: 0.000000 #> 2025-01-06 02:18:26,877 epoch 1 - iter 44/225 - loss 0.37497384 - time (sec): 16.60 - samples/sec: 21.20 - lr: 0.002000 - momentum: 0.000000 #> 2025-01-06 02:21:43,118 epoch 1 - iter 66/225 - loss 0.39964381 - time (sec): 212.84 - samples/sec: 2.48 - lr: 0.002000 - momentum: 0.000000 #> 2025-01-06 02:21:55,222 epoch 1 - iter 88/225 - loss 0.38488409 - time (sec): 224.95 - samples/sec: 3.13 - lr: 0.002000 - momentum: 0.000000 #> 2025-01-06 02:22:08,984 epoch 1 - iter 110/225 - loss 0.38118784 - time (sec): 238.71 - samples/sec: 3.69 - lr: 0.002000 - momentum: 0.000000 #> 2025-01-06 02:23:27,142 epoch 1 - iter 132/225 - loss 0.38156365 - time (sec): 316.87 - samples/sec: 3.33 - lr: 0.002000 - momentum: 0.000000 #> 2025-01-06 02:23:34,401 epoch 1 - iter 154/225 - loss 0.38008256 - time (sec): 324.13 - samples/sec: 3.80 - lr: 0.002000 - momentum: 0.000000 #> 2025-01-06 02:23:41,606 epoch 1 - iter 176/225 - loss 0.38081219 - time (sec): 331.33 - samples/sec: 4.25 - lr: 0.002000 - momentum: 0.000000 #> 2025-01-06 02:23:47,595 epoch 1 - iter 198/225 - loss 0.38418012 - time (sec): 337.32 - samples/sec: 4.70 - lr: 0.002000 - momentum: 0.000000 #> 2025-01-06 02:23:54,166 epoch 1 - iter 220/225 - loss 0.37748125 - time (sec): 343.89 - samples/sec: 5.12 - lr: 0.002000 - momentum: 0.000000 #> 2025-01-06 02:23:55,737 ---------------------------------------------------------------------------------------------------- #> 2025-01-06 02:23:55,738 EPOCH 1 done: loss 0.3753 - lr: 0.002000 #> 2025-01-06 02:23:58,448 DEV : loss 0.4052448570728302 - f1-score (micro avg)  0.86 #> 2025-01-06 02:23:58,450  - 0 epochs without improvement #> 2025-01-06 02:23:58,452 saving best model #> 2025-01-06 02:23:59,299 ---------------------------------------------------------------------------------------------------- #> 2025-01-06 02:23:59,300 Loading model from best epoch ... #> 2025-01-06 02:24:01,545  #> Results: #> - F-score (micro) 0.8471 #> - F-score (macro) 0.8583 #> - Accuracy 0.8471 #>  #> By class: #>               precision    recall  f1-score   support #>  #>       Future     0.8605    0.8605    0.8605        43 #>      Present     0.7586    0.8148    0.7857        27 #>         Past     1.0000    0.8667    0.9286        15 #>  #>     accuracy                         0.8471        85 #>    macro avg     0.8730    0.8473    0.8583        85 #> weighted avg     0.8527    0.8471    0.8487        85 #>  #> 2025-01-06 02:24:01,546 ---------------------------------------------------------------------------------------------------- #> $test_score #> [1] 0.8470588"},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"model-performance-metrics-pre-and-post-fine-tuning","dir":"Articles","previous_headings":"Finetune Transformers","what":"Model Performance Metrics: Pre and Post Fine-tuning","title":"Tutorial","text":"fine-tuning 1 epoch, model showed improved performance test set. R tutorial documentation see .","code":""},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"using-your-own-fine-tuned-model-in-flair","dir":"Articles","previous_headings":"Finetune Transformers","what":"Using Your Own Fine-tuned Model in flaiR","title":"Tutorial","text":"seciton demonstrates utilize custom fine-tuned model flaiR text classification tasks. Let’s explore process step step. Setting Environment First, need load flaiR package prepare model: ’s important verify model’s compatibility $model_card. can check examining version requirements: Making Predictions make predictions, first need prepare text creating Sentence object. key component Flair’s architecture handles text processing: Access Prediction Results Get predicted label Get confidence score  ","code":"library(flaiR) classifier <- flair_models()$TextClassifier$load('vignettes/inst/new-muller-campaign-communication/best-model.pt') print(classifier$model_card) #> $flair_version #> [1] \"0.15.0\" #>  #> $pytorch_version #> [1] \"2.0.0\" #>  #> $transformers_version #> [1] \"4.44.2\" #>  #> $training_parameters #> $training_parameters$base_path #> PosixPath('vignettes/inst/new-muller-campaign-communication') #>  #> $training_parameters$learning_rate #> [1] 0.002 #>  #> $training_parameters$decoder_learning_rate #> NULL #>  #> $training_parameters$mini_batch_size #> [1] 8 #>  #> $training_parameters$eval_batch_size #> [1] 64 #>  #> $training_parameters$mini_batch_chunk_size #> NULL #>  #> $training_parameters$max_epochs #> [1] 1 #>  #> $training_parameters$optimizer #> [1] \"torch.optim.sgd.SGD\" #>  #> $training_parameters$train_with_dev #> [1] FALSE #>  #> $training_parameters$train_with_test #> [1] FALSE #>  #> $training_parameters$max_grad_norm #> [1] 5 #>  #> $training_parameters$reduce_transformer_vocab #> [1] FALSE #>  #> $training_parameters$main_evaluation_metric #> $training_parameters$main_evaluation_metric[[1]] #> [1] \"micro avg\" #>  #> $training_parameters$main_evaluation_metric[[2]] #> [1] \"f1-score\" #>  #>  #> $training_parameters$monitor_test #> [1] FALSE #>  #> $training_parameters$monitor_train_sample #> [1] 0 #>  #> $training_parameters$use_final_model_for_eval #> [1] FALSE #>  #> $training_parameters$gold_label_dictionary_for_eval #> NULL #>  #> $training_parameters$exclude_labels #> list() #>  #> $training_parameters$sampler #> NULL #>  #> $training_parameters$shuffle #> [1] TRUE #>  #> $training_parameters$shuffle_first_epoch #> [1] TRUE #>  #> $training_parameters$embeddings_storage_mode #> [1] \"cpu\" #>  #> $training_parameters$epoch #> [1] 1 #>  #> $training_parameters$save_final_model #> [1] TRUE #>  #> $training_parameters$save_optimizer_state #> [1] FALSE #>  #> $training_parameters$save_model_each_k_epochs #> [1] 0 #>  #> $training_parameters$create_file_logs #> [1] TRUE #>  #> $training_parameters$create_loss_file #> [1] TRUE #>  #> $training_parameters$write_weights #> [1] FALSE #>  #> $training_parameters$use_amp #> [1] FALSE #>  #> $training_parameters$multi_gpu #> [1] FALSE #>  #> $training_parameters$plugins #> $training_parameters$plugins[[1]] #> $training_parameters$plugins[[1]]$`__cls__` #> [1] \"flair.trainers.plugins.functional.anneal_on_plateau.AnnealingPlugin\" #>  #> $training_parameters$plugins[[1]]$base_path #> [1] \"vignettes/inst/new-muller-campaign-communication\" #>  #> $training_parameters$plugins[[1]]$min_learning_rate #> [1] 1e-04 #>  #> $training_parameters$plugins[[1]]$anneal_factor #> [1] 0.5 #>  #> $training_parameters$plugins[[1]]$patience #> [1] 3 #>  #> $training_parameters$plugins[[1]]$initial_extra_patience #> [1] 0 #>  #> $training_parameters$plugins[[1]]$anneal_with_restarts #> [1] FALSE #>  #>  #>  #> $training_parameters$kwargs #> $training_parameters$kwargs$lr #> [1] 0.002 # Check required versions print(classifier$model_card$transformers_version)  # Required transformers version #> [1] \"4.44.2\" print(classifier$model_card$flair_version)         # Required Flair version #> [1] \"0.15.0\" # Get the Sentence class from flaiR Sentence <- flair_data()$Sentence  # Create a Sentence object with your text sentence <- Sentence(\"And to boost the housing we need, we will start to build a new generation of garden cities.\")  # Make prediction classifier$predict(sentence) prediction <- sentence$labels[[1]]$value print(prediction) #> [1] \"Future\" confidence <- sentence$labels[[1]]$score  print(confidence) #> [1] 0.9983375"},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"extending-contexts-embedding-regression","dir":"Articles","previous_headings":"","what":"Extending conText’s Embedding Regression","title":"Tutorial","text":"ConText fast, flexible, transparent framework estimating context-specific word short document embeddings using ‘la carte’ embeddings regression, implemented Rodriguez et al (2022) Rodriguez et al (2024). case study, demonstrate use conText package alongside embedding frameworks working example provided Rodriguez et al.’s Quick Start Guide. ConText includes cross-lingual ALC Embeddings, tutorial extends capabilities integrating flaiR. tutorial integration, tutorial shows : Access flaiR’s powerful embedding models Connect transformer-based embedding models HuggingFace via FlaiR following example directly Rodriguez et al.’s Quick Start Guide case study. ’s important note results obtained using alternative embedding frameworks may deviate original implementation, interpreted caution. comparative results primarily intended reference educational use. First , loading conText package, ’ll find three pre-loaded datasets: cr_sample_corpus, cr_glove_subset, cr_transform. datasets used package’s tutorial demonstrate preprocessing steps. exercise, use cr_sample_corpus explore embedding frameworks, including: en-crawl embedding Flair NLP contextual embeddings (described Akbik et al., COLING 2018 paper) Integrated embeddings extracted transformers like BERT.","code":""},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"build-document-embedding-matrix-with-other-embedding-frameworks","dir":"Articles","previous_headings":"Extending conText’s Embedding Regression","what":"Build Document-Embedding-Matrix with Other Embedding Frameworks","title":"Tutorial","text":"Step 1 Tokenize Text quanteda conText First, let’s tokenize cr_sample_corpus using tokens_context function conText package. Step 2 Import Embedding Tools facilitate loading different embedding types, ’ll import following classes functions flaiR: WordEmbeddings, FlairEmbeddings, TransformerWordEmbeddings, StackedEmbeddings, Sentence. components enable us work GloVe embeddings, Flair’s contextual embeddings, transformer-based embeddings HuggingFace library. Initialize Flair Sentence object concatenating cr_glove_subset row names. collapse parameter ensures proper tokenization adding space delimiters. , embed sentence text using loaded fasttext embeddings. process_embeddings function flaiR extracts pre-embedded GloVe vectors sentence object arranges structured matrix. matrix, tokens represented rows, embedding dimensions columns, row labeled corresponding token text. Step 3 Computing Context-Specific Word Embeddings Using FastText Create feature co-occurrence matrix (FCM) tokenized text transform pre-trained FastText embeddings using co-occurrence information. Calculate Document Embedding Matrix (DEM) using transformed FastText embeddings. Show document inherits corresponding docvars. Step 4 Embedding Eegression extract D-dimensional beta coefficients. nearest neighbors","code":"# tokenize corpus removing unnecessary (i.e. semantically uninformative) elements toks <- tokens(cr_sample_corpus, remove_punct=T, remove_symbols=T, remove_numbers=T, remove_separators=T) #> Warning in (function (n) : input string '# #> # Copyright (C) 2016 and later: Unicode, Inc. and others. #> # License & terms of use: http://www.unicode.org/copyright.html #> # Copyright (C) 2002-2016, International Business Machines Corporation #> # and others. All Rights Reserved. #> # #> # file:  word.txt #> # #> # ICU Word Break Rules #> #      See Unicode Standard Annex #29. #> #      These rules are based on UAX #29 Revision 34 for Unicode Version 12.0 #> # #> # Note:  Updates to word.txt will usually need to be merged into #> #        word_POSIX.txt and word_fi_sv.txt also. #>  #> ############################################################################## #> # #> #  Character class definitions from TR 29 #> # #> ############################################################################## #>  #> !!chain; #> !!quoted_literals_only; #>  #>  #> # #> #  Character Class Definitions. #> # #>  #> $Han                = [:Han:]; #>  #> $CR                 = [\\p{Word_Break = CR}]; #> $LF                 = [\\p{Word_Break = LF}]; #> $Newline            = [\\p{Word_Break = Newline}]; #> $Extend             = [\\p{Wor [... truncated]  # clean out stopwords and words with 2 or fewer characters toks_nostop <- tokens_select(toks, pattern = stopwords(\"en\"), selection = \"remove\", min_nchar=3)  # only use features that appear at least 5 times in the corpus feats <- dfm(toks_nostop, tolower=T, verbose = FALSE) %>% dfm_trim(min_termfreq = 5) %>% featnames()  # leave the pads so that non-adjacent words will not become adjacent toks_nostop_feats <- tokens_select(toks_nostop, feats, padding = TRUE)  # build a tokenized corpus of contexts surrounding the target term \"immigration\" immig_toks <- tokens_context(x = toks_nostop_feats, pattern = \"immigr*\", window = 6L) #> 125 instances of \"immigrant\" found. #> 288 instances of \"immigrants\" found. #> 924 instances of \"immigration\" found.  # build document-feature matrix immig_dfm <- dfm(immig_toks) # Combine all text into a single string and create a Flair sentence sentence <- Sentence(paste(rownames(cr_glove_subset), collapse = \" \"))  # Apply FastText embeddings to the sentence fasttext_embeddings$embed(sentence) #> [[1]] #> Sentence[500]: \"people bill immigration president can american country law states one united speaker time going just now senate years want congress work get border know said make security many think act need children today come house also americans like year dont say america new state take way jobs senator federal government first back even amendment important well legislation support right women reform colleagues million committee laws system percent vote floor last every nation program made issue care immigrants see department national health world good republican families court workers executive administration much help illegal enforcement republicans thank fact members working number opportunity thats believe pass great never legal obama homeland money family across two put look process came may violence order give rule job done able pay must day economy home community budget tax public without passed things better since majority texas let justice another hope policy lets provide debate history ago sure presidents action week young actually nations amendments bipartisan says long issues comprehensive next something place life doesnt thing lot point chairman economic business leadership service constitution tell status dream cant yield future office billion visa find military still member talk together school rights continue part madam amnesty days secure bring best yet lives democrats broken times side nothing ask protect allow problem around making clear body foreign communities including coming use rise simply heard forward end programs leader already saying individuals general power funding case whether debt course keep question worked needs washington war change got address secretary parents little least hard three citizens different education judiciary ever strong immigrant always means current report child less really services political given increase might enough create countries domestic human supreme authority brought reason kind past become aliens understand millions judge enforce benefits constitutional high stand others criminal serve stop middle real matter talking makes someone proud month safety line used college live didnt class called call far borders victims ensure district thousands california taxes rules obamacare deal goes representatives took insurance spending companies actions small instead read resources friends mexico seen illegally policies trying labor party example crisis bills votes ice special wage went taken men asked told comes serious maybe students businesses getting words group chamber senators taking leaders wish dollars citizenship sense problems close information social friend stay offer record away months set urge person minimum democratic cost local voted numbers join energy served happen aisle found congressional wanted according plan kids try chance major almost powers trade undocumented critical poverty start article single left certainly cases access patrol individual honor remember income attorney within officers wrong speak company second hundreds impact created hours respect arizona though move hearing employees gentleman anyone along known meet chair full southern big trillion level four ability experience face provisions man provides fix open theyre efforts asian university decision groups industry allowed higher often agree white visas held upon path certain share isnt looking employers consider colleague average woman anything however balance former city interest control crime weeks free gone unemployment idea true\" fasttext_subset <- process_embeddings(sentence, verbose = TRUE) #> Extracting token embeddings... #> Converting embeddings to matrix format...Processing completed in 3.535 seconds #> Generated embedding matrix with 500 tokens and 300 dimensions # Create a feature co-occurrence matrix (FCM) from tokenized text toks_fcm <- fcm(toks_nostop_feats,                  context = \"window\",                     window = 6,                             count = \"frequency\",                    tri = FALSE)             # Transform pre-trained Glove embeddings using co-occurrence information ft_transform <- compute_transform(     x = toks_fcm,                         pre_trained = fasttext_subset,             weighting = 'log'                 ) # Calculate Document Embedding Matrix (DEM) using transformed FastText embeddings immig_dem_ft <- dem(x = immig_dfm,                      pre_trained = fasttext_subset,                      transform = TRUE,                      transform_matrix = ft_transform,                      verbose = TRUE) head(immig_dem_ft@docvars) #>       pattern party gender nominate_dim1 #> 1  immigrants     D      F        -0.759 #> 2 immigration     D      F        -0.402 #> 3   immigrant     D      F        -0.402 #> 4   immigrant     D      F        -0.402 #> 5   immigrant     D      F        -0.402 #> 6 immigration     D      F        -0.402 set.seed(2021L) library(conText) ft_model <- conText(formula = immigration ~ party + gender,                     data = toks_nostop_feats,                     pre_trained = fasttext_subset,                     transform = TRUE,                      transform_matrix = ft_transform,                      confidence_level = 0.95,                     permute = TRUE,                      jackknife = TRUE,                     num_permutations = 100,                     window = 6, case_insensitive = TRUE,                     verbose = FALSE) #> Note: These values are not regression coefficients. Check out the Quick Start Guide for help with interpretation:  #> https://github.com/prodriguezsosa/conText/blob/master/vignettes/quickstart.md #>  #>   coefficient normed.estimate std.error  lower.ci upper.ci p.value #> 1     party_R        1.169415 0.1589605 0.8574491 1.481381       0 #> 2    gender_M        0.837367 0.1433172 0.5561016 1.118632       0 # The intercept in this case is the fastext embedding for female Democrats # beta coefficients can be combined to get each group's fastext embedding DF_wv <- ft_model['(Intercept)',]  # (D)emocrat - (F)emale  DM_wv <- ft_model['(Intercept)',] + ft_model['gender_M',] # (D)emocrat - (M)ale  RF_wv <- ft_model['(Intercept)',] + ft_model['party_R',]  # (R)epublican - (F)emale  RM_wv <- ft_model['(Intercept)',] + ft_model['party_R',] + ft_model['gender_M',] # (R)epublican - (M)ale nns(rbind(DF_wv,DM_wv),      N = 10,      pre_trained = fasttext_subset,      candidates = ft_model@features) #> $DM_wv #> # A tibble: 10 × 4 #>    target feature      rank value #>    <chr>  <chr>       <int> <dbl> #>  1 DM_wv  immigration     1 0.850 #>  2 DM_wv  immigrants      2 0.746 #>  3 DM_wv  immigrant       3 0.698 #>  4 DM_wv  education       4 0.589 #>  5 DM_wv  government      5 0.587 #>  6 DM_wv  legislation     6 0.579 #>  7 DM_wv  city            7 0.569 #>  8 DM_wv  law             8 0.566 #>  9 DM_wv  reform          9 0.559 #> 10 DM_wv  citizenship    10 0.557 #>  #> $DF_wv #> # A tibble: 10 × 4 #>    target feature      rank value #>    <chr>  <chr>       <int> <dbl> #>  1 DF_wv  immigration     1 0.779 #>  2 DF_wv  immigrants      2 0.667 #>  3 DF_wv  immigrant       3 0.620 #>  4 DF_wv  education       4 0.574 #>  5 DF_wv  government      5 0.556 #>  6 DF_wv  economic        6 0.551 #>  7 DF_wv  citizenship     7 0.549 #>  8 DF_wv  legislation     8 0.540 #>  9 DF_wv  issues          9 0.531 #> 10 DF_wv  laws           10 0.530 library(ggplot2) ggplot(ft_model@normed_coefficients, aes(x = coefficient, y = normed.estimate)) +   geom_errorbar(aes(ymin = lower.ci, ymax = upper.ci), width = 0.2) +   geom_point(size = 3) +   geom_hline(yintercept = 0, linetype = \"dashed\", color = \"gray50\") +   theme_minimal() +   labs(     title = \"Estimated Coefficients with 95% CIs\",     x = \"Variables\",     y = \"Normalized Estimate\"   ) +   theme(axis.text.x = element_text(angle = 45, hjust = 1))"},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"exploring-document-embedding-matrix-with-context-functions","dir":"Articles","previous_headings":"Extending conText’s Embedding Regression","what":"Exploring Document-Embedding Matrix with conText Functions","title":"Tutorial","text":"Check dimensions resulting matrix. get group-specific embeddings, average within party Find nearest neighbors party check results Republican. check results Democrat compute cosine similarity party’s embedding specific set features compute cosine similarity party’s embedding specific set features. compute cosine similarity party’s embedding set tokenized contexts","code":"# Calculate average document embeddings for immigration-related texts immig_wv_ft <- matrix(colMeans(immig_dem_ft),                     ncol = ncol(immig_dem_ft)) %>%  `rownames<-`(\"immigration\") dim(immig_wv_ft) #> [1]   1 300 immig_wv_ft_party <- dem_group(immig_dem_ft,                                 groups = immig_dem_ft@docvars$party) dim(immig_wv_ft_party) #> [1]   2 300 # find nearest neighbors by party # setting as_list = FALSE combines each group's results into a single tibble (useful for joint plotting) immig_nns_ft <- nns(immig_wv_ft_party,                      pre_trained = fasttext_subset,                      N = 5,                      candidates = immig_wv_ft_party@features,                      as_list = TRUE) immig_nns_ft[[\"R\"]] #> # A tibble: 5 × 4 #>   target feature      rank value #>   <chr>  <chr>       <int> <dbl> #> 1 R      immigration     1 0.837 #> 2 R      immigrants      2 0.779 #> 3 R      immigrant       3 0.721 #> 4 R      government      4 0.590 #> 5 R      laws            5 0.588 immig_nns_ft[[\"D\"]] #> # A tibble: 5 × 4 #>   target feature      rank value #>   <chr>  <chr>       <int> <dbl> #> 1 D      immigration     1 0.849 #> 2 D      immigrants      2 0.817 #> 3 D      immigrant       3 0.764 #> 4 D      education       4 0.621 #> 5 D      families        5 0.612 cos_sim(immig_wv_ft_party,          pre_trained = fasttext_subset,          features = c('reform', 'enforcement'), as_list = FALSE) #>   target     feature     value #> 1      D      reform 0.5306484 #> 2      R      reform 0.5425264 #> 3      D enforcement 0.5102908 #> 4      R enforcement 0.5647015 # Republican nns_ratio(x = immig_wv_ft_party,            N = 15,            numerator = \"R\",            candidates = immig_wv_ft_party@features,            pre_trained = fasttext_subset,            verbose = FALSE) #>        feature     value #> 1       coming 1.3142709 #> 2       things 1.2022012 #> 3    political 1.1506919 #> 4  enforcement 1.1066269 #> 5       aliens 1.0194435 #> 6       issues 1.0124816 #> 7   government 0.9908574 #> 8        visas 0.9904320 #> 9         laws 0.9874748 #> 10 immigration 0.9849872 #> 11 legislation 0.9666258 #> 12  immigrants 0.9526017 #> 13 citizenship 0.9524804 #> 14   education 0.9448045 #> 15   immigrant 0.9435372 #> 16         law 0.9222851 #> 17   community 0.8816272 #> 18    citizens 0.8722014 #> 19        city 0.8544540 #> 20    families 0.7845902 #> 21 communities 0.7798629 # Democrat nns_ratio(x = immig_wv_ft_party,            N = 15,            numerator = \"D\",            candidates = immig_wv_ft_party@features,            pre_trained = fasttext_subset,            verbose = FALSE) #>        feature     value #> 1  communities 1.2822766 #> 2     families 1.2745507 #> 3         city 1.1703380 #> 4     citizens 1.1465242 #> 5    community 1.1342663 #> 6          law 1.0842634 #> 7    immigrant 1.0598416 #> 8    education 1.0584201 #> 9  citizenship 1.0498903 #> 10  immigrants 1.0497567 #> 11 legislation 1.0345265 #> 12 immigration 1.0152416 #> 13        laws 1.0126841 #> 14       visas 1.0096605 #> 15  government 1.0092270 #> 16      issues 0.9876722 #> 17      aliens 0.9809273 #> 18 enforcement 0.9036469 #> 19   political 0.8690423 #> 20      things 0.8318075 #> 21      coming 0.7608781 immig_ncs <- ncs(x = immig_wv_ft_party,                   contexts_dem = immig_dem_ft,                   contexts = immig_toks,                   N = 5,                   as_list = TRUE)  # nearest contexts to Republican embedding of target term # note, these may included contexts originating from Democrat speakers immig_ncs[[\"R\"]] #> # A tibble: 5 × 4 #>   target context                                                rank value #>   <chr>  <chr>                                                 <int> <dbl> #> 1 R      reminded difficult achieve consensus issues reform s…     1 0.536 #> 2 R      laws last years eight states adopted enforcement mea…     2 0.496 #> 3 R      well exactly right way stop illegal reducing demand …     3 0.492 #> 4 R      speeches border enforcement speeches stopping illega…     4 0.482 #> 5 R      welcome legal immigrants legal process illegal simpl…     5 0.472 immig_ncs[[\"D\"]] #> # A tibble: 5 × 4 #>   target context                                                rank value #>   <chr>  <chr>                                                 <int> <dbl> #> 1 D      heritage principles demand courage reform broken sys…     1 0.571 #> 2 D      speaker almost year since twothirds comprehensive re…     2 0.562 #> 3 D      senate accepted indeed need thorough comprehensive r…     3 0.562 #> 4 D      state union consideration bill provide comprehensive…     4 0.536 #> 5 D      cover house republican failure bring comprehensive r…     5 0.534"},{"path":[]},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"build-a-la-carte-document-embedding-matrix","dir":"Articles","previous_headings":"Extending conText’s Embedding Regression > Comparative Analysis of A La Carte, Flair Stacked, and BERT Embeddings","what":"Build A La Carte Document-Embedding-Matrix","title":"Tutorial","text":"","code":"# build a document-embedding-matrix immig_dem <- dem(x = immig_dfm, pre_trained = cr_glove_subset, transform = TRUE, transform_matrix = cr_transform, verbose = TRUE)  set.seed(2021L) alc_model <- conText(formula = immigration ~ party + gender,                      data = toks_nostop_feats,                      pre_trained = cr_glove_subset,                      transform = TRUE,                       transform_matrix = cr_transform,                      jackknife = TRUE,                       confidence_level = 0.95,                      permute = TRUE,                       num_permutations = 100,                      window = 6,                       case_insensitive = TRUE,                      verbose = FALSE) #> Note: These values are not regression coefficients. Check out the Quick Start Guide for help with interpretation:  #> https://github.com/prodriguezsosa/conText/blob/master/vignettes/quickstart.md #>  #>   coefficient normed.estimate std.error lower.ci upper.ci p.value #> 1     party_R        2.960860 0.2398964 2.490054 3.431665       0 #> 2    gender_M        2.303401 0.2290150 1.853950 2.752851       0"},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"document-embedding-matrix-construction-using-flair-contextual-stacked-embeddings","dir":"Articles","previous_headings":"Extending conText’s Embedding Regression > Comparative Analysis of A La Carte, Flair Stacked, and BERT Embeddings","what":"Document Embedding Matrix Construction Using Flair Contextual Stacked Embeddings","title":"Tutorial","text":"facilitate loading different embedding types, ’ll import following classes functions flaiF: WordEmbeddings, FlairEmbeddings, TransformerWordEmbeddings, StackedEmbeddings, Sentence. components enable us work GloVe embeddings, Flair’s contextual embeddings, transformer-based embeddings HuggingFace library. Combine three different types embeddings stacked embedding model. creates stacked embedding model combines: FastText embeddings: Captures general word semantics Forward Flair: Captures contextual information reading text left--right Backward Flair: Captures contextual information reading text right--left","code":"stacked_embeddings  <- StackedEmbeddings(list(   fasttext_embeddings,       flair_forward,             flair_backward         )) # Step 1: Create a Flair Sentence object from the text sentence <- Sentence(paste(rownames(cr_glove_subset), collapse = \" \"))  # Step 2: Generate embeddings using our stacked model stacked_embeddings$embed(sentence)  # Step 3: Extract and store embeddings for each token stacked_subset <- process_embeddings(sentence, verbose = TRUE) #> Extracting token embeddings... #> Converting embeddings to matrix format...Processing completed in 3.203 seconds #> Generated embedding matrix with 500 tokens and 4396 dimensions  # Step 4: Compute transformation matrix  st_transform <- compute_transform(    x = toks_fcm,                   pre_trained = stacked_subset,    weighting = 'log'           )  # Step 5: Generate document embeddings matrix immig_dem_st <- dem(    x = immig_dfm,                  pre_trained = stacked_subset,    transform = TRUE,              transform_matrix = st_transform,    verbose = TRUE              )  # Step 6: Fit conText model for analysis set.seed(2021L)                  st_model <- conText(formula = immigration ~ party + gender,                       data = toks_nostop_feats,                                     pre_trained = stacked_subset,                               transform = TRUE,                                           transform_matrix = st_transform,                            jackknife = TRUE,                                           confidence_level = 0.95,                                  permute = TRUE,                                           num_permutations = 100,                                    window = 6,                                               case_insensitive = TRUE,                                   verbose = FALSE) #> Note: These values are not regression coefficients. Check out the Quick Start Guide for help with interpretation:  #> https://github.com/prodriguezsosa/conText/blob/master/vignettes/quickstart.md #>  #>   coefficient normed.estimate std.error  lower.ci upper.ci p.value #> 1     party_R        121.4567   96.6311 -68.18549 311.0988    0.32 #> 2    gender_M        226.2376  102.9460  24.20230 428.2730    0.07"},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"document-embedding-matrix-construction-with-bert","dir":"Articles","previous_headings":"Extending conText’s Embedding Regression > Comparative Analysis of A La Carte, Flair Stacked, and BERT Embeddings","what":"Document Embedding Matrix Construction with BERT","title":"Tutorial","text":"BERT embeddings provide powerful contextual representations bidirectional transformer architecture. embeddings good understanding context directions within text, generating deep contextual representations multiple transformer layers, leveraging pre-training large text corpora achieve strong performance across NLP tasks. classic BERT base model generates 768-dimensional embeddings token, providing rich semantic representations. utilizing Flair framework, also can seamlessly integrate: Multiple BERT variants like RoBERTa DistilBERT Cross-lingual models XLM-RoBERTa Domain-adapted BERT models transformer model available HuggingFace","code":"# Initialize BERT base uncased model embeddings from HuggingFace bert_embeddings <- TransformerWordEmbeddings('bert-base-uncased') # Step 1: Create a Flair Sentence object from the text sentence <- Sentence(paste(rownames(cr_glove_subset), collapse = \" \"))  # Step 2: Generate embeddings using BERT model from HugginFace bert_embeddings$embed(sentence) #> [[1]] #> Sentence[500]: \"people bill immigration president can american country law states one united speaker time going just now senate years want congress work get border know said make security many think act need children today come house also americans like year dont say america new state take way jobs senator federal government first back even amendment important well legislation support right women reform colleagues million committee laws system percent vote floor last every nation program made issue care immigrants see department national health world good republican families court workers executive administration much help illegal enforcement republicans thank fact members working number opportunity thats believe pass great never legal obama homeland money family across two put look process came may violence order give rule job done able pay must day economy home community budget tax public without passed things better since majority texas let justice another hope policy lets provide debate history ago sure presidents action week young actually nations amendments bipartisan says long issues comprehensive next something place life doesnt thing lot point chairman economic business leadership service constitution tell status dream cant yield future office billion visa find military still member talk together school rights continue part madam amnesty days secure bring best yet lives democrats broken times side nothing ask protect allow problem around making clear body foreign communities including coming use rise simply heard forward end programs leader already saying individuals general power funding case whether debt course keep question worked needs washington war change got address secretary parents little least hard three citizens different education judiciary ever strong immigrant always means current report child less really services political given increase might enough create countries domestic human supreme authority brought reason kind past become aliens understand millions judge enforce benefits constitutional high stand others criminal serve stop middle real matter talking makes someone proud month safety line used college live didnt class called call far borders victims ensure district thousands california taxes rules obamacare deal goes representatives took insurance spending companies actions small instead read resources friends mexico seen illegally policies trying labor party example crisis bills votes ice special wage went taken men asked told comes serious maybe students businesses getting words group chamber senators taking leaders wish dollars citizenship sense problems close information social friend stay offer record away months set urge person minimum democratic cost local voted numbers join energy served happen aisle found congressional wanted according plan kids try chance major almost powers trade undocumented critical poverty start article single left certainly cases access patrol individual honor remember income attorney within officers wrong speak company second hundreds impact created hours respect arizona though move hearing employees gentleman anyone along known meet chair full southern big trillion level four ability experience face provisions man provides fix open theyre efforts asian university decision groups industry allowed higher often agree white visas held upon path certain share isnt looking employers consider colleague average woman anything however balance former city interest control crime weeks free gone unemployment idea true\"  # Step 3: Extract and store embeddings for each token bert_subset <- process_embeddings(sentence, verbose = TRUE) #> Extracting token embeddings... #> Converting embeddings to matrix format...Processing completed in 2.833 seconds #> Generated embedding matrix with 500 tokens and 768 dimensions  # Step 4: Compute transformation matrix  bt_transform <- compute_transform(x = toks_fcm,                                        pre_trained = bert_subset,                                   weighting = 'log')  # Step 5: Generate document embeddings matrix immig_dem_bt <- dem(x = immig_dfm,                     pre_trained = bert_subset,                     transform = TRUE,                               transform_matrix = bt_transform,                     verbose = TRUE)  # Step 6: Fit conText model for analysis set.seed(2021L)                  bt_model <- conText(formula = immigration ~ party + gender,                       data = toks_nostop_feats,                                     pre_trained = bert_subset,                               transform = TRUE,                                           transform_matrix = bt_transform,                            jackknife = TRUE,                                           confidence_level = 0.95,                                  permute = TRUE,                                           num_permutations = 100,                                    window = 6,                                               case_insensitive = TRUE,                                   verbose = FALSE) #> Note: These values are not regression coefficients. Check out the Quick Start Guide for help with interpretation:  #> https://github.com/prodriguezsosa/conText/blob/master/vignettes/quickstart.md #>  #>   coefficient normed.estimate std.error  lower.ci  upper.ci p.value #> 1     party_R        356.6359  260.9005 -155.3911  868.6629    0.20 #> 2    gender_M        571.7142  276.0198   30.0149 1113.4134    0.07"},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"comparision-of-different-embedding-approaches","dir":"Articles","previous_headings":"Extending conText’s Embedding Regression > Comparative Analysis of A La Carte, Flair Stacked, and BERT Embeddings","what":"Comparision of Different Embedding Approaches","title":"Tutorial","text":"tutorial doesn’t determine definitive best approach, ’s important understand key distinctions word embedding methods. BERT, FastText, Flair Stacked Embeddings, GloVe can categorized two groups: dynamic static embeddings. Dynamic embeddings, particularly BERT Flair, adapt word representations based context using high-dimensional vector spaces (BERT uses 768 dimensions base model). BERT employs self-attention mechanisms subword tokenization, Flair uses character-level modeling. effectively handle --vocabulary words mechanisms. However, notable difference case study . provide selected words, directly extract individual word vectors BERT Flair (forward/backward) embeddings using set words. doesn’t truly utilize BERT Flair embeddings’ capability modeling context. meaningful approach extract embeddings quasi-sentence paragraph level, alternatively, pool entire document extracting embeddings. context-based approaches stand stark contrast GloVe’s methodology, relies pre-computed global word-word co-occurrence statistics generate static word vectors.   ","code":""},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"cite","dir":"Articles","previous_headings":"","what":"Cite","title":"Tutorial","text":"","code":"@Manual{,   title = {Flair NLP and flaiR for Social Science},   author = {Yen-Chieh Liao, Sohini Timbadia and Stefan Müller},   year = {2024},   url = {https://davidycliao.github.io/flaiR/articles/tutorial.html} }"},{"path":"https://davidycliao.github.io/flaiR/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Yen-Chieh Liao. Maintainer, author, contributor. Stefan Müller. Author, contributor. Sohini Timbadia. Contributor. Akbik Alan. Author, contributor. Blythe Duncan. Author, contributor. Vollgraf Roland. Author, contributor.","code":""},{"path":"https://davidycliao.github.io/flaiR/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Liao Y, Müller S, Alan , Duncan B, Roland V (2025). flaiR: R Wrapper Accessing FLAIR. R package version 0.0.7, https://davidycliao.github.io/flaiR.","code":"@Manual{,   title = {flaiR: An R Wrapper for Accessing FLAIR},   author = {Yen-Chieh Liao and Stefan Müller and Akbik Alan and Blythe Duncan and Vollgraf Roland},   year = {2025},   note = {R package version 0.0.7},   url = {https://davidycliao.github.io/flaiR}, }"},{"path":"https://davidycliao.github.io/flaiR/index.html","id":"flairr-an-r-wrapper-for-accessing-flair-nlp-library-","dir":"","previous_headings":"","what":"flairR: An R Wrapper for Accessing Flair NLP Library","title":"An R Wrapper for Accessing Flair NLP Library","text":"flaiR R package provides convenient access flairNLP/flair, powerful Python-based NLP toolkit developed Humboldt University Berlin. R package maintained Yen-Chieh Liao (University Birmingham) Stefan Müller Next Generation Energy Systems Text Policy Research Group UCD. flaiR, R users can easily utilize combine various word embeddings, train deep learning models, fine-tune latest transformer models Hugging Face, bridging advanced NLP functionality popular quantitative text analysis toolkits like quanteda R environment.","code":""},{"path":"https://davidycliao.github.io/flaiR/index.html","id":"installation-via-github","dir":"","previous_headings":"","what":"Installation via GitHub","title":"An R Wrapper for Accessing Flair NLP Library","text":"Required Softwares Python >= 3.10 R >= 4.2.0 Rstudio Operation Systems *: R 4.2.1, particularly using Matrix package ARM 64 architecture Macs (M1/M2), compatibility issues gfortran may occur. ’s recommended avoid combination.","code":"install.packages(\"remotes\") remotes::install_github(\"davidycliao/flaiR\", force = TRUE) library(flaiR) #> flaiR: An R Wrapper for Accessing Flair NLP 0.13.1"},{"path":"https://davidycliao.github.io/flaiR/index.html","id":"installation-with-docker","dir":"","previous_headings":"","what":"Installation with Docker","title":"An R Wrapper for Accessing Flair NLP Library","text":"Intel/AMD Processors: Apple Silicon (M1/M2 Mac): running commands terminal (powershell), open browser navigate http://localhost:8787 access RStudio. detailed installation instructions, please visit Quick Start Guide.","code":"# Pull image docker pull ghcr.io/davidycliao/flair-rstudio:latest # Run container docker run -p 8787:8787 ghcr.io/davidycliao/flair-rstudio:latest # Pull and run with platform specification docker pull --platform linux/amd64 ghcr.io/davidycliao/flair-rstudio:latest docker run --platform linux/amd64 -p 8787:8787 ghcr.io/davidycliao/flair-rstudio:latest"},{"path":"https://davidycliao.github.io/flaiR/index.html","id":"contribution-and-open-source","dir":"","previous_headings":"","what":"Contribution and Open Source","title":"An R Wrapper for Accessing Flair NLP Library","text":"R developers want contribute flaiR welcome – flaiR open source project. warmly invite R users share similar interests join contributing package. Please feel free shoot email us collaborate task. Contributions – whether comments, code suggestions, tutorial examples, forking repository – greatly appreciated. Please note flaiR released Contributor Code Conduct. contributing project, agree abide terms. primary communication channel R users can found . Please feel free share insights Discussion page report issues related R interface Issue section. issue pertains actual implementation Flair Python, please submit pull request offical flair NLP.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/cc_muller.html","id":null,"dir":"Reference","previous_headings":"","what":"Training Data from : The Temporal Focus of Campaign Communication (2020 JOP) — cc_muller","title":"Training Data from : The Temporal Focus of Campaign Communication (2020 JOP) — cc_muller","text":"replication data sourced \"Temporal Focus Campaign Communication,\" authored Stefan Müller, published Journal Politics 2022. study primarily delves temporal emphasis party manifestos. dataset encompasses 5,858 annotated data entries countries United Kingdom, Ireland, Canada, Australia, New Zealand, United States. central objective compute percentage sentences quasi-sentences referring past, present, future. differentiation made based two categories: \"Prospective\" \"Retrospective\".","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/cc_muller.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Training Data from : The Temporal Focus of Campaign Communication (2020 JOP) — cc_muller","text":"","code":"data(\"cc_muller\")"},{"path":"https://davidycliao.github.io/flaiR/reference/cc_muller.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Training Data from : The Temporal Focus of Campaign Communication (2020 JOP) — cc_muller","text":"data frame 7 variables: text Content text. sentence_id Unique identifier sentence. countryname Country's name. party Associated political party text. date Date record. class Type classification. class_pro_retro Classification either 'Prospective' 'Retrospective'.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/cc_muller.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Training Data from : The Temporal Focus of Campaign Communication (2020 JOP) — cc_muller","text":"Data provided author https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/7NP2XH","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/cc_muller.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Training Data from : The Temporal Focus of Campaign Communication (2020 JOP) — cc_muller","text":"","code":"if (FALSE) { # \\dontrun{ data(cc_muller) head(cc_muller) } # }"},{"path":"https://davidycliao.github.io/flaiR/reference/check_and_gc.html","id":null,"dir":"Reference","previous_headings":"","what":"Perform Garbage Collection Based on Condition — check_and_gc","title":"Perform Garbage Collection Based on Condition — check_and_gc","text":"function checks value gc.active determine whether perform garbage collection. gc.active TRUE, function perform garbage collection send message indicating completion process.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/check_and_gc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Perform Garbage Collection Based on Condition — check_and_gc","text":"","code":"check_and_gc(gc.active)"},{"path":"https://davidycliao.github.io/flaiR/reference/check_and_gc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Perform Garbage Collection Based on Condition — check_and_gc","text":"gc.active logical value indicating whether activate garbage collection.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/check_and_gc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Perform Garbage Collection Based on Condition — check_and_gc","text":"message indicating garbage collection performed gc.active TRUE. Otherwise, action taken message displayed.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/check_batch_size.html","id":null,"dir":"Reference","previous_headings":"","what":"Check the Specified Batch Size — check_batch_size","title":"Check the Specified Batch Size — check_batch_size","text":"Validates given batch size positive integer.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/check_batch_size.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check the Specified Batch Size — check_batch_size","text":"","code":"check_batch_size(batch_size)"},{"path":"https://davidycliao.github.io/flaiR/reference/check_batch_size.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check the Specified Batch Size — check_batch_size","text":"batch_size Integer. batch size checked.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/check_device.html","id":null,"dir":"Reference","previous_headings":"","what":"Check the Device for Accelerating PyTorch — check_device","title":"Check the Device for Accelerating PyTorch — check_device","text":"function verifies specified device available PyTorch. CUDA available, message shown. Additionally, system running Mac M1, MPS used instead CUDA. Checks specified device compatible current system's hardware operating system configuration, particularly Mac systems Apple M1/M2 silicon using Metal Performance Shaders (MPS).","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/check_device.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check the Device for Accelerating PyTorch — check_device","text":"","code":"check_device(device)"},{"path":"https://davidycliao.github.io/flaiR/reference/check_device.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check the Device for Accelerating PyTorch — check_device","text":"device character string specifying device type.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/check_device.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check the Device for Accelerating PyTorch — check_device","text":"PyTorch device object.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/check_device.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Check the Device for Accelerating PyTorch — check_device","text":"MPS available system meets requirements, device type MPS returned. Otherwise, CPU device used. requirements using MPS follows:\\cr Mac computers Apple silicon AMD GPUs\\cr macOS 12.3 later\\cr Python 3.7 later\\cr Xcode command-line tools installed (xcode-select --install)\\cr information : https://developer.apple.com/metal/pytorch/.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/check_flair_installed.html","id":null,"dir":"Reference","previous_headings":"","what":"Check Flair — check_flair_installed","title":"Check Flair — check_flair_installed","text":"Determines Flair Python module available current Python environment.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/check_flair_installed.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check Flair — check_flair_installed","text":"","code":"check_flair_installed(...)"},{"path":"https://davidycliao.github.io/flaiR/reference/check_flair_installed.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check Flair — check_flair_installed","text":"Logical. TRUE Flair installed, otherwise FALSE.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/check_language_supported.html","id":null,"dir":"Reference","previous_headings":"","what":"Check the Given Language Models against Supported Languages Models — check_language_supported","title":"Check the Given Language Models against Supported Languages Models — check_language_supported","text":"function checks whether provided language supported. , stops execution returns message indicating supported languages.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/check_language_supported.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check the Given Language Models against Supported Languages Models — check_language_supported","text":"","code":"check_language_supported(language, supported_lan_models)"},{"path":"https://davidycliao.github.io/flaiR/reference/check_language_supported.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check the Given Language Models against Supported Languages Models — check_language_supported","text":"language language check. supported_lan_models vector supported languages.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/check_language_supported.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check the Given Language Models against Supported Languages Models — check_language_supported","text":"function return anything, stops execution check fails.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/check_language_supported.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check the Given Language Models against Supported Languages Models — check_language_supported","text":"","code":"# Assuming 'en' is a supported language and 'abc' is not: check_language_supported(\"en\", c(\"en\", \"de\", \"fr\")) # check_language_supported(\"abc\", c(\"en\", \"de\", \"fr\")) # will stop execution"},{"path":"https://davidycliao.github.io/flaiR/reference/check_prerequisites.html","id":null,"dir":"Reference","previous_headings":"","what":"Check Environment Pre-requisites — check_prerequisites","title":"Check Environment Pre-requisites — check_prerequisites","text":"function checks Python installed, flair module available Python, active internet connection.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/check_prerequisites.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check Environment Pre-requisites — check_prerequisites","text":"","code":"check_prerequisites(...)"},{"path":"https://davidycliao.github.io/flaiR/reference/check_prerequisites.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check Environment Pre-requisites — check_prerequisites","text":"... passing additional arguments.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/check_prerequisites.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check Environment Pre-requisites — check_prerequisites","text":"message detailing missing pre-requisites.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/check_python_installed.html","id":null,"dir":"Reference","previous_headings":"","what":"Check for Available Python Installation — check_python_installed","title":"Check for Available Python Installation — check_python_installed","text":"function checks environment installed R system.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/check_python_installed.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check for Available Python Installation — check_python_installed","text":"","code":"check_python_installed(...)"},{"path":"https://davidycliao.github.io/flaiR/reference/check_python_installed.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check for Available Python Installation — check_python_installed","text":"... param run.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/check_python_installed.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check for Available Python Installation — check_python_installed","text":"Logical. TRUE Python installed, FALSE otherwise. Additionally, installed, path Python installation printed.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/check_show.text_id.html","id":null,"dir":"Reference","previous_headings":"","what":"Check the show.text_id Parameter — check_show.text_id","title":"Check the show.text_id Parameter — check_show.text_id","text":"Validates given show.text_id logical value.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/check_show.text_id.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check the show.text_id Parameter — check_show.text_id","text":"","code":"check_show.text_id(show.text_id)"},{"path":"https://davidycliao.github.io/flaiR/reference/check_show.text_id.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check the show.text_id Parameter — check_show.text_id","text":"show.text_id Logical. parameter checked.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/check_tagger.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if Tagger is Valid — check_tagger","title":"Check if Tagger is Valid — check_tagger","text":"Internal function verify provided tagger valid required methods.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/check_tagger.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if Tagger is Valid — check_tagger","text":"","code":"check_tagger(tagger)"},{"path":"https://davidycliao.github.io/flaiR/reference/check_tagger.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check if Tagger is Valid — check_tagger","text":"tagger Flair tagger object check","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/check_tagger.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check if Tagger is Valid — check_tagger","text":"Logical indicating tagger valid","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/check_texts_and_ids.html","id":null,"dir":"Reference","previous_headings":"","what":"Check the texts and document IDs — check_texts_and_ids","title":"Check the texts and document IDs — check_texts_and_ids","text":"Validates given texts document IDs NULL empty.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/check_texts_and_ids.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check the texts and document IDs — check_texts_and_ids","text":"","code":"check_texts_and_ids(texts, doc_ids)"},{"path":"https://davidycliao.github.io/flaiR/reference/check_texts_and_ids.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check the texts and document IDs — check_texts_and_ids","text":"texts List. list texts. doc_ids List. list document IDs.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/clear_flair_cache.html","id":null,"dir":"Reference","previous_headings":"","what":"Clear Flair Cache — clear_flair_cache","title":"Clear Flair Cache — clear_flair_cache","text":"function clears cache associated Flair Python library. cache directory typically located \"~/.flair\".","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/clear_flair_cache.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Clear Flair Cache — clear_flair_cache","text":"","code":"clear_flair_cache(...)"},{"path":"https://davidycliao.github.io/flaiR/reference/clear_flair_cache.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Clear Flair Cache — clear_flair_cache","text":"... argument passed next.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/clear_flair_cache.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Clear Flair Cache — clear_flair_cache","text":"Returns NULL invisibly. Messages printed indicating whether cache found cleared.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/clear_flair_cache.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Clear Flair Cache — clear_flair_cache","text":"","code":"if (FALSE) { # \\dontrun{ clear_flair_cache() } # }"},{"path":"https://davidycliao.github.io/flaiR/reference/de_immigration.html","id":null,"dir":"Reference","previous_headings":"","what":"German Bundestag Immigration Debate Data — de_immigration","title":"German Bundestag Immigration Debate Data — de_immigration","text":"dataset containing speeches debates German Bundestag topic immigration.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/de_immigration.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"German Bundestag Immigration Debate Data — de_immigration","text":"","code":"data(\"de_immigration\")"},{"path":"https://davidycliao.github.io/flaiR/reference/de_immigration.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"German Bundestag Immigration Debate Data — de_immigration","text":"data frame 16 variables: date Date speech, Date type agenda Agenda subject speech, character speechnumber Unique identifier speech, numeric speaker Name person giving speech, character party Political party speaker, character party.facts.id ID party, usually numeric character chair Person chairing session, character terms Terms tags associated speech, character list text Actual text speech, character parliament Bundestag session, character numeric iso3country ISO3 country code Germany, character year Year speech made, numeric agenda_ID Unique identifier agenda, usually numeric character migration_dummy Dummy variable related migration topic, usually numeric (0 1) comment_agenda Additional comments agenda, character","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/de_immigration.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"German Bundestag Immigration Debate Data — de_immigration","text":"Data collected ParSpeechV2 House Commons year 2010. dataset publicly available https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/L4OAKN.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/de_immigration.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"German Bundestag Immigration Debate Data — de_immigration","text":"","code":"if (FALSE) { # \\dontrun{ data(de_immigration) head(de_immigration) } # }"},{"path":"https://davidycliao.github.io/flaiR/reference/dot-onAttach.html","id":null,"dir":"Reference","previous_headings":"","what":"Install Python Dependencies and Load the flaiRnlp — .onAttach","title":"Install Python Dependencies and Load the flaiRnlp — .onAttach","text":".onAttach sets virtual environment, checks Python availability, ensures 'flair' module installed flair_env Python.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/dot-onAttach.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Install Python Dependencies and Load the flaiRnlp — .onAttach","text":"","code":".onAttach(...)"},{"path":"https://davidycliao.github.io/flaiR/reference/dot-onAttach.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Install Python Dependencies and Load the flaiRnlp — .onAttach","text":"... character string specifying name virtual environment.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/dot-onAttach.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Install Python Dependencies and Load the flaiRnlp — .onAttach","text":"function performs following steps: Checks virtual environment specified venv exists. , creates environment. Activates virtual environment. Checks availability Python. Python available, displays error message. Checks 'flair' Python module available virtual environment. , attempts install 'flair'. installation fails, prompts user install 'flair' manually.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/embeddings_to_matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert Embeddings to Matrix — embeddings_to_matrix","title":"Convert Embeddings to Matrix — embeddings_to_matrix","text":"function takes three-dimensional array embeddings converts two-dimensional matrix based specified strategy.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/embeddings_to_matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert Embeddings to Matrix — embeddings_to_matrix","text":"","code":"embeddings_to_matrix(embeddings, strategy = \"average\")"},{"path":"https://davidycliao.github.io/flaiR/reference/embeddings_to_matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert Embeddings to Matrix — embeddings_to_matrix","text":"embeddings three-dimensional array shape (number_of_texts, number_of_words, embedding_dimension). strategy character string specifying strategy use. Options \"average\", \"concatenate\", \"max_pooling\", \"min_pooling\".","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/embeddings_to_matrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert Embeddings to Matrix — embeddings_to_matrix","text":"two-dimensional matrix transformed embeddings.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/embeddings_to_matrix.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert Embeddings to Matrix — embeddings_to_matrix","text":"","code":"if (FALSE) { # \\dontrun{ embeddings <- array(runif(10 * 5 * 3), c(10, 5, 3)) result <- embeddings_to_matrix(embeddings, strategy = \"average\") } # }"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_data.Sentence.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a Flair Sentence — flair_data.Sentence","title":"Create a Flair Sentence — flair_data.Sentence","text":"Flair powerful NLP framework leverages state---art embeddings various natural language processing tasks.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_data.Sentence.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a Flair Sentence — flair_data.Sentence","text":"","code":"flair_data.Sentence(sentence_text)"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_data.Sentence.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a Flair Sentence — flair_data.Sentence","text":"sentence_text character string converted Flair Sentence object.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_data.Sentence.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a Flair Sentence — flair_data.Sentence","text":"Flair Sentence object.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_data.Sentence.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Create a Flair Sentence — flair_data.Sentence","text":"Ensure input string language compatible intended Flair model. R, processing multiple text, can use purrr basic R functions lapply sapply.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_data.Sentence.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Create a Flair Sentence — flair_data.Sentence","text":"Python equivalent:","code":"from flair.data import Sentence sentence = Sentence(\"The quick brown fox jumps over the lazy dog.\")"},{"path":[]},{"path":"https://davidycliao.github.io/flaiR/reference/flair_data.Sentence.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a Flair Sentence — flair_data.Sentence","text":"","code":"if (FALSE) { # \\dontrun{ flair_data.Sentence(\"The quick brown fox jumps over the lazy dog.\")} # }"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Import flair.data Module — flair_data","title":"Import flair.data Module — flair_data","text":"flair.data module provides essential utilities text data processing representation Flair library. function gives access various classes utilities flair.data module, notably: BoundingBox(left, top, right, bottom): Bases: tuple (Python); list (R) left - str. Alias field number 0. top - int Alias field number 1 right - int Alias field number 2 bottom - int Alias field number 3 Sentence(text, use_tokenizer=True, language_code=None, start_position=0):Sentence list tokens used represent sentence text fragment. Sentence can imported flair_data()$Sentence via flaiR. text Union[str, List[str], List[Token]] - original string (sentence), pre-tokenized list tokens. use_tokenizer Union[bool, Tokenizer] - Specify custom tokenizer split text tokens. default flair.tokenization.SegTokTokenizer. use_tokenizer set False, flair.tokenization.SpaceTokenizer used instead. tokenizer ignored text refers pre-tokenized tokens. language_code Optional[str] - Language sentence. provided, langdetect called language_code accessed first time. start_position int - Start character offset sentence superordinate document. Span(tokens, tag=None, score=1.0): Bases: _PartOfSentence. Span slice Sentence, consisting list Tokens. Span can imported flair_data()$Span. Token(text, head_id=None, whitespace_after=1, start_position=0, sentence=None): class represents one word tokenized sentence. token may number tags. may also point head dependency tree. Token can imported flair_data()$Token via flaiR. Corpus(train=None, dev=None, test=None, name='corpus', sample_missing_splits=True): Represents collection sentences, facilitating operations like splitting train/test/development sets applying transformations. particularly useful training evaluating models custom datasets. Corpus can imported flair_data()$Corpus via flaiR. Dictionary: Represents mapping items indices. useful converting text machine-readable formats.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Import flair.data Module — flair_data","text":"","code":"flair_data()"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Import flair.data Module — flair_data","text":"Python module (flair.data). access classes utilities.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_data.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Import flair.data Module — flair_data","text":"Python reference:","code":"from flair.data import Sentence"},{"path":[]},{"path":"https://davidycliao.github.io/flaiR/reference/flair_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Import flair.data Module — flair_data","text":"","code":"if (FALSE) { # \\dontrun{ Sentence <- flair_data()$Sentence Token <- flair_data()$Token Corpus <- flair_data()$Corpus } # }"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_datasets.html","id":null,"dir":"Reference","previous_headings":"","what":"Access the flair_datasets Module from Flair — flair_datasets","title":"Access the flair_datasets Module from Flair — flair_datasets","text":"Utilizes reticulate package import flair.datasets dataset Flair's datasets Python, enabling use dataset R environment.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_datasets.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Access the flair_datasets Module from Flair — flair_datasets","text":"","code":"flair_datasets()"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_datasets.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Access the flair_datasets Module from Flair — flair_datasets","text":"Python Module(flair.datasets) Flair, can utilized NLP tasks.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_datasets.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Access the flair_datasets Module from Flair — flair_datasets","text":"Python equivalent:","code":"from flair.datasets import UD_ENGLISH corpus = UD_ENGLISH().downsample(0.1)"},{"path":[]},{"path":"https://davidycliao.github.io/flaiR/reference/flair_datasets.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Access the flair_datasets Module from Flair — flair_datasets","text":"","code":"if (FALSE) { # \\dontrun{ UD_ENGLISH <- flair_datasets()$UD_ENGLISH corpus <- UD_ENGLISH()$downsample(0.1)} # }  # print all the datasets from flair names(flair_datasets()) #>   [1] \"AGNEWS\"                           #>   [2] \"AMAZON_REVIEWS\"                   #>   [3] \"ANAT_EM\"                          #>   [4] \"AZDZ\"                             #>   [5] \"BC2GM\"                            #>   [6] \"BIOBERT_CHEMICAL_BC4CHEMD\"        #>   [7] \"BIOBERT_CHEMICAL_BC5CDR\"          #>   [8] \"BIOBERT_DISEASE_BC5CDR\"           #>   [9] \"BIOBERT_DISEASE_NCBI\"             #>  [10] \"BIOBERT_GENE_BC2GM\"               #>  [11] \"BIOBERT_GENE_JNLPBA\"              #>  [12] \"BIOBERT_SPECIES_LINNAEUS\"         #>  [13] \"BIOBERT_SPECIES_S800\"             #>  [14] \"BIONLP2013_CG\"                    #>  [15] \"BIONLP2013_PC\"                    #>  [16] \"BIOSCOPE\"                         #>  [17] \"BIOSEMANTICS\"                     #>  [18] \"BIO_INFER\"                        #>  [19] \"CDR\"                              #>  [20] \"CELL_FINDER\"                      #>  [21] \"CEMP\"                             #>  [22] \"CHEMDNER\"                         #>  [23] \"CLEANCONLL\"                       #>  [24] \"CLL\"                              #>  [25] \"COMMUNICATIVE_FUNCTIONS\"          #>  [26] \"CONLL_03\"                         #>  [27] \"CONLL_03_DUTCH\"                   #>  [28] \"CONLL_03_GERMAN\"                  #>  [29] \"CONLL_03_SPANISH\"                 #>  [30] \"CONLL_2000\"                       #>  [31] \"CRAFT\"                            #>  [32] \"CRAFT_V4\"                         #>  [33] \"CSVClassificationCorpus\"          #>  [34] \"CSVClassificationDataset\"         #>  [35] \"CTD_CHEMICALS_DICTIONARY\"         #>  [36] \"CTD_DISEASES_DICTIONARY\"          #>  [37] \"ClassificationCorpus\"             #>  [38] \"ClassificationDataset\"            #>  [39] \"ColumnCorpus\"                     #>  [40] \"ColumnDataset\"                    #>  [41] \"DECA\"                             #>  [42] \"DataLoader\"                       #>  [43] \"DataPairCorpus\"                   #>  [44] \"DataPairDataset\"                  #>  [45] \"DataTripleCorpus\"                 #>  [46] \"DataTripleDataset\"                #>  [47] \"EntityLinkingDictionary\"          #>  [48] \"FEWNERD\"                          #>  [49] \"FSU\"                              #>  [50] \"FeideggerCorpus\"                  #>  [51] \"FeideggerDataset\"                 #>  [52] \"FlairDatapointDataset\"            #>  [53] \"GELLUS\"                           #>  [54] \"GERMEVAL_2018_OFFENSIVE_LANGUAGE\" #>  [55] \"GLUE_COLA\"                        #>  [56] \"GLUE_MNLI\"                        #>  [57] \"GLUE_MRPC\"                        #>  [58] \"GLUE_QNLI\"                        #>  [59] \"GLUE_QQP\"                         #>  [60] \"GLUE_RTE\"                         #>  [61] \"GLUE_SST2\"                        #>  [62] \"GLUE_STSB\"                        #>  [63] \"GLUE_WNLI\"                        #>  [64] \"GO_EMOTIONS\"                      #>  [65] \"GPRO\"                             #>  [66] \"HUNER_CELL_LINE\"                  #>  [67] \"HUNER_CELL_LINE_CELL_FINDER\"      #>  [68] \"HUNER_CELL_LINE_CLL\"              #>  [69] \"HUNER_CELL_LINE_GELLUS\"           #>  [70] \"HUNER_CELL_LINE_JNLPBA\"           #>  [71] \"HUNER_CHEMICAL\"                   #>  [72] \"HUNER_CHEMICAL_CDR\"               #>  [73] \"HUNER_CHEMICAL_CEMP\"              #>  [74] \"HUNER_CHEMICAL_CHEBI\"             #>  [75] \"HUNER_CHEMICAL_CHEMDNER\"          #>  [76] \"HUNER_CHEMICAL_CRAFT_V4\"          #>  [77] \"HUNER_CHEMICAL_SCAI\"              #>  [78] \"HUNER_DISEASE\"                    #>  [79] \"HUNER_DISEASE_CDR\"                #>  [80] \"HUNER_DISEASE_MIRNA\"              #>  [81] \"HUNER_DISEASE_NCBI\"               #>  [82] \"HUNER_DISEASE_PDR\"                #>  [83] \"HUNER_DISEASE_SCAI\"               #>  [84] \"HUNER_DISEASE_VARIOME\"            #>  [85] \"HUNER_GENE\"                       #>  [86] \"HUNER_GENE_BC2GM\"                 #>  [87] \"HUNER_GENE_BIO_INFER\"             #>  [88] \"HUNER_GENE_CELL_FINDER\"           #>  [89] \"HUNER_GENE_CHEBI\"                 #>  [90] \"HUNER_GENE_CRAFT_V4\"              #>  [91] \"HUNER_GENE_DECA\"                  #>  [92] \"HUNER_GENE_FSU\"                   #>  [93] \"HUNER_GENE_GPRO\"                  #>  [94] \"HUNER_GENE_IEPA\"                  #>  [95] \"HUNER_GENE_JNLPBA\"                #>  [96] \"HUNER_GENE_LOCTEXT\"               #>  [97] \"HUNER_GENE_MIRNA\"                 #>  [98] \"HUNER_GENE_OSIRIS\"                #>  [99] \"HUNER_GENE_VARIOME\"               #> [100] \"HUNER_SPECIES\"                    #> [101] \"HUNER_SPECIES_CELL_FINDER\"        #> [102] \"HUNER_SPECIES_CHEBI\"              #> [103] \"HUNER_SPECIES_CRAFT_V4\"           #> [104] \"HUNER_SPECIES_LINNEAUS\"           #> [105] \"HUNER_SPECIES_LOCTEXT\"            #> [106] \"HUNER_SPECIES_MIRNA\"              #> [107] \"HUNER_SPECIES_S800\"               #> [108] \"HUNER_SPECIES_VARIOME\"            #> [109] \"HunerEntityLinkingDictionary\"     #> [110] \"IEPA\"                             #> [111] \"IMDB\"                             #> [112] \"JNLPBA\"                           #> [113] \"KEYPHRASE_INSPEC\"                 #> [114] \"KEYPHRASE_SEMEVAL2010\"            #> [115] \"KEYPHRASE_SEMEVAL2017\"            #> [116] \"LINNEAUS\"                         #> [117] \"LOCTEXT\"                          #> [118] \"MASAKHA_POS\"                      #> [119] \"MIRNA\"                            #> [120] \"MongoDataset\"                     #> [121] \"NCBI_DISEASE\"                     #> [122] \"NCBI_GENE_HUMAN_DICTIONARY\"       #> [123] \"NCBI_TAXONOMY_DICTIONARY\"         #> [124] \"NEL_ENGLISH_AIDA\"                 #> [125] \"NEL_ENGLISH_AQUAINT\"              #> [126] \"NEL_ENGLISH_IITB\"                 #> [127] \"NEL_ENGLISH_REDDIT\"               #> [128] \"NEL_ENGLISH_TWEEKI\"               #> [129] \"NEL_GERMAN_HIPE\"                  #> [130] \"NER_ARABIC_ANER\"                  #> [131] \"NER_ARABIC_AQMAR\"                 #> [132] \"NER_BASQUE\"                       #> [133] \"NER_CHINESE_WEIBO\"                #> [134] \"NER_DANISH_DANE\"                  #> [135] \"NER_ENGLISH_MOVIE_COMPLEX\"        #> [136] \"NER_ENGLISH_MOVIE_SIMPLE\"         #> [137] \"NER_ENGLISH_PERSON\"               #> [138] \"NER_ENGLISH_RESTAURANT\"           #> [139] \"NER_ENGLISH_SEC_FILLINGS\"         #> [140] \"NER_ENGLISH_STACKOVERFLOW\"        #> [141] \"NER_ENGLISH_TWITTER\"              #> [142] \"NER_ENGLISH_WEBPAGES\"             #> [143] \"NER_ENGLISH_WIKIGOLD\"             #> [144] \"NER_ENGLISH_WNUT_2020\"            #> [145] \"NER_ESTONIAN_NOISY\"               #> [146] \"NER_FINNISH\"                      #> [147] \"NER_GERMAN_BIOFID\"                #> [148] \"NER_GERMAN_EUROPARL\"              #> [149] \"NER_GERMAN_GERMEVAL\"              #> [150] \"NER_GERMAN_LEGAL\"                 #> [151] \"NER_GERMAN_MOBIE\"                 #> [152] \"NER_GERMAN_POLITICS\"              #> [153] \"NER_HIPE_2022\"                    #> [154] \"NER_HUNGARIAN\"                    #> [155] \"NER_ICDAR_EUROPEANA\"              #> [156] \"NER_ICELANDIC\"                    #> [157] \"NER_JAPANESE\"                     #> [158] \"NER_MASAKHANE\"                    #> [159] \"NER_MULTI_CONER\"                  #> [160] \"NER_MULTI_CONER_V2\"               #> [161] \"NER_MULTI_WIKIANN\"                #> [162] \"NER_MULTI_WIKINER\"                #> [163] \"NER_MULTI_XTREME\"                 #> [164] \"NER_NERMUD\"                       #> [165] \"NER_NOISEBENCH\"                   #> [166] \"NER_SWEDISH\"                      #> [167] \"NER_TURKU\"                        #> [168] \"NER_UKRAINIAN\"                    #> [169] \"NEWSGROUPS\"                       #> [170] \"ONTONOTES\"                        #> [171] \"OSIRIS\"                           #> [172] \"OcrJsonDataset\"                   #> [173] \"OpusParallelCorpus\"               #> [174] \"PDR\"                              #> [175] \"ParallelTextCorpus\"               #> [176] \"ParallelTextDataset\"              #> [177] \"RE_ENGLISH_CONLL04\"               #> [178] \"RE_ENGLISH_DRUGPROT\"              #> [179] \"RE_ENGLISH_SEMEVAL2010\"           #> [180] \"RE_ENGLISH_TACRED\"                #> [181] \"S800\"                             #> [182] \"SCAI_CHEMICALS\"                   #> [183] \"SCAI_DISEASE\"                     #> [184] \"SENTEVAL_CR\"                      #> [185] \"SENTEVAL_MPQA\"                    #> [186] \"SENTEVAL_MR\"                      #> [187] \"SENTEVAL_SST_BINARY\"              #> [188] \"SENTEVAL_SST_GRANULAR\"            #> [189] \"SENTEVAL_SUBJ\"                    #> [190] \"SENTIMENT_140\"                    #> [191] \"SROIE\"                            #> [192] \"STACKOVERFLOW\"                    #> [193] \"SUPERGLUE_RTE\"                    #> [194] \"SentenceDataset\"                  #> [195] \"StringDataset\"                    #> [196] \"TREC_50\"                          #> [197] \"TREC_6\"                           #> [198] \"UD_AFRIKAANS\"                     #> [199] \"UD_ANCIENT_GREEK\"                 #> [200] \"UD_ARABIC\"                        #> [201] \"UD_ARMENIAN\"                      #> [202] \"UD_BASQUE\"                        #> [203] \"UD_BAVARIAN_MAIBAAM\"              #> [204] \"UD_BELARUSIAN\"                    #> [205] \"UD_BULGARIAN\"                     #> [206] \"UD_BURYAT\"                        #> [207] \"UD_CATALAN\"                       #> [208] \"UD_CHINESE\"                       #> [209] \"UD_CHINESE_KYOTO\"                 #> [210] \"UD_COPTIC\"                        #> [211] \"UD_CROATIAN\"                      #> [212] \"UD_CZECH\"                         #> [213] \"UD_DANISH\"                        #> [214] \"UD_DUTCH\"                         #> [215] \"UD_ENGLISH\"                       #> [216] \"UD_ESTONIAN\"                      #> [217] \"UD_FAROESE\"                       #> [218] \"UD_FINNISH\"                       #> [219] \"UD_FRENCH\"                        #> [220] \"UD_GALICIAN\"                      #> [221] \"UD_GERMAN\"                        #> [222] \"UD_GERMAN_HDT\"                    #> [223] \"UD_GOTHIC\"                        #> [224] \"UD_GREEK\"                         #> [225] \"UD_HEBREW\"                        #> [226] \"UD_HINDI\"                         #> [227] \"UD_INDONESIAN\"                    #> [228] \"UD_IRISH\"                         #> [229] \"UD_ITALIAN\"                       #> [230] \"UD_JAPANESE\"                      #> [231] \"UD_KAZAKH\"                        #> [232] \"UD_KOREAN\"                        #> [233] \"UD_LATIN\"                         #> [234] \"UD_LATVIAN\"                       #> [235] \"UD_LITHUANIAN\"                    #> [236] \"UD_LIVVI\"                         #> [237] \"UD_MALTESE\"                       #> [238] \"UD_MARATHI\"                       #> [239] \"UD_NAIJA\"                         #> [240] \"UD_NORTH_SAMI\"                    #> [241] \"UD_NORWEGIAN\"                     #> [242] \"UD_OLD_CHURCH_SLAVONIC\"           #> [243] \"UD_OLD_FRENCH\"                    #> [244] \"UD_PERSIAN\"                       #> [245] \"UD_POLISH\"                        #> [246] \"UD_PORTUGUESE\"                    #> [247] \"UD_ROMANIAN\"                      #> [248] \"UD_RUSSIAN\"                       #> [249] \"UD_SERBIAN\"                       #> [250] \"UD_SLOVAK\"                        #> [251] \"UD_SLOVENIAN\"                     #> [252] \"UD_SPANISH\"                       #> [253] \"UD_SWEDISH\"                       #> [254] \"UD_TURKISH\"                       #> [255] \"UD_UKRAINIAN\"                     #> [256] \"UD_WOLOF\"                         #> [257] \"UP_CHINESE\"                       #> [258] \"UP_ENGLISH\"                       #> [259] \"UP_FINNISH\"                       #> [260] \"UP_FRENCH\"                        #> [261] \"UP_GERMAN\"                        #> [262] \"UP_ITALIAN\"                       #> [263] \"UP_SPANISH\"                       #> [264] \"UP_SPANISH_ANCORA\"                #> [265] \"UniversalDependenciesCorpus\"      #> [266] \"UniversalDependenciesDataset\"     #> [267] \"VARIOME\"                          #> [268] \"WASSA_ANGER\"                      #> [269] \"WASSA_FEAR\"                       #> [270] \"WASSA_JOY\"                        #> [271] \"WASSA_SADNESS\"                    #> [272] \"WNUT_17\"                          #> [273] \"WSD_MASC\"                         #> [274] \"WSD_OMSTI\"                        #> [275] \"WSD_RAGANATO_ALL\"                 #> [276] \"WSD_SEMCOR\"                       #> [277] \"WSD_TRAINOMATIC\"                  #> [278] \"WSD_UFSAC\"                        #> [279] \"WSD_WORDNET_GLOSS_TAGGED\"         #> [280] \"YAHOO_ANSWERS\"                    #> [281] \"ZELDA\"                            #> [282] \"base\"                             #> [283] \"biomedical\"                       #> [284] \"document_classification\"          #> [285] \"entity_linking\"                   #> [286] \"ocr\"                              #> [287] \"relation_extraction\"              #> [288] \"sequence_labeling\"                #> [289] \"text_image\"                       #> [290] \"text_text\"                        #> [291] \"treebanks\""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_device.html","id":null,"dir":"Reference","previous_headings":"","what":"Set Flair Device — flair_device","title":"Set Flair Device — flair_device","text":"function sets device Flair Python library. allows set device use CPU, GPU (coda:0, coda:1, coda:3), specific MPS devices Mac (mps:0, mps:1, mps:2).","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_device.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set Flair Device — flair_device","text":"","code":"flair_device(device = \"cpu\")"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_device.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set Flair Device — flair_device","text":"device character string specifying device. Valid options include: \"cpu\", \"cuda\", \"mps:0\", \"mps:1\", \"mps:2\", etc.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_device.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set Flair Device — flair_device","text":"set device Flair.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_device.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set Flair Device — flair_device","text":"","code":"if (FALSE) { # \\dontrun{ flair_device(\"cpu\")    # Set device to CPU flair_device(\"cuda\")   # Set device to GPU (if available) flair_device(\"mps:0\")  # Set device to MPS device 0 (if available on Mac) } # }"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_embeddings.FlairEmbeddings.html","id":null,"dir":"Reference","previous_headings":"","what":"Initializing a Class for Flair's Forward and Backward Embeddings — flair_embeddings.FlairEmbeddings","title":"Initializing a Class for Flair's Forward and Backward Embeddings — flair_embeddings.FlairEmbeddings","text":"function initializes Flair embeddings flair.embeddings module.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_embeddings.FlairEmbeddings.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Initializing a Class for Flair's Forward and Backward Embeddings — flair_embeddings.FlairEmbeddings","text":"","code":"flair_embeddings.FlairEmbeddings(embeddings_type = \"news-forward\")"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_embeddings.FlairEmbeddings.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Initializing a Class for Flair's Forward and Backward Embeddings — flair_embeddings.FlairEmbeddings","text":"embeddings_type character string specifying type embeddings initialize. Options include: \"news-forward\", \"news-backward\".","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_embeddings.FlairEmbeddings.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Initializing a Class for Flair's Forward and Backward Embeddings — flair_embeddings.FlairEmbeddings","text":"Flair embeddings class flair.embeddings module.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_embeddings.FlairEmbeddings.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Initializing a Class for Flair's Forward and Backward Embeddings — flair_embeddings.FlairEmbeddings","text":"Multi-Language Embeddings: multi-X: Supports 300+ languages, sourced JW300 corpus. JW300 corpus, proposed Agić Vulić (2019). corpus licensed CC--NC-SA. multi-X-fast: CPU-friendly version, trained mix corpora languages like English, German, French, Italian, Dutch, Polish. English Embeddings: 'news-X': Trained 1 billion word corpus 'news-X-fast': Trained 1 billion word corpus, CPU-friendly. 'mix-X': Trained mixed corpus (Web, Wikipedia, Subtitles) 'pubmed-X': Added @jessepeng: Trained 5% PubMed abstracts 2015 (1150 hidden states, 3 layers) Specific Langauge Embeddings: 'de-X': German. Trained mixed corpus (Web, Wikipedia, Subtitles) de-historic-ha-X: German (historical). Added @stefan-: Historical German trained Hamburger Anzeiger. de-historic-wz-X: German (historical). Added @stefan-: Historical German trained Wiener Zeitung. de-historic-rw-X: German (historical). Added @redewiedergabe: Historical German trained 100 million tokens de-impresso-hipe-v1-X: -domain data CLEF HIPE Shared task. -domain data (Swiss Luxembourgish newspapers) CLEF HIPE Shared task. information shared task can found paper. '-X': Norwegian. Added @stefan-: Trained Wikipedia/OPUS. 'nl-X': Dutch. Added @stefan-: Trained Wikipedia/OPUS 'nl-v0-X': Dutch.Added @stefan-: LM embeddings (earlier version) 'ja-X': Japanese. Added @frtacoa: Trained 439M words Japanese Web crawls (2048 hidden states, 2 layers) 'ja-X': Japanese. Added @frtacoa: Trained 439M words Japanese Web crawls (2048 hidden states, 2 layers) 'fi-X': Finnish. Added @stefan-: Trained Wikipedia/OPUS. 'fr-X': French. Added @mhham: Trained French Wikipedia Japanese Web crawls (2048 hidden states, 2 layers) Domain-Specific Embeddings: 'es-clinical-': Spanish (clinical). Added @matirojasg: Trained Wikipedia 'pubmed-X':English.  Added @jessepeng: Trained 5% PubMed abstracts 2015 (1150 hidden states, 3 layers) examples. Ensure reference correct embedding name details application. Replace 'X' either 'forward' 'backward'. comprehensive list embeddings, please refer : Flair Embeddings Documentation.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_embeddings.FlairEmbeddings.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Initializing a Class for Flair's Forward and Backward Embeddings — flair_embeddings.FlairEmbeddings","text":"FlairEmbeddings Flair Python library. Python example usage:","code":"from flair.embeddings import FlairEmbeddings flair_embedding_forward = FlairEmbeddings('news-forward') flair_embedding_backward = FlairEmbeddings('news-backward')"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_embeddings.FlairEmbeddings.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Initializing a Class for Flair's Forward and Backward Embeddings — flair_embeddings.FlairEmbeddings","text":"","code":"if (FALSE) { # \\dontrun{ flair_embedding_forward <- flair_embeddings.FlairEmbeddings(\"news-forward\") flair_embedding_backward <- flair_embeddings.FlairEmbeddings(\"news-backward\") } # }"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_embeddings.StackedEmbeddings.html","id":null,"dir":"Reference","previous_headings":"","what":"Initializing a Class for StackedEmbeddings — flair_embeddings.StackedEmbeddings","title":"Initializing a Class for StackedEmbeddings — flair_embeddings.StackedEmbeddings","text":"Creates stacked embedding instance using multiple Flair embeddings.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_embeddings.StackedEmbeddings.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Initializing a Class for StackedEmbeddings — flair_embeddings.StackedEmbeddings","text":"","code":"flair_embeddings.StackedEmbeddings(embeddings_list)"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_embeddings.StackedEmbeddings.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Initializing a Class for StackedEmbeddings — flair_embeddings.StackedEmbeddings","text":"embeddings_list list containing Flair embedding instances.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_embeddings.StackedEmbeddings.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Initializing a Class for StackedEmbeddings — flair_embeddings.StackedEmbeddings","text":"instance StackedEmbeddings flair.embeddings module.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_embeddings.StackedEmbeddings.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Initializing a Class for StackedEmbeddings — flair_embeddings.StackedEmbeddings","text":"function ensures embedding provided list recognized Flair embedding. embeddings list recognized, function throw error.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_embeddings.StackedEmbeddings.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Initializing a Class for StackedEmbeddings — flair_embeddings.StackedEmbeddings","text":"","code":"if (FALSE) { # \\dontrun{ glove_embedding <- flair_embeddings.WordEmbeddings(\"glove\") fasttext_embedding <- flair_embeddings.WordEmbeddings(\"fasttext\") stacked_embedding <- flair_embeddings.StackedEmbeddings(list(glove_embedding, fasttext_embedding)) } # }"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_embeddings.TransformerDocumentEmbeddings.html","id":null,"dir":"Reference","previous_headings":"","what":"Initializing a Class for TransformerDocumentEmbeddings — flair_embeddings.TransformerDocumentEmbeddings","title":"Initializing a Class for TransformerDocumentEmbeddings — flair_embeddings.TransformerDocumentEmbeddings","text":"function interfaces Python via reticulate create flair_embeddings.TransformerDocumentEmbeddings object flair.embeddings module.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_embeddings.TransformerDocumentEmbeddings.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Initializing a Class for TransformerDocumentEmbeddings — flair_embeddings.TransformerDocumentEmbeddings","text":"","code":"flair_embeddings.TransformerDocumentEmbeddings(   model = \"bert-base-uncased\",   layers = \"all\",   subtoken_pooling = \"mean\",   fine_tune = FALSE,   allow_long_sentences = TRUE,   memory_efficient = NULL,   use_context = FALSE )"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_embeddings.TransformerDocumentEmbeddings.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Initializing a Class for TransformerDocumentEmbeddings — flair_embeddings.TransformerDocumentEmbeddings","text":"model character string specifying pre-trained model use. Defaults 'bert-base-uncased'. name transformer model, e.g., \"bert-base-uncased\", \"gpt2-medium\", etc. can also path pre-trained model. layers (Optional) Layers transformer model use. string specifies layers transformer model use. BERT, can specify multiple like \"1,2,3\" single layers 1. layers argument controls transformer layers used embedding. set value '-1,-2,-3,-4', top 4 layers used make embedding. set '-1', last layer used. set \"\", layers used. subtoken_pooling (Optional) Method pooling handle subtokens. determines subtokens (word pieces) pooled one embedding original token. Options 'first' (use first subtoken), 'last' (use last subtoken), 'first_last' (concatenate first last subtokens), 'mean' (average subtokens). fine_tune Logical. Indicates fine-tuning done. Defaults FALSE. allow_long_sentences Logical. Allows longer sentences processed. Defaults TRUE. certain transformer models (like BERT), maximum sequence length. default, Flair cuts sentences \\ long. option set True, Flair split long sentences smaller parts later average embeddings. memory_efficient (Optional) Enables memory efficient mode transformers. set TRUE, uses less memory, might slower. use_context Logical. Whether consider surrounding context processing step. Default FALSE.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_embeddings.TransformerDocumentEmbeddings.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Initializing a Class for TransformerDocumentEmbeddings — flair_embeddings.TransformerDocumentEmbeddings","text":"Flair TransformerWordEmbeddings Python class.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_embeddings.TransformerDocumentEmbeddings.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Initializing a Class for TransformerDocumentEmbeddings — flair_embeddings.TransformerDocumentEmbeddings","text":"function provides interface R users easily access utilize power Flair's TransformerDocumentEmbeddings. bridges gap Python's Flair library R, enabling R users leverage state---art NLP models.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_embeddings.TransformerDocumentEmbeddings.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Initializing a Class for TransformerDocumentEmbeddings — flair_embeddings.TransformerDocumentEmbeddings","text":"Python's Flair library:","code":"from flair.embeddings import TransformerDocumentEmbeddings embedding = TransformerDocumentEmbeddings('bert-base-uncased')"},{"path":[]},{"path":"https://davidycliao.github.io/flaiR/reference/flair_embeddings.TransformerDocumentEmbeddings.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Initializing a Class for TransformerDocumentEmbeddings — flair_embeddings.TransformerDocumentEmbeddings","text":"","code":"if (FALSE) { # \\dontrun{ embedding <- flair_embeddings.TransformerDocumentEmbeddings(\"bert-base-uncased\") } # }"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_embeddings.TransformerWordEmbeddings.html","id":null,"dir":"Reference","previous_headings":"","what":"Initializing a Class for TransformerWordEmbeddings — flair_embeddings.TransformerWordEmbeddings","title":"Initializing a Class for TransformerWordEmbeddings — flair_embeddings.TransformerWordEmbeddings","text":"function interfaces Python via reticulate create TransformerWordEmbeddings object object flair.embeddings module.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_embeddings.TransformerWordEmbeddings.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Initializing a Class for TransformerWordEmbeddings — flair_embeddings.TransformerWordEmbeddings","text":"","code":"flair_embeddings.TransformerWordEmbeddings(   model = \"bert-base-uncased\",   layers = \"all\",   subtoken_pooling = \"mean\",   fine_tune = FALSE,   allow_long_sentences = TRUE,   memory_efficient = NULL,   use_context = FALSE )"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_embeddings.TransformerWordEmbeddings.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Initializing a Class for TransformerWordEmbeddings — flair_embeddings.TransformerWordEmbeddings","text":"model character string specifying pre-trained model use. Defaults 'bert-base-uncased'. name transformer model, e.g., \"bert-base-uncased\", \"gpt2-medium\", etc. can also path pre-trained model. layers (Optional) Layers transformer model use. string specifies layers transformer model use. BERT, can specify multiple like \"1,2,3\" single layers 1. layers argument controls transformer layers used embedding. set value '-1,-2,-3,-4', top 4 layers used make embedding. set '-1', last layer used. set \"\", layers used. subtoken_pooling (Optional) Method pooling handle subtokens. determines subtokens (word pieces) pooled one embedding original token. Options 'first' (use first subtoken), 'last' (use last subtoken), 'first_last' (concatenate first last subtokens), 'mean' (average subtokens). fine_tune Logical. Indicates fine-tuning done. Defaults FALSE. allow_long_sentences Logical. Allows longer sentences processed. Defaults TRUE. certain transformer models (like BERT), maximum sequence length. default, Flair cuts sentences long. option set True, Flair split long sentences smaller parts later average embeddings. memory_efficient (Optional) Enables memory efficient mode transformers. set TRUE, uses less memory, might slower. use_context Logical. Whether consider surrounding context processing step. Default FALSE.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_embeddings.TransformerWordEmbeddings.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Initializing a Class for TransformerWordEmbeddings — flair_embeddings.TransformerWordEmbeddings","text":"Flair TransformerWordEmbeddings Python class.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_embeddings.TransformerWordEmbeddings.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Initializing a Class for TransformerWordEmbeddings — flair_embeddings.TransformerWordEmbeddings","text":"function provides interface R users easily access utilize power Flair's TransformerWordEmbeddings. bridges gap Python's Flair library R, enabling R users leverage state---art NLP models.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_embeddings.TransformerWordEmbeddings.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Initializing a Class for TransformerWordEmbeddings — flair_embeddings.TransformerWordEmbeddings","text":"Python equivalent:","code":"from flair.embeddings import TransformerWordEmbeddings embedding = TransformerWordEmbeddings('bert-base-uncased')"},{"path":[]},{"path":"https://davidycliao.github.io/flaiR/reference/flair_embeddings.TransformerWordEmbeddings.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Initializing a Class for TransformerWordEmbeddings — flair_embeddings.TransformerWordEmbeddings","text":"","code":"if (FALSE) { # \\dontrun{ embedding <- flair_embeddings.TransformerWordEmbeddings(\"bert-base-uncased\") } # }"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_embeddings.WordEmbeddings.html","id":null,"dir":"Reference","previous_headings":"","what":"Initializing a Class for Flair WordEmbeddings Class — flair_embeddings.WordEmbeddings","title":"Initializing a Class for Flair WordEmbeddings Class — flair_embeddings.WordEmbeddings","text":"function interfaces Python via reticulate create WordEmbeddings object using Flair library. Users select pre-trained embeddings load providing appropriate ID string. Typically, two-letter language code initializes embedding (e.g., 'en' English, 'de' German). default, loads FastText embeddings trained Wikipedia. web crawl embeddings, use '-crawl' suffix (e.g., 'de-crawl' German). English offers options like 'en-glove', 'en-extvec', etc. Supported embeddings include: 'en-glove' 'glove': English GloVe embeddings 'en-extvec' 'extvec': English Komninos embeddings 'en-crawl' 'crawl': English FastText web crawl embeddings 'en-twitter' 'twitter': English Twitter embeddings 'en-turian' 'turian': English Turian embeddings (small) 'en', 'en-news', 'news': English FastText news Wikipedia embeddings 'de': German FastText embeddings 'nl': Dutch FastText embeddings 'fr': French FastText embeddings '': Italian FastText embeddings 'es': Spanish FastText embeddings 'pt': Portuguese FastText embeddings 'ro': Romanian FastText embeddings 'ca': Catalan FastText embeddings 'sv': Swedish FastText embeddings 'da': Danish FastText embeddings '': Norwegian FastText embeddings 'fi': Finnish FastText embeddings 'pl': Polish FastText embeddings 'cz': Czech FastText embeddings 'sk': Slovak FastText embeddings 'sl': Slovenian FastText embeddings 'sr': Serbian FastText embeddings 'hr': Croatian FastText embeddings 'bg': Bulgarian FastText embeddings 'ru': Russian FastText embeddings 'ar': Arabic FastText embeddings '': Hebrew FastText embeddings 'tr': Turkish FastText embeddings 'fa': Persian FastText embeddings 'ja': Japanese FastText embeddings 'ko': Korean FastText embeddings 'zh': Chinese FastText embeddings 'hi': Hindi FastText embeddings 'id': Indonesian FastText embeddings 'eu': Basque FastText embeddings example, load German FastText embeddings, use 'de' embeddings parameter.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_embeddings.WordEmbeddings.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Initializing a Class for Flair WordEmbeddings Class — flair_embeddings.WordEmbeddings","text":"","code":"flair_embeddings.WordEmbeddings(embeddings = \"glove\")"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_embeddings.WordEmbeddings.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Initializing a Class for Flair WordEmbeddings Class — flair_embeddings.WordEmbeddings","text":"embeddings type pre-trained embeddings use. Defaults \"glove\".","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_embeddings.WordEmbeddings.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Initializing a Class for Flair WordEmbeddings Class — flair_embeddings.WordEmbeddings","text":"Flair WordEmbeddings class.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_embeddings.WordEmbeddings.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Initializing a Class for Flair WordEmbeddings Class — flair_embeddings.WordEmbeddings","text":"Python equivalent:","code":"from flair.embeddings import WordEmbeddings embedding = WordEmbeddings('glove')"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_embeddings.WordEmbeddings.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Initializing a Class for Flair WordEmbeddings Class — flair_embeddings.WordEmbeddings","text":"","code":"if (FALSE) { # \\dontrun{ embedding <- flair_embeddings.WordEmbeddings(\"glove\") } # }"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_embeddings.html","id":null,"dir":"Reference","previous_headings":"","what":"Initialization of Flair Embeddings Modules — flair_embeddings","title":"Initialization of Flair Embeddings Modules — flair_embeddings","text":"function provides interface R users access utilize flair.embeddings module Flair NLP library. Flair's embedding functionalities offer various state---art embeddings crucial natural language processing tasks. using function, R users can seamlessly incorporate advanced embeddings NLP workflows without delving deep Python. Essentially, function acts bridge R's ecosystem Flair's rich embedding capabilities.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_embeddings.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Initialization of Flair Embeddings Modules — flair_embeddings","text":"","code":"flair_embeddings()"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_embeddings.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Initialization of Flair Embeddings Modules — flair_embeddings","text":"flair.embeddings module Flair.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_embeddings.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Initialization of Flair Embeddings Modules — flair_embeddings","text":"function allows R users access following Flair embeddings modules: FlairEmbeddings Contextual string embeddings capturing latent syntactic-semantic information beyond standard word embeddings. WordEmbeddings Classic word embeddings like GloVe FastText. TransformerWordEmbeddings Word embeddings transformer models BERT, RoBERTa, etc. TransformerDocumentEmbeddings Transformer-based embeddings entire documents sentences. StackedEmbeddings Combines multiple embeddings richer representation. DocumentPoolEmbeddings Provides single embedding vector entire document based chosen operation mode (mean, max, etc.). BytePairEmbeddings Embeddings based Byte-Pair Encoding (BPE) mechanism used subword tokenization. ELMoEmbeddings Deep contextual embeddings derived internal state pretrained bidirectional LSTM. embedding type offers unique features suitable various NLP tasks. understanding differences capabilities, R users can select appropriate embeddings enhance NLP models.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_embeddings.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Initialization of Flair Embeddings Modules — flair_embeddings","text":"Python's Flair library:","code":"from flair.embeddings import *"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_embeddings.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Initialization of Flair Embeddings Modules — flair_embeddings","text":"","code":"if (FALSE) { # \\dontrun{ library(flaiR) # Initialize FlairEmbeddings FlairEmbeddings <- flair_embeddings()$FlairEmbeddings embedding <- FlairEmbeddings('news-forward') } # }  if (FALSE) { # \\dontrun{ # Initialize WordEmbeddings WordEmbeddings <- flair_embeddings()$WordEmbeddings embedding <- WordEmbeddings('glove') } # }  if (FALSE) { # \\dontrun{ # Initialize TransformerWordEmbeddings TransformerWordEmbeddings <- flair_embeddings()$TransformerWordEmbeddings embedding <- TransformerWordEmbeddings('bert-base-uncased') } # }  if (FALSE) { # \\dontrun{ # Initialize TransformerDocumentEmbeddings TransformerDocumentEmbeddings <- flair_embeddings()$TransformerDocumentEmbeddings embedding <- TransformerDocumentEmbeddings('bert-base-uncased') } # }  if (FALSE) { # \\dontrun{ # Initialize StackedEmbeddings StackedEmbeddings <- flair_embeddings()$StackedEmbeddings WordEmbeddings <-  flair_embeddings()$WordEmbeddings FlairEmbeddings <-  flair_embeddings()$FlairEmbeddings  stacked_embeddings <- StackedEmbeddings(                                        list(WordEmbeddings('glove'),                                             FlairEmbeddings('news-forward'),                                             FlairEmbeddings('news-backward')                                             )                                        ) } # }  if (FALSE) { # \\dontrun{ # Initialize DocumentPoolEmbeddings DocumentPoolEmbeddings <- flair_embeddings()$DocumentPoolEmbeddings WordEmbeddings <- flair_embeddings()$WordEmbeddings doc_embeddings <- DocumentPoolEmbeddings(list(WordEmbeddings('glove'))) } # }"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_models.Sequencetagger.html","id":null,"dir":"Reference","previous_headings":"","what":"Access Flair's SequenceTagger — flair_models.Sequencetagger","title":"Access Flair's SequenceTagger — flair_models.Sequencetagger","text":"function utilizes reticulate package import SequenceTaggers Flair's models Python, enabling interaction Flair's sequence tagging models R environment.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_models.Sequencetagger.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Access Flair's SequenceTagger — flair_models.Sequencetagger","text":"","code":"flair_models.Sequencetagger()"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_models.Sequencetagger.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Access Flair's SequenceTagger — flair_models.Sequencetagger","text":"Python module (SequenceTagger) Flair, can utilized load use sequence tagging models.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_models.Sequencetagger.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Access Flair's SequenceTagger — flair_models.Sequencetagger","text":"function take parameters directly returns SequenceTagger called, can used sequence tagging tasks using pre-trained models Flair.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_models.Sequencetagger.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Access Flair's SequenceTagger — flair_models.Sequencetagger","text":"Python equivalent:","code":"from flair.models import SequenceTagger"},{"path":[]},{"path":"https://davidycliao.github.io/flaiR/reference/flair_models.Sequencetagger.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Access Flair's SequenceTagger — flair_models.Sequencetagger","text":"","code":"if (FALSE) { # \\dontrun{ sequence_tagger <- flair_models.sequencetagger() } # }"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_models.TextClassifier.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve TextClassifier from flair.models — flair_models.TextClassifier","title":"Retrieve TextClassifier from flair.models — flair_models.TextClassifier","text":"function utilizes reticulate package directly import TextClassifier flair.models Flair NLP Python library. Ensure Python environment properly set Flair package installed.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_models.TextClassifier.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve TextClassifier from flair.models — flair_models.TextClassifier","text":"","code":"flair_models.TextClassifier()"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_models.TextClassifier.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve TextClassifier from flair.models — flair_models.TextClassifier","text":"Python class representing flair.models.TextClassifier.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_models.TextClassifier.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Retrieve TextClassifier from flair.models — flair_models.TextClassifier","text":"Python equivalent:","code":"from flair.models import TextClassifier"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_models.TextClassifier.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Retrieve TextClassifier from flair.models — flair_models.TextClassifier","text":"","code":"# Load the TextClassifier TextClassifier <- flair_models.TextClassifier() # Load a pre-trained sentiment model classifier <- TextClassifier$load('sentiment')  # Create a sentence object Sentence <- flair_data()$Sentence sentence <- Sentence(\"Flair is pretty neat!\")  # Predict the sentiment classifier$predict(sentence) # Display the sentiment print(sentence$get_labels()) #> [[1]] #> 'Sentence[5]: \"Flair is pretty neat!\"'/'POSITIVE' (0.9997) #>"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_models.html","id":null,"dir":"Reference","previous_headings":"","what":"Import the flair.models Python module — flair_models","title":"Import the flair.models Python module — flair_models","text":"function imports flair.models module Flair NLP Python library, providing access several powerful models tailored NLP tasks. three primary methods available module: TextClassifier: method represents neural network model designed text classification tasks. Given piece text, predicts class label category. instance, can used classify movie reviews positive negative. SequenceTagger: Tailored tasks like Named Entity Recognition (NER) Part--Speech (POS) tagging, method annotates sequences words. NER, tag entities sentence locations, persons, organizations. POS tagging, can label word sentence grammatical role like noun, verb, adjective, etc. LanguageModel: method represents model trained predict next word sequence, making powerful tasks like text generation completion. learns statistical properties structure language, can base transfer learning NLP tasks.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_models.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Import the flair.models Python module — flair_models","text":"","code":"flair_models()"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_models.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Import the flair.models Python module — flair_models","text":"Python module object representing flair.models.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_models.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Import the flair.models Python module — flair_models","text":"Python equivalent:","code":"from flair.models import *"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_nn.Classifier.html","id":null,"dir":"Reference","previous_headings":"","what":"Initializing a Class for Flair Classifier — flair_nn.Classifier","title":"Initializing a Class for Flair Classifier — flair_nn.Classifier","text":"function interfaces Python via reticulate package create Classifier object Flair library.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_nn.Classifier.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Initializing a Class for Flair Classifier — flair_nn.Classifier","text":"","code":"flair_nn.Classifier()"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_nn.Classifier.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Initializing a Class for Flair Classifier — flair_nn.Classifier","text":"Flair Classifier class instance.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_nn.Classifier.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Initializing a Class for Flair Classifier — flair_nn.Classifier","text":"Python equivalent:","code":"from flair.nn import Classifier"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_nn.Classifier.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Initializing a Class for Flair Classifier — flair_nn.Classifier","text":"","code":"if (FALSE) { # \\dontrun{ classifier <- flair_nn.Classifier() } # }"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_nn.html","id":null,"dir":"Reference","previous_headings":"","what":"Import Flair's Neural Network Module — flair_nn","title":"Import Flair's Neural Network Module — flair_nn","text":"function provides interface flair.nn module Flair library. flair.nn module encompasses various sub-modules : decoder distance dropout loss model multitask recurrent Model Classifier PrototypicalDecoder LockedDropout WordDropout","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_nn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Import Flair's Neural Network Module — flair_nn","text":"","code":"flair_nn()"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_nn.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Import Flair's Neural Network Module — flair_nn","text":"reference Flair's neural network module (flair.nn).","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_nn.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Import Flair's Neural Network Module — flair_nn","text":"","code":"if (FALSE) { # \\dontrun{   flair_nn_module <- flair_nn()   Classifier <- flair_nn_module$Classifier } # }"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_splitter.SegtokSentenceSplitter.html","id":null,"dir":"Reference","previous_headings":"","what":"Segtok Sentence Splitter — flair_splitter.SegtokSentenceSplitter","title":"Segtok Sentence Splitter — flair_splitter.SegtokSentenceSplitter","text":"Interface Python flair.splitter module utilize SegtokSentenceSplitter class/method.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_splitter.SegtokSentenceSplitter.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Segtok Sentence Splitter — flair_splitter.SegtokSentenceSplitter","text":"","code":"flair_splitter.SegtokSentenceSplitter()"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_splitter.SegtokSentenceSplitter.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Segtok Sentence Splitter — flair_splitter.SegtokSentenceSplitter","text":"instance Python class SegtokSentenceSplitter flair.splitter module.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_splitter.SegtokSentenceSplitter.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Segtok Sentence Splitter — flair_splitter.SegtokSentenceSplitter","text":"Python equivalent:","code":"from flair.splitter import SegtokSentenceSplitter"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_splitter.SegtokSentenceSplitter.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Segtok Sentence Splitter — flair_splitter.SegtokSentenceSplitter","text":"","code":"if (FALSE) { # \\dontrun{ splitter <- flair_splitter.SegtokSentenceSplitter() } # }"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_splitter.html","id":null,"dir":"Reference","previous_headings":"","what":"Import flair.splitter Module in R — flair_splitter","title":"Import flair.splitter Module in R — flair_splitter","text":"function interface Python flair.splitter module. function provides access various sentence splitting strategies implemented Flair library: NoSentenceSplitter: Treats entire text single sentence without splitting . SegtokSentenceSplitter: Uses segtok library split text sentences. SpacySentenceSplitter: Uses spaCy library sentence splitting. TagSentenceSplitter: Assumes specific tags text indicate sentence boundaries.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_splitter.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Import flair.splitter Module in R — flair_splitter","text":"","code":"flair_splitter()"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_splitter.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Import flair.splitter Module in R — flair_splitter","text":"Python module (flair.splitter).","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_splitter.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Import flair.splitter Module in R — flair_splitter","text":"Python reference SegtokSentenceSplitter: Additional references classes can found within Flair library documentation. Flair GitHub","code":"from flair.splitter import *"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_splitter.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Import flair.splitter Module in R — flair_splitter","text":"","code":"if (FALSE) { # \\dontrun{ SegtokSentenceSplitter <- flair_splitter$SegtokSentenceSplitter() text <- \"I am Taiwanese and come from Taiwan\" sentences <- splitter$split(text) } # }"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_trainers.html","id":null,"dir":"Reference","previous_headings":"","what":"Import flair.trainers Module in R — flair_trainers","title":"Import flair.trainers Module in R — flair_trainers","text":"flair_trainers() provides R users access Flair's ModelTrainer Python class using reticulate package. ModelTrainer class offers following main methods: train: Trains given model. Parameters include corpus (data split training, development, test sets), output directory save model logs, various parameters control training process (e.g., learning rate, mini-batch size, maximum epochs). find_learning_rate: Uses \"learning rate finder\" method find optimal learning rate training. Parameters typically include corpus, batch size, range learning rates explore. final_test: training model, method evaluates model test set prints results. save_checkpoint: Saves current training state (including model parameters training configurations) resume later interrupted. load_checkpoint: Loads previously saved checkpoint resume training. log_line: Utility method logging. Writes line console log file. log_section: Utility method logging. Writes section break console log file.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_trainers.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Import flair.trainers Module in R — flair_trainers","text":"","code":"flair_trainers()"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_trainers.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Import flair.trainers Module in R — flair_trainers","text":"Python Module(flair.trainers) object allowing access Flair's trainers R.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_trainers.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Import flair.trainers Module in R — flair_trainers","text":"Flair GitHub Python equivalent:","code":"from flair.trainers import ModelTrainer"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_trainers.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Import flair.trainers Module in R — flair_trainers","text":"","code":"if (FALSE) { # \\dontrun{ trainers <- flair_trainers() model_trainer <- trainers$ModelTrainer } # }"},{"path":"https://davidycliao.github.io/flaiR/reference/get_entities.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Named Entities from Texts with Batch Processing — get_entities","title":"Extract Named Entities from Texts with Batch Processing — get_entities","text":"function processes texts batches extracts named entities using Flair NLP library. supports standard NER OntoNotes models, options batch processing GPU acceleration.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/get_entities.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Named Entities from Texts with Batch Processing — get_entities","text":"","code":"get_entities(   texts,   doc_ids = NULL,   tagger,   show.text_id = FALSE,   gc.active = FALSE,   batch_size = 5,   device = \"cpu\",   verbose = FALSE )"},{"path":"https://davidycliao.github.io/flaiR/reference/get_entities.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Named Entities from Texts with Batch Processing — get_entities","text":"texts character vector containing texts process. doc_ids character numeric vector containing document IDs corresponding text. tagger Flair tagger object named entity recognition. Must provided user. Can created using load_tagger_ner() different models: Standard NER: tagger_ner <- load_tagger_ner('ner') OntoNotes: tagger_ner <- load_tagger_ner('flair/ner-english-ontonotes') Large model: tagger_ner <- load_tagger_ner('flair/ner-english-large') show.text_id logical value. TRUE, includes actual text entity extracted. Default FALSE. gc.active logical value. TRUE, runs garbage collector processing texts. Default FALSE. batch_size integer specifying size batch. Set 1 single-text processing. Default 5. device character string specifying computation device (\"cpu\", \"cuda:0\", \"cuda:1\", etc.). Default \"cpu\". Note: MPS (Mac M1/M2) currently fully supported default CPU. verbose logical value. TRUE, prints processing progress. Default FALSE.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/get_entities.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Named Entities from Texts with Batch Processing — get_entities","text":"data table columns: doc_id Character numeric. ID document entity extracted. text_id Character. complete text entity extracted. included show.text_id = TRUE. entity Character. actual named entity text extracted. NA entity found. tag Character. category named entity. score Numeric. Confidence score prediction.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/get_entities.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract Named Entities from Texts with Batch Processing — get_entities","text":"","code":"if (FALSE) { # \\dontrun{ library(reticulate) library(flaiR)  # Using standard NER model tagger_std <- load_tagger_ner('ner')  texts <- c(   \"John Smith works at Google in New York.\",   \"The Eiffel Tower was built in 1889.\" ) doc_ids <- c(\"doc1\", \"doc2\")  results <- get_entities(   texts = texts,   doc_ids = doc_ids,   tagger = tagger_std,   batch_size = 2,   verbose = TRUE ) } # }"},{"path":"https://davidycliao.github.io/flaiR/reference/get_flair_version.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve Flair Version — get_flair_version","title":"Retrieve Flair Version — get_flair_version","text":"Gets version installed Flair module current Python environment.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/get_flair_version.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve Flair Version — get_flair_version","text":"","code":"get_flair_version(...)"},{"path":"https://davidycliao.github.io/flaiR/reference/get_flair_version.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve Flair Version — get_flair_version","text":"Character string representing version Flair. Flair installed, may return NULL cause error.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/get_pos.html","id":null,"dir":"Reference","previous_headings":"","what":"Tagging Part-of-Speech Tagging with Flair Models — get_pos","title":"Tagging Part-of-Speech Tagging with Flair Models — get_pos","text":"function returns data table POS tags related data given texts.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/get_pos.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tagging Part-of-Speech Tagging with Flair Models — get_pos","text":"","code":"get_pos(   texts,   doc_ids = NULL,   tagger = NULL,   language = NULL,   show.text_id = FALSE,   gc.active = FALSE )"},{"path":"https://davidycliao.github.io/flaiR/reference/get_pos.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tagging Part-of-Speech Tagging with Flair Models — get_pos","text":"texts character vector containing texts processed. doc_ids character vector containing document ids. tagger tagger object (default NULL). language language texts (default NULL). show.text_id logical value. TRUE, includes actual text entity extracted resulting data table. Useful verification traceability purposes might increase size output. Default FALSE. gc.active logical value. TRUE, runs garbage collector processing texts. can help freeing memory releasing unused memory space, especially processing large number texts. Default FALSE.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/get_pos.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tagging Part-of-Speech Tagging with Flair Models — get_pos","text":"data.table containing following columns: doc_id document identifier corresponding text. token_id token number original text, indicating position token. text_id actual text input passed function. token individual word token text POS tagged. tag part--speech tag assigned token Flair library. precision confidence score (numeric) assigned POS tag.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/get_pos.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tagging Part-of-Speech Tagging with Flair Models — get_pos","text":"","code":"if (FALSE) { # \\dontrun{ library(reticulate) library(fliaR) tagger_pos_fast <- load_tagger_pos('pos-fast') texts <- c(\"UCD is one of the best universities in Ireland.\",            \"Essex is not in the Russell Group, but it is famous for political science research.\",            \"TCD is the oldest university in Ireland.\") doc_ids <- c(\"doc1\", \"doc2\", \"doc3\")  get_pos(texts, doc_ids, tagger_pos_fast) } # }"},{"path":"https://davidycliao.github.io/flaiR/reference/get_tagger_tags.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Model Tags — get_tagger_tags","title":"Extract Model Tags — get_tagger_tags","text":"Helper function extract categorize tags loaded Flair SequenceTagger model. tags grouped categories person, organization, location, miscellaneous.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/get_tagger_tags.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Model Tags — get_tagger_tags","text":"","code":"get_tagger_tags(tagger)"},{"path":"https://davidycliao.github.io/flaiR/reference/get_tagger_tags.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Model Tags — get_tagger_tags","text":"tagger loaded Flair SequenceTagger model","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/get_tagger_tags.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Model Tags — get_tagger_tags","text":"list tags grouped category: Complete list available tags special Special tags like , O, , person Person-related tags (e.g., B-PER, -PER) organization Organization tags (e.g., B-ORG, E-ORG) location Location tags (e.g., B-LOC, S-LOC) misc Miscellaneous entity tags","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/get_tagger_tags.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract Model Tags — get_tagger_tags","text":"tags follow BIOES (Begin, Inside, Outside, End, Single) scheme: B-: Beginning multi-token entity (e.g., B-PER \"John Smith\") -: Inside multi-token entity (e.g., -PER \"John Smith\") O: Outside entity E-: End multi-token entity S-: Single token entity (e.g., S-LOC \"Paris\")","code":""},{"path":[]},{"path":"https://davidycliao.github.io/flaiR/reference/get_tagger_tags.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract Model Tags — get_tagger_tags","text":"","code":"if (FALSE) { # \\dontrun{ # Load a NER model tagger <- load_tagger_ner(\"flair/ner-english-large\")  # Extract all tags tags <- get_tagger_tags(tagger)  # Access specific tag categories print(tags$person)      # All person-related tags print(tags$location)    # All location-related tags  # Example usage with text annotation # B-PER I-PER    O    S-ORG # \"John Smith works at Google\"  # B-LOC  E-LOC   O   B-ORG    E-ORG # \"New   York    is  United   Nations headquarters\"  # Use tags to filter entities person_entities <- results[tag %in% tags$person] org_entities <- results[tag %in% tags$organization] } # }"},{"path":"https://davidycliao.github.io/flaiR/reference/gs_score.html","id":null,"dir":"Reference","previous_headings":"","what":"Training Data from : When Do Politicians Grandstand? Measuring Message Politics in Committee Hearings (2021 JOP) — gs_score","title":"Training Data from : When Do Politicians Grandstand? Measuring Message Politics in Committee Hearings (2021 JOP) — gs_score","text":"dataset Ju Yeon Park's paper published Journal Politics 2021, titled \"Politicians Grandstand? Measuring Message Politics Committee Hearings\". contains \"Congressional Hearing Dataset: 105th 114th Congresses\", replication dataset paper. manuscript accepted publication June 2019. Please cite paper using data.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/gs_score.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Training Data from : When Do Politicians Grandstand? Measuring Message Politics in Committee Hearings (2021 JOP) — gs_score","text":"","code":"data(\"gs_score\")"},{"path":"https://davidycliao.github.io/flaiR/reference/gs_score.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Training Data from : When Do Politicians Grandstand? Measuring Message Politics in Committee Hearings (2021 JOP) — gs_score","text":"data frame 3 variables: speech Hearing speeches sentimentit_score grandstanding score. rescaled_gs Label indicating whether text grandstanding speech: '1' grandstanding speech '0' non-grandstanding speech. rescaled version sentimentit_score (grandstanding scores) original released data.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/gs_score.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Training Data from : When Do Politicians Grandstand? Measuring Message Politics in Committee Hearings (2021 JOP) — gs_score","text":"Data provided authors Ju Yeon Park JOP's Dataverse https://dataverse.harvard.edu/file.xhtml?persistentId=doi:10.7910/DVN/GSMBFX/JIHIGH&version=1.0.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/gs_score.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Training Data from : When Do Politicians Grandstand? Measuring Message Politics in Committee Hearings (2021 JOP) — gs_score","text":"","code":"if (FALSE) { # \\dontrun{ data(gs_score) head(gs_score) } # }"},{"path":"https://davidycliao.github.io/flaiR/reference/hatespeech_zh_tw.html","id":null,"dir":"Reference","previous_headings":"","what":"Training Data from : Political Hate Speech Detection and Lexicon Building: A Study in Taiwan (IEEE Explore 2022) — hatespeech_zh_tw","title":"Training Data from : Political Hate Speech Detection and Lexicon Building: A Study in Taiwan (IEEE Explore 2022) — hatespeech_zh_tw","text":"dataset derived sample development set \"Political Hate Speech Detection Lexicon Building: Study Taiwan.\" contains 1,000 annotated data entries, 926 labeled '0' (hate speech) 74 '1' (hate speech). paper can accessed https://ieeexplore.ieee.org/document/9738642.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/hatespeech_zh_tw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Training Data from : Political Hate Speech Detection and Lexicon Building: A Study in Taiwan (IEEE Explore 2022) — hatespeech_zh_tw","text":"","code":"data(\"hatespeech_zh_tw\")"},{"path":"https://davidycliao.github.io/flaiR/reference/hatespeech_zh_tw.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Training Data from : Political Hate Speech Detection and Lexicon Building: A Study in Taiwan (IEEE Explore 2022) — hatespeech_zh_tw","text":"data frame 2 variables: text Content text. label Label indicating whether text hate speech: '1' hate speech '0' non-hate speech.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/hatespeech_zh_tw.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Training Data from : Political Hate Speech Detection and Lexicon Building: A Study in Taiwan (IEEE Explore 2022) — hatespeech_zh_tw","text":"Data provided authors Chih-Chien Wang, Min-Yuh Day, Chun-Lian Wu. Available https://ieeexplore.ieee.org/document/9738642.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/hatespeech_zh_tw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Training Data from : Political Hate Speech Detection and Lexicon Building: A Study in Taiwan (IEEE Explore 2022) — hatespeech_zh_tw","text":"","code":"if (FALSE) { # \\dontrun{ data(hatespeech_zh_tw) head(hatespeech_zh_tw) } # }"},{"path":"https://davidycliao.github.io/flaiR/reference/highlight_text.html","id":null,"dir":"Reference","previous_headings":"","what":"Highlight Entities with Specified Colors and Tag — highlight_text","title":"Highlight Entities with Specified Colors and Tag — highlight_text","text":"function highlights specified entities text string specified background colors, font colors, optional labels. Additionally, allows setting specific font type highlighted text.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/highlight_text.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Highlight Entities with Specified Colors and Tag — highlight_text","text":"","code":"highlight_text(text, entities_mapping, font_family = \"Arial\")"},{"path":"https://davidycliao.github.io/flaiR/reference/highlight_text.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Highlight Entities with Specified Colors and Tag — highlight_text","text":"text character string containing text highlight. entities_mapping named list lists, sub-list containing: words: character vector words highlight. background_color: character string specifying CSS color highlight background. font_color: character string specifying CSS color highlighted text. label: character string specifying label append highlighted word. label_color: character string specifying CSS color label text. font_family character string specifying CSS font family highlighted text label. Default \"Arial\".","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/highlight_text.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Highlight Entities with Specified Colors and Tag — highlight_text","text":"HTML object containing text highlighted entities.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/highlight_text.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Highlight Entities with Specified Colors and Tag — highlight_text","text":"","code":"library(flaiR) data(\"uk_immigration\") uk_immigration <- head(uk_immigration, 1) tagger_ner <- load_tagger_ner(\"ner\") #>  #> NER Tagger Dictionary: #> ======================================== #> Total tags: 20 #> Model: ner #> ---------------------------------------- #> Special        : <unk>, O, <START>, <STOP> #> Organization   : S-ORG, B-ORG, E-ORG, I-ORG #> Location       : S-LOC, B-LOC, E-LOC, I-LOC #> Misc           : S-MISC, B-MISC, I-MISC, E-MISC #> ---------------------------------------- #> Tag scheme: BIOES #> B-: Beginning of multi-token entity #> I-: Inside of multi-token entity #> O: Outside (not part of any entity) #> E-: End of multi-token entity #> S-: Single token entity #> ======================================== results <- get_entities(uk_immigration$text,                         uk_immigration$speaker,                         tagger_ner,                         show.text_id = FALSE) #> CPU is used.  highlighted_text <- highlight_text(uk_immigration$text, map_entities(results)) print(highlighted_text) #> <div style=\"text-align: justify; font-family: Arial\">I thank Mr. Speaker for giving me permission to hold this debate today. I welcome the Minister-I very much appreciate the contact from his office prior to today-and the <span style=\"background-color: pink; color: black; font-family: Arial\">Conservative<\/span> <span style=\"color: pink; font-family: Arial\">(ORG)<\/span> and <span style=\"background-color: pink; color: black; font-family: Arial\">Liberal Democrat Front Benchers<\/span> <span style=\"color: pink; font-family: Arial\">(ORG)<\/span> to the debate. I also welcome my hon. Friends on the <span style=\"background-color: yellow; color: black; font-family: Arial\">Back Benches<\/span> <span style=\"color: orange; font-family: Arial\">(MISC)<\/span>. Immigration is the most important issue for my constituents. I get more complaints, comments and suggestions about immigration than about anything else. In the <span style=\"background-color: lightblue; color: black; font-family: Arial\">Kettering<\/span> <span style=\"color: blue; font-family: Arial\">(LOC)<\/span> constituency, the number of immigrants is actually very low. There is a well-settled <span style=\"background-color: yellow; color: black; font-family: Arial\">Sikh<\/span> <span style=\"color: orange; font-family: Arial\">(MISC)<\/span> community in the middle of <span style=\"background-color: lightblue; color: black; font-family: Arial\">Kettering<\/span> <span style=\"color: blue; font-family: Arial\">(LOC)<\/span> town itself, which has been in <span style=\"background-color: lightblue; color: black; font-family: Arial\">Kettering<\/span> <span style=\"color: blue; font-family: Arial\">(LOC)<\/span> for some 40 or 50 years and is very much part of the local community and of the fabric of local life. There are other very small migrant groups in my constituency, but it is predominantly made up of indigenous <span style=\"background-color: yellow; color: black; font-family: Arial\">British<\/span> <span style=\"color: orange; font-family: Arial\">(MISC)<\/span> people. However, there is huge concern among my constituents about the level of immigration into our country. I believe that I am right in saying that, in recent years, net immigration into the <span style=\"background-color: lightblue; color: black; font-family: Arial\">United Kingdom<\/span> <span style=\"color: blue; font-family: Arial\">(LOC)<\/span> is the largest wave of immigration that our country has ever known and, proportionately, is probably the biggest wave of immigration since the <span style=\"background-color: yellow; color: black; font-family: Arial\">Norman<\/span> <span style=\"color: orange; font-family: Arial\">(MISC)<\/span> conquest. My contention is that our country simply cannot cope with immigration on that scale-to coin a phrase, we simply cannot go on like this. It is about time that mainstream politicians started airing the views of their constituents, because for too long people have muttered under their breath that they are concerned about immigration. They have been frightened to speak out about it because they are frightened of being accused of being racist. My contention is that immigration is not a racist issue; it is a question of numbers. I personally could not care tuppence about the ethnicity of the immigrants concerned, the colour of their skin or the language that they speak. What I am concerned about is the very large numbers of new arrivals to our country. My contention is that the <span style=\"background-color: lightblue; color: black; font-family: Arial\">United Kingdom<\/span> <span style=\"color: blue; font-family: Arial\">(LOC)<\/span> simply cannot cope with them.<\/div>"},{"path":"https://davidycliao.github.io/flaiR/reference/import_flair.html","id":null,"dir":"Reference","previous_headings":"","what":"Wrapper for the Flair Python Library — import_flair","title":"Wrapper for the Flair Python Library — import_flair","text":"flair: wrapper access Flair library Python. Returns: list: list method python module. Environment Configuration: os: Pertains operating system related functions, path handling, file operations, . Path: pathlib, used convenient file path operations. set_seed: Functions set random seed. hf_set_seed: Functions set random seed. set_proxies: Used configure network proxies. Data Data Loading: data: Functions related data handling operations. datasets: Modules methods load handle specific datasets. file_utils: Utilities file operations. Embeddings Model Layers: embeddings: embeddings, including word embeddings, contextual embeddings, etc. nn: Related neural network layers operations. models: Different model architectures structures. Training Optimization: trainers: Related training models. training_utils: Utility functions training process. optim: Optimization algorithms, like SGD, Adam. Tokenization Text Processing: tokenization: break text tokens. splitter: splitting datasets texts. Visualizations Miscellaneous: visual: Related visualization. torch: main PyTorch library. cache_root: Related caching data models.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/import_flair.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Wrapper for the Flair Python Library — import_flair","text":"","code":"import_flair()"},{"path":"https://davidycliao.github.io/flaiR/reference/import_flair.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Wrapper for the Flair Python Library — import_flair","text":"object represents Flair module Python.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/import_flair.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Wrapper for the Flair Python Library — import_flair","text":"function relies reticulate package import use Flair module Python. Ensure Flair Python library installed Python environment used.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/import_flair.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Wrapper for the Flair Python Library — import_flair","text":"","code":"if (FALSE) { # \\dontrun{ flair <- import_flair() } # }"},{"path":"https://davidycliao.github.io/flaiR/reference/install_python_package.html","id":null,"dir":"Reference","previous_headings":"","what":"Install a Specific Python Package and Return Its Version — install_python_package","title":"Install a Specific Python Package and Return Its Version — install_python_package","text":"function checks Python interpreter's location (either specified user automatically located), compares current R session's Python setting, installs specified Python package using identified Python interpreter, returns package version installation environment.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/install_python_package.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Install a Specific Python Package and Return Its Version — install_python_package","text":"","code":"install_python_package(   package_name,   package_version = NULL,   python_path = Sys.which(\"python3\") )"},{"path":"https://davidycliao.github.io/flaiR/reference/install_python_package.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Install a Specific Python Package and Return Its Version — install_python_package","text":"package_name name Python package install. package_version version Python package install. NULL, latest version installed. python_path path Python interpreter used installation. provided, defaults result Sys.(\"python3\").","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/install_python_package.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Install a Specific Python Package and Return Its Version — install_python_package","text":"list containing package name, installed version, path Python interpreter used installation.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/install_python_package.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Install a Specific Python Package and Return Its Version — install_python_package","text":"","code":"if (FALSE) { # \\dontrun{ install_python_package(package_name =\"flair\", package_version =\"0.12\") } # }"},{"path":"https://davidycliao.github.io/flaiR/reference/load_tagger_ner.html","id":null,"dir":"Reference","previous_headings":"","what":"Load and Configure NER Tagger — load_tagger_ner","title":"Load and Configure NER Tagger — load_tagger_ner","text":"Loads Named Entity Recognition model Flair displays tag dictionary. Supports standard NER OntoNotes models.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/load_tagger_ner.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load and Configure NER Tagger — load_tagger_ner","text":"","code":"load_tagger_ner(model_name = \"ner\", show_tags = TRUE)"},{"path":"https://davidycliao.github.io/flaiR/reference/load_tagger_ner.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load and Configure NER Tagger — load_tagger_ner","text":"model_name Character string specifying model load. Can \"ner\" (default), \"flair/ner-english-large\", \"flair/ner-english-ontonotes\" show_tags Logical, whether display tag dictionary. Default TRUE.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/load_tagger_ner.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Load and Configure NER Tagger — load_tagger_ner","text":"Flair SequenceTagger model object","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/load_tagger_pos.html","id":null,"dir":"Reference","previous_headings":"","what":"Load POS (Part-of-Speech) Tagger Model — load_tagger_pos","title":"Load POS (Part-of-Speech) Tagger Model — load_tagger_pos","text":"Loads Part--Speech tagging model Flair displays tag dictionary organized categories.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/load_tagger_pos.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load POS (Part-of-Speech) Tagger Model — load_tagger_pos","text":"","code":"load_tagger_pos(model_name = \"pos-fast\", show_tags = TRUE)"},{"path":"https://davidycliao.github.io/flaiR/reference/load_tagger_pos.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load POS (Part-of-Speech) Tagger Model — load_tagger_pos","text":"model_name Character string specifying model load. Default \"pos-fast\". show_tags Logical, whether display tag dictionary. Default TRUE.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/load_tagger_pos.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Load POS (Part-of-Speech) Tagger Model — load_tagger_pos","text":"Flair tagger model object POS tagging","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/map_entities.html","id":null,"dir":"Reference","previous_headings":"","what":"Create Mapping for NER Highlighting — map_entities","title":"Create Mapping for NER Highlighting — map_entities","text":"function generates mapping list Named Entity Recognition (NER) highlighting. mapping list defines different entity types highlighted text displays, defining background color, font color, label, label color entity type.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/map_entities.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create Mapping for NER Highlighting — map_entities","text":"","code":"map_entities(df, entity = \"entity\", tag = \"tag\")"},{"path":"https://davidycliao.github.io/flaiR/reference/map_entities.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create Mapping for NER Highlighting — map_entities","text":"df data frame containing least two columns: entity: character vector words/entities highlighted. tag: character vector indicating entity type word/entity. entity character vector entities annotated model. tag character vector tags corresponding annotated entities.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/map_entities.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create Mapping for NER Highlighting — map_entities","text":"list mapping settings entity type, entity type represented list containing: words: character vector words highlighted. background_color: character string representing background color highlighting words. font_color: character string representing font color words. label: character string label entity type. label_color: character string representing font color label.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/map_entities.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create Mapping for NER Highlighting — map_entities","text":"","code":"if (FALSE) { # \\dontrun{   sample_df <- data.frame(     entity = c(\"Microsoft\", \"USA\", \"dollar\", \"Bill Gates\"),     tag = c(\"ORG\", \"LOC\", \"MISC\", \"PER\"),     stringsAsFactors = FALSE   )   mapping <- map_entities(sample_df) } # }"},{"path":"https://davidycliao.github.io/flaiR/reference/predict_label.html","id":null,"dir":"Reference","previous_headings":"","what":"Predict Text Label Using Flair Classifier — predict_label","title":"Predict Text Label Using Flair Classifier — predict_label","text":"Predict Text Label Using Flair Classifier","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/predict_label.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predict Text Label Using Flair Classifier — predict_label","text":"","code":"predict_label(text, classifier, sentence = NULL)"},{"path":"https://davidycliao.github.io/flaiR/reference/predict_label.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predict Text Label Using Flair Classifier — predict_label","text":"text character string containing text labeled classifier Flair TextClassifier object making predictions sentence Optional Flair Sentence object. NULL, one created text","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/predict_label.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predict Text Label Using Flair Classifier — predict_label","text":"list containing: label Character string predicted label score Numeric confidence score classifier token_number Integer count tokens input text","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/predict_label.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Predict Text Label Using Flair Classifier — predict_label","text":"","code":"if (FALSE) { # \\dontrun{ # Example 1: Using text input classifier <- flair_models()$TextClassifier$load('stance-classifier') result1 <- predict_label(   text = \"I strongly support this policy\",   classifier = classifier )  # Example 2: Using pre-created and tagged sentence sent <- Sentence(\"I love Berlin and New York.\") tagger <- flair_models()$SequenceTagger$load('pos') tagger$predict(sent) print(sent)  # Shows tokens with POS tags  result2 <- predict_label(   text = NULL,   classifier = classifier,   sentence = sent ) } # }"},{"path":"https://davidycliao.github.io/flaiR/reference/process_embeddings.html","id":null,"dir":"Reference","previous_headings":"","what":"Process Token Embeddings from Flair Sentence Object — process_embeddings","title":"Process Token Embeddings from Flair Sentence Object — process_embeddings","text":"function processes token embeddings Flair sentence object converts matrix format token names row names. handles extraction embeddings tokens, retrieval token texts, conversion matrix format.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/process_embeddings.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process Token Embeddings from Flair Sentence Object — process_embeddings","text":"","code":"process_embeddings(sentence, verbose = FALSE)"},{"path":"https://davidycliao.github.io/flaiR/reference/process_embeddings.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process Token Embeddings from Flair Sentence Object — process_embeddings","text":"sentence Flair sentence object containing tokens embeddings. sentence object 'tokens' attribute, token 'embedding' (numpy() method) 'text' attribute. verbose Logical indicating whether print progress messages. Default FALSE.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/process_embeddings.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process Token Embeddings from Flair Sentence Object — process_embeddings","text":"matrix : row represents token's embedding Row names corresponding token texts Columns represent dimensions embedding vectors","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/process_embeddings.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Process Token Embeddings from Flair Sentence Object — process_embeddings","text":"function throw errors following cases: sentence NULL tokens token missing embedding token missing text","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/process_embeddings.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process Token Embeddings from Flair Sentence Object — process_embeddings","text":"","code":"if (FALSE) { # \\dontrun{ # Create a Flair sentence sentence <- Sentence(\"example text\") WordEmbeddings <- flair_embeddings()$WordEmbeddings  # Initialize FastText embeddings trained on Common Crawl fasttext_embeddings <- WordEmbeddings('en-crawl')  # Apply embeddings fasttext_embeddings$embed(sentence)  # Process embeddings with timing and messages embedding_matrix <- process_embeddings(sentence, verbose = TRUE) } # }"},{"path":"https://davidycliao.github.io/flaiR/reference/show_flair_cache.html","id":null,"dir":"Reference","previous_headings":"","what":"Show Flair Cache Preloaed flair's Directory — show_flair_cache","title":"Show Flair Cache Preloaed flair's Directory — show_flair_cache","text":"function lists contents flair cache directory returns data frame.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/show_flair_cache.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Show Flair Cache Preloaed flair's Directory — show_flair_cache","text":"","code":"show_flair_cache()"},{"path":"https://davidycliao.github.io/flaiR/reference/show_flair_cache.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Show Flair Cache Preloaed flair's Directory — show_flair_cache","text":"data frame containing file paths contents flair cache directory. directory exist empty, NULL returned.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/show_flair_cache.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Show Flair Cache Preloaed flair's Directory — show_flair_cache","text":"","code":"if (FALSE) { # \\dontrun{ show_flair_cache() } # }"},{"path":"https://davidycliao.github.io/flaiR/reference/statements.html","id":null,"dir":"Reference","previous_headings":"","what":"Sampled Grandstanding Text — statements","title":"Sampled Grandstanding Text — statements","text":"Sampled Grandstanding Text","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/statements.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sampled Grandstanding Text — statements","text":"","code":"data(\"statements\")"},{"path":"https://davidycliao.github.io/flaiR/reference/statements.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Sampled Grandstanding Text — statements","text":"data frame 3 variables: Type Grandstanding types Statement Grandstanding texts","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/statements.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sampled Grandstanding Text — statements","text":"","code":"if (FALSE) { # \\dontrun{ data(statements) head(statements) } # }"},{"path":"https://davidycliao.github.io/flaiR/reference/uk_immigration.html","id":null,"dir":"Reference","previous_headings":"","what":"UK House of Commons Immigration Debate Data — uk_immigration","title":"UK House of Commons Immigration Debate Data — uk_immigration","text":"dataset containing speeches debates UK House Commons topic immigration 2010.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/uk_immigration.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"UK House of Commons Immigration Debate Data — uk_immigration","text":"","code":"data(\"uk_immigration\")"},{"path":"https://davidycliao.github.io/flaiR/reference/uk_immigration.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"UK House of Commons Immigration Debate Data — uk_immigration","text":"data frame 12 variables: date Date speech, Date type agenda Agenda subject speech, character speechnumber Unique identifier speech, numeric speaker Name person giving speech, character party Political party speaker, character party.facts.id ID party, usually numeric character chair Person chairing session, character terms Terms tags associated speech, character list text Actual text speech, character parliament parliament session, character numeric iso3country ISO3 country code parliament located, character year Year speech made, numeric","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/uk_immigration.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"UK House of Commons Immigration Debate Data — uk_immigration","text":"Data collected ParSpeechV2 House Commons year 2010. dataset publicly available https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/L4OAKN.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/uk_immigration.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"UK House of Commons Immigration Debate Data — uk_immigration","text":"","code":"if (FALSE) { # \\dontrun{ data(uk_immigration) head(uk_immigration) } # }"},{"path":"https://davidycliao.github.io/flaiR/reference/uninstall_python_package.html","id":null,"dir":"Reference","previous_headings":"","what":"Uninstall a Python Package — uninstall_python_package","title":"Uninstall a Python Package — uninstall_python_package","text":"uninstall_python_package function uninstalls specified Python package using system's Python installation. checks Python installed accessible, proceeds uninstall package. Finally, uninstall_python_package verifies package successfully uninstalled.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/uninstall_python_package.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Uninstall a Python Package — uninstall_python_package","text":"","code":"uninstall_python_package(package_name, python_path = Sys.which(\"python3\"))"},{"path":"https://davidycliao.github.io/flaiR/reference/uninstall_python_package.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Uninstall a Python Package — uninstall_python_package","text":"package_name name Python package uninstall. python_path path Python executable. provided, uses system's default Python path.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/uninstall_python_package.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Uninstall a Python Package — uninstall_python_package","text":"Invisibly returns TRUE package successfully uninstalled, otherwise stops error message.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/uninstall_python_package.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Uninstall a Python Package — uninstall_python_package","text":"","code":"if (FALSE) { # \\dontrun{ uninstall_python_package(\"numpy\") } # }"},{"path":[]},{"path":"https://davidycliao.github.io/flaiR/news/index.html","id":"major-changes-0-0-7","dir":"Changelog","previous_headings":"","what":"Major Changes","title":"flaiR 0.0.7 (2024-12-31)","text":"release brings significant enhancements streamline natural language processing workflows R, introducing Docker support unified function interfaces.","code":""},{"path":"https://davidycliao.github.io/flaiR/news/index.html","id":"new-features-0-0-7","dir":"Changelog","previous_headings":"Major Changes","what":"New Features","title":"flaiR 0.0.7 (2024-12-31)","text":"Added comprehensive tutorial section Flair NLP embedding extraction regression analysis Introduced Docker support RStudio Server integration Enhanced documentation detailed usage examples","code":""},{"path":[]},{"path":"https://davidycliao.github.io/flaiR/news/index.html","id":"r-package-installation-0-0-7","dir":"Changelog","previous_headings":"Installation Guide","what":"R Package Installation","title":"flaiR 0.0.7 (2024-12-31)","text":"","code":"# Install from GitHub remotes::install_github(\"davidycliao/flaiR\")"},{"path":[]},{"path":"https://davidycliao.github.io/flaiR/news/index.html","id":"intelamd-processors-0-0-7","dir":"Changelog","previous_headings":"Installation Guide > Docker Installation & Usage","what":"Intel/AMD Processors:","title":"flaiR 0.0.7 (2024-12-31)","text":"","code":"# Pull and run docker pull ghcr.io/davidycliao/flair:latest docker run -p 8787:8787 ghcr.io/davidycliao/flair:latest"},{"path":"https://davidycliao.github.io/flaiR/news/index.html","id":"apple-silicon-m1m2-mac-0-0-7","dir":"Changelog","previous_headings":"Installation Guide > Docker Installation & Usage","what":"Apple Silicon (M1/M2 Mac):","title":"flaiR 0.0.7 (2024-12-31)","text":"Access RStudio Server: - Open browser: http://localhost:8787 - Username: rstudio - Password: rstudio123","code":"# Pull and run with platform specification docker pull --platform linux/amd64 ghcr.io/davidycliao/flair:latest docker run --platform linux/amd64 -p 8787:8787 ghcr.io/davidycliao/flair:latest"},{"path":"https://davidycliao.github.io/flaiR/news/index.html","id":"function-optimizations-0-0-7","dir":"Changelog","previous_headings":"Installation Guide","what":"Function Optimizations","title":"flaiR 0.0.7 (2024-12-31)","text":"Unified POS tagging streamlined interface: combined get_pos() functions Consolidated NER functionality single get_entities() function Improved code performance reliability","code":""},{"path":"https://davidycliao.github.io/flaiR/news/index.html","id":"code-cleanup-0-0-7","dir":"Changelog","previous_headings":"Installation Guide","what":"Code Cleanup","title":"flaiR 0.0.7 (2024-12-31)","text":"Removed deprecated sentiment analysis functions Simplified API better usability Enhanced error handling feedback","code":""},{"path":"https://davidycliao.github.io/flaiR/news/index.html","id":"technical-notes-0-0-7","dir":"Changelog","previous_headings":"","what":"Technical Notes","title":"flaiR 0.0.7 (2024-12-31)","text":"Release Date: 2024-12-30 Version: 0.0.7 Environment: Python 3.9+, R 4.0+ Docker: Integrated RStudio Server pre-configured Python environment M1/M2 Mac Support: Compatible Rosetta 2 Dependencies: numpy 1.26.4, scipy 1.12.0 optimal compatibility","code":""},{"path":"https://davidycliao.github.io/flaiR/news/index.html","id":"flair-006-2023-10-29","dir":"Changelog","previous_headings":"","what":"flaiR 0.0.6 (2023-10-29)","title":"flaiR 0.0.6 (2023-10-29)","text":"flair {flaiR} renamed flair() import_flair() avoid overlapping conventional practice import flair Python. install_python_package() uninstall_python_package() new functions install uninstall Python packages using pip environment used flaiR package. Add new training data grandstanding training data Ju Yeon Park’s paper. zzz.R revised code proceeds three steps. First, installing loading package, {flaiR} utilizes system’s environment tool undergoes three evaluation stages. Initially, {flaiR} requires least Python 3 installed device. Python 3 available, unable install {flaiR} successfully. requirement met, system checks appropriate versions PyTorch Flair. primary focus Flair. already installed, see message indicating ‘Flair installed Python’. process represents new format loading Python environment used flaiR package. Add example datasets (cc_muller hatespeech_zh_tw) tutorials documentation.","code":""},{"path":"https://davidycliao.github.io/flaiR/news/index.html","id":"flair-005-2023-10-01","dir":"Changelog","previous_headings":"","what":"flaiR 0.0.5 (2023-10-01)","title":"flaiR 0.0.5 (2023-10-01)","text":"Added tests monitor function operation. Added wrapped functions integrating Python code. Created function coloring entities. Provided tutorials interacting R Python using Flair. Notice Python 3.x flair may fail install Python dependencies windows-latest due potential compatibility issues latest Python versions Windows. fix , modified Python version actions/setup-python@v2 step use Python 3.9 lower version. Added two new example datasets tutorials documentation.  ","code":""},{"path":"https://davidycliao.github.io/flaiR/news/index.html","id":"flair-003-2023-09-10","dir":"Changelog","previous_headings":"","what":"flaiR 0.0.3 (2023-09-10)","title":"flaiR 0.0.3 (2023-09-10)","text":"Modifications Overview Added show.text_id gc.active parameters get_entities(), get_pos(), get_sentiment(). Enhanced batch processing introduction batch_size functions get_entities_batch(), get_pos_batch(), get_sentiment_batch(). Introduced device parameter specify computation device. Introduction New Parameters: show.text_id: activated (TRUE), actual text (labeled ‘text_id’) entity derived appended resulting dataset. Although enriching output validation traceability, users cautious, might inflate output size. default, option remains deactivated (FALSE). context, previously, ‘text_id’ intrinsically generated, potentially elevating R’s memory consumption. gc.active: Activating (TRUE) trigger garbage collector post-text processing. action aids memory optimization relinquishing unallocated memory spaces, crucial step, particularly processing extensive text dataset. default set FALSE, users managing larger texts consider setting gc.active TRUE. Though action doesn’t bolster computational efficiency, circumvent potential RStudio crashes. Batch Processing Enhancement: inception batch_size parameter (defaulted 5) get_entities_batch(), get_pos_batch(), get_sentiment_batch() augments batch processing capabilities. addition led creation internal function named process_batch proficiently manage text batch linked doc_ids. core functionality adapted segregate texts doc_ids specific batches, subsequently processed via process_batch function, final results amalgamated seamlessly. device: descriptive character string pinpointing computation device. Users can opt “cpu” GPU device number string format. instance, representing primary GPU 0. GPU device number furnished, system endeavor harness specific GPU, “cpu” default setting. batch_size: integer specifying size batch. Default 5.  ","code":""},{"path":"https://davidycliao.github.io/flaiR/news/index.html","id":"flair-001-development-version","dir":"Changelog","previous_headings":"","what":"flaiR 0.0.1 (development version)","title":"flaiR 0.0.1 (development version)","text":"features flaiR currently include part--speech tagging, sentiment tagging, named entity recognition tagging. flaiR requires Python version 3.7 higher operate concurrently. create_flair_env(): function install Flair Python library using reticulate R package, automatically generated.","code":""}]
