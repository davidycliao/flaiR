---
title: "Quick Start"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Quick Start}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r include=FALSE}
library(reticulate)
library(flaiR)
reticulate::py_install("flair")
system(paste(reticulate::py_config()$python, "-m pip install flair"))
```


## Why Write {flaiR} to Access fair NLP in Python?
<div style="text-align: justify">

Flair ([Zalando Research](https://engineering.zalando.com/posts/2018/11/zalando-research-releases-flair.html) ) stands out as a notably feature-rich and user-friendly NLP framework, offering a robust toolset to navigate through a myriad of natural language processing challenges.  Flair offers intuitive interfaces for utilizing and combining various word and document embeddings, including the proposed Flair embeddings and numerous transformers. It boasts exceptional multilingual support, particularly in various embedding frameworks (e.g., Glove) and transformer-based models (e.g., BERT), and is equipped with pre-trained models `and` context-aware capabilities. Flair also establishes dependencies with primary NLP Python libraries (such as gensim, transformer, flair, and more); installing {`flaiR`} will subsequently install other related NLP packages in Python. By installing {`flaiR`} in R, we can seamlessly utilize the Python Flair NLP library in R alongside basic Python libraries (such as [NumPy](https://numpy.org) and [Pandas](https://pandas.pydata.org)) and modern Python NLP toolkits and frameworks (such as [PyTorch](https://pytorch.org) and [Gensim](https://radimrehurek.com/gensim/intro.html)) through reticulate in an R environment.


</div>


&nbsp;

-----

## Install `flaiR` with Using [`remotes`](https://github.com/r-lib/remotes)

<div style="text-align: justify">

`flaiR` is built on top of the reticulate package and incorporates key functions to access the core features of __FlairNLP__, returning data in a tidy and clean [`data.table`](https://cran.r-project.org/web/packages/data.table/index.html). The installation consists of two parts: first, install [Python 3.7](https://www.python.org/downloads/) or higher, and second, install [R](https://cran.r-project.org) (version 3.6.3 or higher) along with RStudio. ~~Additionally, you'll also need [`Anaconda`](Anaconda) to assist `reticulate` in setting up your Python environment, as well as enabling your RStudio to identify the environment.~~

__System Requirement:__

- Python (>= 3.7.0)

- R (>= 3.6.3)

- RStudio ___(recommended)___

- Anaconda ___(optional)___


If you're using Python-based packages in R for the first time, such as {`flaiR`} or {`reticulate`}, you probably haven't installed a Conda environment yet. When loading flaiR in R, two main steps occur. First, __a [conda](https://docs.conda.io/projects/conda/en/4.6.0/_downloads/52a95608c49671267e40c689e0bc00ca/conda-cheatsheet.pdf) environment is created through {[reticulate](https://ugoproto.github.io/ugo_r_doc/pdf/reticulate.pdf)}__. During this process, you will observe numerous messages related to the installation of the Python environment and the Python flair module. Notably, flair has numerous dependencies, including libraries related to transformers (like the Pytorch, gensim, flair and HuggingFace, etc). Thus, the installation might take some time to complete. 

When you copy the command below, you will generally be asked to upgrade the package. This is because this package operates on the {`reticulate`}, and when your packages in R are  outdated, RStudio would likely display __“These packages have more recent versions available.”__ to prompt you to update. We recommend that you update.


```
install.packages("remotes")
remotes::install_github("davidycliao/flaiR", force = TRUE)
library(flaiR)
```

Afterward, you might see the message __"Virtual environment 'r-reticulate' successfully created."__ Next, you will be prompted to confirm whether or not you want to use `r-reticulate`. Enter __"Yes,"__ and it will automatically install `flair` via your conda environment in Python.  If there are any issues with the installation, feel free to ask in the <u>[Discussion](https://github.com/davidycliao/flaiR/discussions)</u>.

</div>

&nbsp;

-----


## Wrapped Functions

<div style="text-align: justify">

For R users, {`flairR`} is built on top of {reticulate}, enabling you to interact directly with Python modules in R and providing seamless support for documents in the R community. __Please note that the following basic examples and explanations are derived from the official [Flair NLP](https://flairnlp.github.io/docs/intro) Python documentation and tutorial.__

</div>


| **Wrapped Functions**                             | Corresponding Practice in Python                          | 
|---------------------------------------------------|-----------------------------------------------------------|
| `flair_datasets()`                                | from flair.datasets import *                              |
| `flair_data.sentence()`                           | from flair.data import Sentence                           |
| `flair_nn.classifier_load()`                      | from flair.embeddings import *                            |
| `flair_embeddings()`                              | from flair.nn import Classifier                           |
| `flair_embeddings.FlairEmbeddings()`              | from flair.embeddings import FlairEmbeddings              |
| `flair_embeddings.TransformerWordEmbeddings()`    | from flair.embeddings import TransformerWordEmbeddings    |
| `flair_embeddings.WordEmbeddings()`               | from flair.embeddings import WordEmbeddings               |
| `flair_embeddings.TransformerDocumentEmbeddings()`| from flair.embeddings import TransformerDocumentEmbeddings|
| `flair_splitter.SegtokSentenceSplitter()`         | flair_splitter.SegtokSentenceSplitter                     |
| `flair_models.sequencetagger()`                   | from flair.models import SequenceTagger                   |
| `flair_trainers()`                                | from flair.trainers import *                              |
| `flair_models()`                                  | from flair.models import *                                |
| `flair_models.TextClassifier()`                   | from flair.models import TextClassifier                   |
 
 
 

&nbsp;

### __Tag Entities in Text__ 

<div style="text-align: justify">

Let's run named entity recognition (NER) over the following example sentence: "I love Berlin and New York. To do this, all you need is to make a Sentence for this text, load a pre-trained model and use it to predict tags for the sentence:

```{r}
library(flaiR)

# make a sentence
sentence = flair_data.sentence('I love Berlin and New York.')

# load the NER tagger
tagger = flair_nn.classifier_load('ner')

# run NER over sentence
tagger$predict(sentence)
```

This should print:
```{r}
# print the sentence with all annotations
print(sentence)
```

Use a for loop to print out each pos tag.
```{r}
for (i in seq_along(sentence$get_labels())) {
      print(sentence$get_labels()[[i]])
  }
```

</div>

&nbsp;


### __Tag Part-of-Speech in Text__ 

<div style="text-align: justify">

We use flair/pos-english for POS tagging in the standard models on Hugging Face.
```{r}
library(flaiR)

# make a sentence
sentence = flair_data.sentence('I love Berlin and New York.')

# load the NER tagger
tagger = flair_nn.classifier_load('pos')

# run NER over sentence
tagger$predict(sentence)
```

This should print:

```{r}
# print the sentence with all annotations
print(sentence)
```

Use a for loop to print out each pos tag.
```{r}
for (i in seq_along(sentence$get_labels())) {
      print(sentence$get_labels()[[i]])
  }
```

</div>

&nbsp;

### __Detect Sentiment__

<div style="text-align: justify">

Let's run sentiment analysis over the same sentence to determine whether it is POSITIVE or NEGATIVE.

You can do this with essentially the same code as above. Just instead of loading the 'ner' model, you now load the 'sentiment' model:

```{r}
library(flaiR)

# make a sentence
sentence = flair_data.sentence('I love Berlin and New York.')

# load the flair_nn.classifier_load tagger
tagger = flair_nn.classifier_load("sentiment")

# run sentiment analysis over sentence
tagger$predict(sentence)
```

```{r}
# print the sentence with all annotations
print(sentence)
```

</div>

&nbsp;


### __Embeddings__


__Embeddings Words with Transformers__

<div style="text-align: justify">

Let's use a standard BERT model (bert-base-uncased) to embed the sentence "the grass is green".
Simply instantate `flair_embeddings.TransformerWordEmbeddings()`  and call `$embed()` over the sentence object:

```{r}
library(flaiR)

# initiate TransformerWordEmbeddings
embedding = flair_embeddings.TransformerWordEmbeddings('bert-base-uncased')

# create a sentence
sentence = flair_data.sentence('The grass is green .')

# embed words in sentence
embedding$embed(sentence)
```
This will cause each word in the sentence to be embedded. You can iterate through the words and get each embedding like this:

```{r}
for (i in seq_along(sentence$tokens)) {
  cat("Token: ",  reticulate::py_str(sentence$tokens[[i]]), "\n")
  # Access the embedding of the token, converting it to an R object, 
  # and print the first 15 elements of the vector.
  token_embedding <- sentence$tokens[[1]]$embedding
  print(head(token_embedding, 15))
}
```

</div>

&nbsp;

__Embeddings Documents with Transformers__

<div style="text-align: justify">

Sometimes you want to have an embedding for a whole document, not only individual words. In this case, use one of the DocumentEmbeddings classes in Flair. Let's again use a standard BERT model to get an embedding for the entire sentence:

```{r}
# initiate TransformerWordEmbeddings
embedding = flair_embeddings.TransformerDocumentEmbeddings('bert-base-uncased')

# create a sentence
sentence = flair_data.sentence('The grass is green .')

# embed words in sentence
embedding$embed(sentence)
```

Use the `$embedding` method to extract the entire embedding from the sentence and print the embedding as follows:

```{r}
print(head(sentence$embedding, n = 20))
```

</div>

&nbsp;

__How to Stack Embeddings__

<div style="text-align: justify">


Flair allows you to combine embeddings into "embedding stacks". When not fine-tuning, using combinations of embeddings often gives best results!

Use the `StackedEmbeddings` class and instantiate it by passing a list of embeddings that you wish to combine. For instance, lets combine classic `GloVe` embeddings with `forward` and `backward` Flair embeddings.

First, instantiate the two embeddings you wish to combine:

```{r}
# init standard GloVe embedding
glove_embedding = flair_embeddings.WordEmbeddings('glove')

# init Flair forward and backwards embeddings
flair_embedding_forward = flair_embeddings.FlairEmbeddings('news-forward')
flair_embedding_backward = flair_embeddings.FlairEmbeddings('news-backward')
```

Now, instantiate the `StackedEmbeddings` class and pass a list containing these two embeddings. Both R and Python have list functionality. Let's create a StackedEmbedding object that combines the GloVe and forward/backward Flair embeddings.
```{r}
stacked_embeddings <- flair_embeddings()$StackedEmbeddings(list(glove_embedding, 
                                                                flair_embedding_forward,
                                                                flair_embedding_backward))
```


Next, use the `$embed()` method to transform text into vectors for your sentences.
```{r}
# make a sentence
sentence = flair_data.sentence('I love Berlin and New York.')

# just embed a sentence using the StackedEmbedding as you would with any single embedding.
stacked_embeddings$embed(sentence)
```


Words are now embedded using a concatenation of three different embeddings. This means that the resulting embedding vector is still a single PyTorch vector.


```{r}
for (i in seq_along(sentence$tokens)) {
  cat("Token: ",  reticulate::py_str(sentence$tokens[[i]]), "\n")
  # Access the embedding of the token, converting it to an R object, 
  # and print the first 15 elements of the vector.
  token_embedding <- sentence$tokens[[1]]$embedding
  print(head(token_embedding, 15))
}
```

</div>

&nbsp;

-----

## Featured Functions for NLP Tasks with data.table Output

<div style="text-align: justify">


To enhance more efficient utilization in social science research, {flairR} encapsulates FlairNLP Python with three principal functions to extract features in a neat and orderly format using [data.table](https://cran.r-project.org/web/packages/data.table/index.html). Through these featured functions, you don't have to write loops to format parsed output on your own; {`flairR`} will automatically do it for you in a neat format. The main features include [**part-of-speech tagging**](https://davidycliao.github.io/flaiR/articles/get_pos.html), [**transformer-based sentiment analysis**](https://davidycliao.github.io/flaiR/articles/get_entities.html), and [**named entity recognition**](https://davidycliao.github.io/flaiR/articles/get_sentiments.html).



| **Core  Featured Function in flaiR**                    | Loader                     | Supported Models                                                                                                         |
|----------------------------------------------|----------------------------|--------------------------------------------------------------------------------------------------------------------------|
| `get_entities()`, `get_entities_batch()`     | `load_tagger_ner()`        | `en` (English), `fr` (French), `da` (Danish), `nl` (Dutch), and more.                                                    |
| `get_pos()`, `get_pos_batch()`               | `load_tagger_pos()`        | `pos` (English POS), `fr-pos` (French POS), `de-pos` (German POS), `nl-pos` (Dutch POS), and more.                       |
| `get_sentiments()`, `get_sentiments_batch()` | `load_tagger_sentiments()` | `sentiment` (English) , `sentiment-fast `(English) , `de-offensive-language` (German offensive language detection model) |

</div>

&nbsp;


### __Tagging Parts-of-Speech with Flair Models__

<div style="text-align: justify">


You can load the pre-trained model `"pos-fast"`. For more pre-trained models, see https://flairnlp.github.io/docs/tutorial-basics/part-of-speech-tagging#-in-english.

```{r}
texts <- c("UCD is one of the best universities in Ireland.",
           "UCD has a good campus but is very far from my apartment in Dublin.",
           "Essex is famous for social science research.",
           "Essex is not in the Russell Group, but it is famous for political science research and in 1994 Group.",
           "TCD is the oldest university in Ireland.",
           "TCD is similar to Oxford.")

doc_ids <- c("doc1", "doc2", "doc3", "doc4", "doc5", "doc6")
```

```{r}
library(flaiR)
```

```{r}
tagger_pos <- load_tagger_pos("pos-fast")
```

```{r}
results <- get_pos(texts, doc_ids, tagger_pos)
head(results, n = 10)
```

</div>

&nbsp;


### __Tagging Entities with Flair Models__

<div style="text-align: justify">

Load the pretrained model "ner". For more pretrained models, see https://flairnlp.github.io/docs/tutorial-basics/tagging-entities.



```{r}
library(flaiR)
```

```{r}
tagger_ner <- load_tagger_ner("ner")
```

```{r}
results <- get_entities(texts, doc_ids, tagger_ner)
head(results, n = 10)
```

</div>

&nbsp;


### __Tagging Sentiment__

<div style="text-align: justify">


Load the pretrained model "`sentiment`". The pre-trained models of "`sentiment`", "`sentiment-fast`", and "`de-offensive-language`" are currently available. For more pretrained models, see https://flairnlp.github.io/docs/tutorial-basics/tagging-sentiment.


```{r}
library(flaiR)
```

```{r}
tagger_sent <- load_tagger_sentiments("sentiment")
```


```{r}
results <- get_sentiments(texts, doc_ids, tagger_sent)
head(results, n = 10)
```

</div>

&nbsp;

-----


## How to Contribute

<div style="text-align: justify">

I currently am working as a postdoctoral researcher at  [Text and Policy Research Group](https://text-and-policy.com) in [SPIRe](https://www.ucd.ie/spire/) of University College Dublin, immersed in numerous ongoing research projects. My availability to maintain, test, and create examples for R users may be limited. I warmly invite R users who share similar interests to join in contributing to this package. Contributions – whether they be comments, code suggestions, tutorial examples, or forking the repository – are greatly appreciated. Please note that the `flaiR` is released with the [Contributor Code of Conduct](https://github.com/davidycliao/flaiR/blob/master/CONDUCT.md). By contributing to this project, you agree to abide by its terms. 


</div>




