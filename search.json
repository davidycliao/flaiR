[{"path":"https://davidycliao.github.io/flaiR/articles/flair_models.html","id":"list-of-ner-models","dir":"Articles","previous_headings":"","what":"List of NER Models","title":"Flair Models","text":"Source: https://flairnlp.github.io/docs/tutorial-basics/tagging-entities  ","code":""},{"path":"https://davidycliao.github.io/flaiR/articles/flair_models.html","id":"list-of-pos-models","dir":"Articles","previous_headings":"","what":"List of POS Models","title":"Flair Models","text":"Source: https://flairnlp.github.io/docs/tutorial-basics/part--speech-tagging  ","code":""},{"path":"https://davidycliao.github.io/flaiR/articles/flair_models.html","id":"list-of-sentiment-models","dir":"Articles","previous_headings":"","what":"List of Sentiment Models","title":"Flair Models","text":"Source: https://flairnlp.github.io/docs/tutorial-basics/tagging-sentiment","code":""},{"path":"https://davidycliao.github.io/flaiR/articles/get_entities.html","id":"generic-approach-using-pre-trained-ner-english-model","dir":"Articles","previous_headings":"","what":"Generic Approach Using Pre-trained NER English Model","title":"Tagging Named Entities with Flair Standard Models","text":"Use load_tagger_ner call NER pretrained model. model downloaded Flair’s Hugging Face repo. Thus, ensure internet connection. downloaded, model stored .flair cache device. , ’ve downloaded hasn’t manually removed, executing command trigger download. want computation run faster, recommended keep show.text_id set FALSE default.","code":"library(flaiR) data(\"uk_immigration\") uk_immigration <- head(uk_immigration, 10) tagger_ner <- load_tagger_ner(\"ner\") #> 2023-10-09 17:22:04,115 SequenceTagger predicts: Dictionary with 20 tags: <unk>, O, S-ORG, S-MISC, B-PER, E-PER, S-LOC, B-ORG, E-ORG, I-PER, S-PER, B-MISC, I-MISC, E-MISC, I-ORG, B-LOC, E-LOC, I-LOC, <START>, <STOP> time <- system.time({     results <- get_entities(uk_immigration$text,                             uk_immigration$speaker,                              tagger_ner,                             show.text_id = FALSE                             )     gc() })  print(time) #>    user  system elapsed  #>  46.279   0.564  47.122 print(results) #>               doc_id                          entity  tag #>  1: Philip Hollobone                    Conservative  ORG #>  2: Philip Hollobone Liberal Democrat Front Benchers  ORG #>  3: Philip Hollobone                    Back Benches MISC #>  4: Philip Hollobone                       Kettering  LOC #>  5: Philip Hollobone                            Sikh MISC #>  6: Philip Hollobone                       Kettering  LOC #>  7: Philip Hollobone                       Kettering  LOC #>  8: Philip Hollobone                         British MISC #>  9: Philip Hollobone                  United Kingdom  LOC #> 10: Philip Hollobone                          Norman MISC #> 11: Philip Hollobone                  United Kingdom  LOC #> 12:  Stewart Jackson                          Friend  PER #> 13:  Stewart Jackson        Archbishop of Canterbury  ORG #> 14:  Stewart Jackson                           Carey  PER #> 15: Philip Hollobone                          Friend  PER #> 16: Philip Hollobone                  United Kingdom  LOC #> 17: Philip Hollobone                              UK  LOC #> 18: Philip Hollobone                          Europe  LOC #> 19: Philip Hollobone                           Malta  LOC #> 20:  Stewart Jackson                         Barking  LOC #> 21:  Stewart Jackson                        Dagenham  LOC #> 22:  Stewart Jackson                British National  ORG #> 23:  Stewart Jackson                    Conservative  ORG #> 24:  Stewart Jackson                          Friend  PER #> 25:  Stewart Jackson                      Folkestone  LOC #> 26:  Stewart Jackson                           Hythe  LOC #> 27:  Stewart Jackson                          Howard  PER #> 28: Philip Hollobone                          Friend  PER #> 29: Philip Hollobone                         Shipley  PER #> 30: Philip Hollobone                   Philip Davies  PER #> 31: Philip Hollobone                        Solihull  LOC #> 32: Philip Hollobone                     Lorely Burt  ORG #> 33: Philip Hollobone                    Peterborough  LOC #> 34: Philip Hollobone                         Jackson  PER #> 35: Philip Hollobone                          Friend  PER #> 36:    Philip Davies                          Friend  PER #> 37:    Philip Davies                      Government  ORG #> 38: Philip Hollobone                       Kettering  LOC #> 39: Philip Hollobone                      Government  ORG #> 40: Philip Hollobone                       Kettering  LOC #> 41: Philip Hollobone                       Kettering  LOC #> 42: Philip Hollobone               Migrationwatch UK  ORG #> 43: Philip Hollobone                      Carshalton  LOC #> 44: Philip Hollobone                      Wallington  LOC #> 45: Philip Hollobone                       Tom Brake  PER #> 46: Philip Hollobone                            <NA> <NA> #> 47:      Phil Woolas                       Gentleman  PER #> 48:      Phil Woolas                      Carshalton  LOC #> 49:      Phil Woolas                      Wallington  LOC #> 50:      Phil Woolas                       Tom Brake  PER #>               doc_id                          entity  tag"},{"path":"https://davidycliao.github.io/flaiR/articles/get_entities.html","id":"batch-processing","dir":"Articles","previous_headings":"","what":"Batch Processing","title":"Tagging Named Entities with Flair Standard Models","text":"Processing texts individually can inefficient memory-intensive. hand, processing texts simultaneously surpass memory constraints, especially document dataset sizable. Parsing documents smaller batches may provide optimal compromise two scenarios. Batch processing can enhance efficiency aid memory management.","code":"batch_process_time <- system.time({     batch_process_results  <- get_entities_batch(uk_immigration$text,                                                  uk_immigration$speaker,                                                   tagger_ner,                                                   show.text_id = FALSE,                                                  batch_size = 5)     gc() }) #> CPU is used. #> Processing batch 1 out of 2... #> Processing batch 2 out of 2... print(batch_process_time) #>    user  system elapsed  #>  32.616   0.501  34.352 print(batch_process_results) #>               doc_id                          entity  tag text_id #>  1: Philip Hollobone                    Conservative  ORG      NA #>  2: Philip Hollobone Liberal Democrat Front Benchers  ORG      NA #>  3: Philip Hollobone                    Back Benches MISC      NA #>  4: Philip Hollobone                       Kettering  LOC      NA #>  5: Philip Hollobone                            Sikh MISC      NA #>  6: Philip Hollobone                       Kettering  LOC      NA #>  7: Philip Hollobone                       Kettering  LOC      NA #>  8: Philip Hollobone                         British MISC      NA #>  9: Philip Hollobone                  United Kingdom  LOC      NA #> 10: Philip Hollobone                          Norman MISC      NA #> 11: Philip Hollobone                  United Kingdom  LOC      NA #> 12:  Stewart Jackson                          Friend  PER      NA #> 13:  Stewart Jackson        Archbishop of Canterbury  ORG      NA #> 14:  Stewart Jackson                           Carey  PER      NA #> 15: Philip Hollobone                          Friend  PER      NA #> 16: Philip Hollobone                  United Kingdom  LOC      NA #> 17: Philip Hollobone                              UK  LOC      NA #> 18: Philip Hollobone                          Europe  LOC      NA #> 19: Philip Hollobone                           Malta  LOC      NA #> 20:  Stewart Jackson                         Barking  LOC      NA #> 21:  Stewart Jackson                        Dagenham  LOC      NA #> 22:  Stewart Jackson                British National  ORG      NA #> 23:  Stewart Jackson                    Conservative  ORG      NA #> 24:  Stewart Jackson                          Friend  PER      NA #> 25:  Stewart Jackson                      Folkestone  LOC      NA #> 26:  Stewart Jackson                           Hythe  LOC      NA #> 27:  Stewart Jackson                          Howard  PER      NA #> 28: Philip Hollobone                          Friend  PER      NA #> 29: Philip Hollobone                         Shipley  PER      NA #> 30: Philip Hollobone                   Philip Davies  PER      NA #> 31: Philip Hollobone                        Solihull  LOC      NA #> 32: Philip Hollobone                     Lorely Burt  ORG      NA #> 33: Philip Hollobone                    Peterborough  LOC      NA #> 34: Philip Hollobone                         Jackson  PER      NA #> 35: Philip Hollobone                          Friend  PER      NA #> 36:    Philip Davies                          Friend  PER      NA #> 37:    Philip Davies                      Government  ORG      NA #> 38: Philip Hollobone                       Kettering  LOC      NA #> 39: Philip Hollobone                      Government  ORG      NA #> 40: Philip Hollobone                       Kettering  LOC      NA #> 41: Philip Hollobone                       Kettering  LOC      NA #> 42: Philip Hollobone               Migrationwatch UK  ORG      NA #> 43: Philip Hollobone                      Carshalton  LOC      NA #> 44: Philip Hollobone                      Wallington  LOC      NA #> 45: Philip Hollobone                       Tom Brake  PER      NA #> 46: Philip Hollobone                            <NA> <NA>      NA #> 47:      Phil Woolas                       Gentleman  PER      NA #> 48:      Phil Woolas                      Carshalton  LOC      NA #> 49:      Phil Woolas                      Wallington  LOC      NA #> 50:      Phil Woolas                       Tom Brake  PER      NA #>               doc_id                          entity  tag text_id"},{"path":"https://davidycliao.github.io/flaiR/articles/get_pos.html","id":"generic-approach-using-part-of-speech-tagging","dir":"Articles","previous_headings":"","what":"Generic Approach Using Part-of-Speech Tagging","title":"Tagging Part-of-Speech Tagging with Flair Standard Models","text":"Download de-pos part--speech tagging model FlairNLP Hugging Face.","code":"library(flaiR) data(\"de_immigration\") uk_immigration <- head(uk_immigration, 2) tagger_pos <- load_tagger_pos(\"pos\") #> 2023-10-09 17:23:34,926 SequenceTagger predicts: Dictionary with 53 tags: <unk>, O, UH, ,, VBD, PRP, VB, PRP$, NN, RB, ., DT, JJ, VBP, VBG, IN, CD, NNS, NNP, WRB, VBZ, WDT, CC, TO, MD, VBN, WP, :, RP, EX, JJR, FW, XX, HYPH, POS, RBR, JJS, PDT, NNPS, RBS, AFX, WP$, -LRB-, -RRB-, ``, '', LS, $, SYM, ADD results <- get_pos(uk_immigration$text,                     uk_immigration$speaker, tagger_pos,                     show.text_id = FALSE,                    gc.active = FALSE) print(results) #>                doc_id token_id text_id   token tag precision #>   1: Philip Hollobone        0      NA       I PRP    1.0000 #>   2: Philip Hollobone        1      NA   thank VBP    0.9996 #>   3: Philip Hollobone        2      NA     Mr. NNP    1.0000 #>   4: Philip Hollobone        3      NA Speaker NNP    1.0000 #>   5: Philip Hollobone        4      NA     for  IN    1.0000 #>  ---                                                         #> 440:  Stewart Jackson       66      NA parties NNS    1.0000 #> 441:  Stewart Jackson       67      NA      in  IN    1.0000 #> 442:  Stewart Jackson       68      NA    this  DT    1.0000 #> 443:  Stewart Jackson       69      NA country  NN    1.0000 #> 444:  Stewart Jackson       70      NA       ?   .    0.9949"},{"path":"https://davidycliao.github.io/flaiR/articles/get_pos.html","id":"batch-processing","dir":"Articles","previous_headings":"","what":"Batch Processing","title":"Tagging Part-of-Speech Tagging with Flair Standard Models","text":"","code":"batch_process_results  <- get_pos_batch(uk_immigration$text,                                         uk_immigration$speaker,                                          tagger_pos,                                          show.text_id = FALSE,                                         batch_size = 10,                                         device = \"mps\",                                         verbose = TRUE) #> MPS is used on Mac M1/M2. #> Processing batch starting at index: 1 print(batch_process_results) #>                doc_id token_id text_id   token tag precision #>   1: Philip Hollobone        0      NA       I PRP    1.0000 #>   2: Philip Hollobone        1      NA   thank VBP    0.9996 #>   3: Philip Hollobone        2      NA     Mr. NNP    1.0000 #>   4: Philip Hollobone        3      NA Speaker NNP    1.0000 #>   5: Philip Hollobone        4      NA     for  IN    1.0000 #>  ---                                                         #> 448:             <NA>        0      NA      NA NNP    0.8859 #> 449:             <NA>        0      NA      NA NNP    0.8859 #> 450:             <NA>        0      NA      NA NNP    0.8859 #> 451:             <NA>        0      NA      NA NNP    0.8859 #> 452:             <NA>        0      NA      NA NNP    0.8859"},{"path":"https://davidycliao.github.io/flaiR/articles/get_sentiments.html","id":"an-example-using-sentiment-model-pre-trained-english-model","dir":"Articles","previous_headings":"","what":"An Example Using sentiment Model (Pre-trained English Model)","title":"Tagging Sentiment with Flair Standard Models","text":"Download English sentiment model FlairNLP Hugging Face. Currently, also supports large English sentiment model German pre-trained model.","code":"library(flaiR) data(\"uk_immigration\") uk_immigration <- head(uk_immigration, 5) tagger_sent <- load_tagger_sentiments(\"sentiment\") results <- get_sentiments(uk_immigration$text, seq_len(nrow(uk_immigration)),                           tagger_sent) print(results) #>    doc_id sentiment     score #> 1:      1  POSITIVE 0.8097585 #> 2:      2  POSITIVE 0.9990165 #> 3:      3  POSITIVE 0.8827487 #> 4:      4  NEGATIVE 0.9997155 #> 5:      5  POSITIVE 0.8604354"},{"path":"https://davidycliao.github.io/flaiR/articles/get_sentiments.html","id":"batch-processing-in-english-sentiment-model","dir":"Articles","previous_headings":"","what":"Batch Processing in English Sentiment Model","title":"Tagging Sentiment with Flair Standard Models","text":"","code":"batch_process_results  <- get_sentiments_batch(uk_immigration$text,                                                uk_immigration$speaker,                                                 tagger_sent,                                                 show.text_id = FALSE,                                                batch_size = 2,                                                verbose = TRUE) #> CPU is used. #> Processing batch 1 out of 3... #> Processing batch 2 out of 3... #> Processing batch 3 out of 3... print(batch_process_results) #>              doc_id sentiment     score #> 1: Philip Hollobone  POSITIVE 0.8097585 #> 2:  Stewart Jackson  POSITIVE 0.9990165 #> 3: Philip Hollobone  POSITIVE 0.8827488 #> 4:  Stewart Jackson  NEGATIVE 0.9997155 #> 5: Philip Hollobone  POSITIVE 0.8604354"},{"path":"https://davidycliao.github.io/flaiR/articles/highlight_text.html","id":"create-text-with-named-entities","dir":"Articles","previous_headings":"","what":"Create Text with Named Entities","title":"Highlight Entities with Colors","text":" ","code":"library(flaiR) data(\"uk_immigration\") uk_immigration <- uk_immigration[30,] tagger_ner <- load_tagger_ner(\"ner\") #> 2023-10-09 17:24:21,131 SequenceTagger predicts: Dictionary with 20 tags: <unk>, O, S-ORG, S-MISC, B-PER, E-PER, S-LOC, B-ORG, E-ORG, I-PER, S-PER, B-MISC, I-MISC, E-MISC, I-ORG, B-LOC, E-LOC, I-LOC, <START>, <STOP> result <- get_entities(uk_immigration$text,                        tagger = tagger_ner,                        show.text_id = FALSE                        ) #> Warning in check_texts_and_ids(texts, doc_ids): doc_ids is NULL. #> Auto-assigning doc_ids."},{"path":"https://davidycliao.github.io/flaiR/articles/highlight_text.html","id":"highlight-text-with-entities","dir":"Articles","previous_headings":"","what":"Highlight Text with Entities","title":"Highlight Entities with Colors","text":"","code":"highlighted_text <- highlight_text(text = uk_immigration$text,                                     entities_mapping = map_entities(result)) highlighted_text"},{"path":"https://davidycliao.github.io/flaiR/articles/quickstart.html","id":"install-flair-with-using-remotes","dir":"Articles","previous_headings":"","what":"Install flaiR with Using remotes","title":"Quick Start","text":"flaiR built top reticulate package incorporates key functions access core features FlairNLP, returning data tidy clean data.table. installation consists two parts: first, install Python 3.7 higher, second, install R (version 3.6.3 higher) along RStudio. Additionally, ’ll also need Anaconda assist reticulate setting Python environment, well enabling RStudio identify environment. System Requirement: Python (>= 3.7.0) R (>= 3.6.3) RStudio (recommended) Anaconda (optional) ’re using Python-based packages R first time, {flaiR} {reticulate}, probably haven’t installed Conda environment yet. loading flaiR R, two main steps occur. First, conda environment created {reticulate}. process, observe numerous messages related installation Python environment Python flair module. Notably, flair numerous dependencies, including libraries related transformers (like HuggingFace). Thus, installation might take time complete. copy command , generally asked upgrade package. package operates {reticulate}, packages R outdated, RStudio likely display “packages recent versions available.” prompt update. recommend update. Afterward, might see message “Virtual environment ‘r-reticulate’ successfully created.” Next, prompted confirm whether want use r-reticulate. Enter “Yes,” automatically install flair via conda environment Python. issues installation, feel free ask Discussion.  ","code":"install.packages(\"remotes\") remotes::install_github(\"davidycliao/flaiR\", force = TRUE) library(flaiR)"},{"path":"https://davidycliao.github.io/flaiR/articles/quickstart.html","id":"wrapped-functions","dir":"Articles","previous_headings":"","what":"Wrapped Functions","title":"Quick Start","text":"R users, {flairR} built top {reticulate}, enabling interact directly Python modules R providing seamless support documents R community. Please note following basic examples explanations derived official Flair NLP Python documentation tutorial.  ","code":""},{"path":"https://davidycliao.github.io/flaiR/articles/quickstart.html","id":"tag-entities-in-text","dir":"Articles","previous_headings":"Wrapped Functions","what":"Tag Entities in Text","title":"Quick Start","text":"Let’s run named entity recognition (NER) following example sentence: “love Berlin New York. , need make Sentence text, load pre-trained model use predict tags sentence: print: Use loop print pos tag.  ","code":"library(flaiR)  # make a sentence sentence = flair_data.sentence('I love Berlin and New York.')  # load the NER tagger tagger = flair_nn.classifier_load('ner') #> 2023-10-09 17:24:40,744 SequenceTagger predicts: Dictionary with 20 tags: <unk>, O, S-ORG, S-MISC, B-PER, E-PER, S-LOC, B-ORG, E-ORG, I-PER, S-PER, B-MISC, I-MISC, E-MISC, I-ORG, B-LOC, E-LOC, I-LOC, <START>, <STOP>  # run NER over sentence tagger$predict(sentence) # print the sentence with all annotations print(sentence) #> Sentence[7]: \"I love Berlin and New York.\" → [\"Berlin\"/LOC, \"New York\"/LOC] for (i in seq_along(sentence$get_labels())) {       print(sentence$get_labels()[[i]])   } #> 'Span[2:3]: \"Berlin\"'/'LOC' (0.9812) #> 'Span[4:6]: \"New York\"'/'LOC' (0.9957)"},{"path":"https://davidycliao.github.io/flaiR/articles/quickstart.html","id":"tag-part-of-speech-in-text","dir":"Articles","previous_headings":"Wrapped Functions","what":"Tag Part-of-Speech in Text","title":"Quick Start","text":"use flair/pos-english POS tagging standard models Hugging Face. print: Use loop print pos tag.  ","code":"library(flaiR)  # make a sentence sentence = flair_data.sentence('I love Berlin and New York.')  # load the NER tagger tagger = flair_nn.classifier_load('pos') #> 2023-10-09 17:24:41,611 SequenceTagger predicts: Dictionary with 53 tags: <unk>, O, UH, ,, VBD, PRP, VB, PRP$, NN, RB, ., DT, JJ, VBP, VBG, IN, CD, NNS, NNP, WRB, VBZ, WDT, CC, TO, MD, VBN, WP, :, RP, EX, JJR, FW, XX, HYPH, POS, RBR, JJS, PDT, NNPS, RBS, AFX, WP$, -LRB-, -RRB-, ``, '', LS, $, SYM, ADD  # run NER over sentence tagger$predict(sentence) # print the sentence with all annotations print(sentence) #> Sentence[7]: \"I love Berlin and New York.\" → [\"I\"/PRP, \"love\"/VBP, \"Berlin\"/NNP, \"and\"/CC, \"New\"/NNP, \"York\"/NNP, \".\"/.] for (i in seq_along(sentence$get_labels())) {       print(sentence$get_labels()[[i]])   } #> 'Token[0]: \"I\"'/'PRP' (1.0) #> 'Token[1]: \"love\"'/'VBP' (1.0) #> 'Token[2]: \"Berlin\"'/'NNP' (0.9999) #> 'Token[3]: \"and\"'/'CC' (1.0) #> 'Token[4]: \"New\"'/'NNP' (1.0) #> 'Token[5]: \"York\"'/'NNP' (1.0) #> 'Token[6]: \".\"'/'.' (1.0)"},{"path":"https://davidycliao.github.io/flaiR/articles/quickstart.html","id":"detect-sentiment","dir":"Articles","previous_headings":"Wrapped Functions","what":"Detect Sentiment","title":"Quick Start","text":"Let’s run sentiment analysis sentence determine whether POSITIVE NEGATIVE. can essentially code . Just instead loading ‘ner’ model, now load ‘sentiment’ model:  ","code":"library(flaiR)  # make a sentence sentence = flair_data.sentence('I love Berlin and New York.')  # load the flair_nn.classifier_load tagger tagger = flair_nn.classifier_load(\"sentiment\")  # run sentiment analysis over sentence tagger$predict(sentence) # print the sentence with all annotations print(sentence) #> Sentence[7]: \"I love Berlin and New York.\" → POSITIVE (0.9982)"},{"path":"https://davidycliao.github.io/flaiR/articles/quickstart.html","id":"embeddings","dir":"Articles","previous_headings":"Wrapped Functions","what":"Embeddings","title":"Quick Start","text":"Embeddings Words Transformers Let’s use standard BERT model (bert-base-uncased) embed sentence “grass green”. Simply instantate flair_embeddings.TransformerWordEmbeddings() call $embed() sentence object: cause word sentence embedded. can iterate words get embedding like :   Embeddings Documents Transformers Sometimes want embedding whole document, individual words. case, use one DocumentEmbeddings classes Flair. Let’s use standard BERT model get embedding entire sentence: Use $embedding method extract entire embedding sentence print embedding follows:   Stack Embeddings Flair allows combine embeddings “embedding stacks”. fine-tuning, using combinations embeddings often gives best results! Use StackedEmbeddings class instantiate passing list embeddings wish combine. instance, lets combine classic GloVe embeddings forward backward Flair embeddings. First, instantiate two embeddings wish combine: Now, instantiate StackedEmbeddings class pass list containing two embeddings. R Python list functionality. Let’s create StackedEmbedding object combines GloVe forward/backward Flair embeddings. Next, use $embed() method transform text vectors sentences. Words now embedded using concatenation three different embeddings. means resulting embedding vector still single PyTorch vector.  ","code":"library(flaiR)  # initiate TransformerWordEmbeddings embedding = flair_embeddings.TransformerWordEmbeddings('bert-base-uncased')  # create a sentence sentence = flair_data.sentence('The grass is green .')  # embed words in sentence embedding$embed(sentence) #> [[1]] #> Sentence[5]: \"The grass is green .\" for (i in seq_along(sentence$tokens)) {   cat(\"Token: \",  reticulate::py_str(sentence$tokens[[i]]), \"\\n\")   # Access the embedding of the token, converting it to an R object,    # and print the first 15 elements of the vector.   token_embedding <- sentence$tokens[[1]]$embedding   print(head(token_embedding, 15)) } #> Token:  Token[0]: \"The\"  #> tensor([-0.3904, -1.1946,  0.1296,  0.5806, -0.0847, -0.4520,  1.3699,  0.3850, #>         -0.6132, -0.3246, -0.9899, -0.6897,  0.2754, -0.5867,  0.2399]) #> Token:  Token[1]: \"grass\"  #> tensor([-0.3904, -1.1946,  0.1296,  0.5806, -0.0847, -0.4520,  1.3699,  0.3850, #>         -0.6132, -0.3246, -0.9899, -0.6897,  0.2754, -0.5867,  0.2399]) #> Token:  Token[2]: \"is\"  #> tensor([-0.3904, -1.1946,  0.1296,  0.5806, -0.0847, -0.4520,  1.3699,  0.3850, #>         -0.6132, -0.3246, -0.9899, -0.6897,  0.2754, -0.5867,  0.2399]) #> Token:  Token[3]: \"green\"  #> tensor([-0.3904, -1.1946,  0.1296,  0.5806, -0.0847, -0.4520,  1.3699,  0.3850, #>         -0.6132, -0.3246, -0.9899, -0.6897,  0.2754, -0.5867,  0.2399]) #> Token:  Token[4]: \".\"  #> tensor([-0.3904, -1.1946,  0.1296,  0.5806, -0.0847, -0.4520,  1.3699,  0.3850, #>         -0.6132, -0.3246, -0.9899, -0.6897,  0.2754, -0.5867,  0.2399]) # initiate TransformerWordEmbeddings embedding = flair_embeddings.TransformerDocumentEmbeddings('bert-base-uncased')  # create a sentence sentence = flair_data.sentence('The grass is green .')  # embed words in sentence embedding$embed(sentence) #> [[1]] #> Sentence[5]: \"The grass is green .\" print(head(sentence$embedding, n = 20)) #> tensor([-0.0717, -0.4132, -0.3651,  0.0199, -0.6143, -0.0525,  1.2074, -0.0852, #>         -0.3331,  0.0753, -0.3081, -0.2436,  0.6264,  0.0861,  0.1762, -0.5427, #>          0.4518,  0.5222, -0.0022,  0.2461]) # init standard GloVe embedding glove_embedding = flair_embeddings.WordEmbeddings('glove')  # init Flair forward and backwards embeddings flair_embedding_forward = flair_embeddings.FlairEmbeddings('news-forward') #> Initialized Flair forward embeddings flair_embedding_backward = flair_embeddings.FlairEmbeddings('news-backward') #> Initialized Flair backward embeddings stacked_embeddings <- flair_embeddings()$StackedEmbeddings(list(glove_embedding,                                                                  flair_embedding_forward,                                                                 flair_embedding_backward)) # make a sentence sentence = flair_data.sentence('I love Berlin and New York.')  # just embed a sentence using the StackedEmbedding as you would with any single embedding. stacked_embeddings$embed(sentence) for (i in seq_along(sentence$tokens)) {   cat(\"Token: \",  reticulate::py_str(sentence$tokens[[i]]), \"\\n\")   # Access the embedding of the token, converting it to an R object,    # and print the first 15 elements of the vector.   token_embedding <- sentence$tokens[[1]]$embedding   print(head(token_embedding, 15)) } #> Token:  Token[0]: \"I\"  #> tensor([ 0.6197,  0.5665, -0.4658, -1.1890,  0.4460,  0.0660,  0.3191,  0.1468, #>         -0.2212,  0.7924,  0.2991,  0.1607,  0.0253,  0.1868, -0.3100]) #> Token:  Token[1]: \"love\"  #> tensor([ 0.6197,  0.5665, -0.4658, -1.1890,  0.4460,  0.0660,  0.3191,  0.1468, #>         -0.2212,  0.7924,  0.2991,  0.1607,  0.0253,  0.1868, -0.3100]) #> Token:  Token[2]: \"Berlin\"  #> tensor([ 0.6197,  0.5665, -0.4658, -1.1890,  0.4460,  0.0660,  0.3191,  0.1468, #>         -0.2212,  0.7924,  0.2991,  0.1607,  0.0253,  0.1868, -0.3100]) #> Token:  Token[3]: \"and\"  #> tensor([ 0.6197,  0.5665, -0.4658, -1.1890,  0.4460,  0.0660,  0.3191,  0.1468, #>         -0.2212,  0.7924,  0.2991,  0.1607,  0.0253,  0.1868, -0.3100]) #> Token:  Token[4]: \"New\"  #> tensor([ 0.6197,  0.5665, -0.4658, -1.1890,  0.4460,  0.0660,  0.3191,  0.1468, #>         -0.2212,  0.7924,  0.2991,  0.1607,  0.0253,  0.1868, -0.3100]) #> Token:  Token[5]: \"York\"  #> tensor([ 0.6197,  0.5665, -0.4658, -1.1890,  0.4460,  0.0660,  0.3191,  0.1468, #>         -0.2212,  0.7924,  0.2991,  0.1607,  0.0253,  0.1868, -0.3100]) #> Token:  Token[6]: \".\"  #> tensor([ 0.6197,  0.5665, -0.4658, -1.1890,  0.4460,  0.0660,  0.3191,  0.1468, #>         -0.2212,  0.7924,  0.2991,  0.1607,  0.0253,  0.1868, -0.3100])"},{"path":"https://davidycliao.github.io/flaiR/articles/quickstart.html","id":"featured-functions-for-nlp-tasks-with-data-table-output","dir":"Articles","previous_headings":"","what":"Featured Functions for NLP Tasks with data.table Output","title":"Quick Start","text":"enhance efficient utilization social science research, {flairR} encapsulates FlairNLP Python three principal functions extract features neat orderly format using data.table. featured functions, don’t write loops format parsed output ; {flairR} automatically neat format. main features include part--speech tagging, transformer-based sentiment analysis, named entity recognition.  ","code":""},{"path":"https://davidycliao.github.io/flaiR/articles/quickstart.html","id":"tagging-parts-of-speech-with-flair-models","dir":"Articles","previous_headings":"Featured Functions for NLP Tasks with data.table Output","what":"Tagging Parts-of-Speech with Flair Models","title":"Quick Start","text":"can load pre-trained model \"pos-fast\". pre-trained models, see https://flairnlp.github.io/docs/tutorial-basics/part--speech-tagging#--english.  ","code":"texts <- c(\"UCD is one of the best universities in Ireland.\",            \"UCD has a good campus but is very far from my apartment in Dublin.\",            \"Essex is famous for social science research.\",            \"Essex is not in the Russell Group, but it is famous for political science research and in 1994 Group.\",            \"TCD is the oldest university in Ireland.\",            \"TCD is similar to Oxford.\")  doc_ids <- c(\"doc1\", \"doc2\", \"doc3\", \"doc4\", \"doc5\", \"doc6\") library(flaiR) tagger_pos <- load_tagger_pos(\"pos-fast\") #> 2023-10-09 17:24:49,321 SequenceTagger predicts: Dictionary with 53 tags: <unk>, O, UH, ,, VBD, PRP, VB, PRP$, NN, RB, ., DT, JJ, VBP, VBG, IN, CD, NNS, NNP, WRB, VBZ, WDT, CC, TO, MD, VBN, WP, :, RP, EX, JJR, FW, XX, HYPH, POS, RBR, JJS, PDT, NNPS, RBS, AFX, WP$, -LRB-, -RRB-, ``, '', LS, $, SYM, ADD results <- get_pos(texts, doc_ids, tagger_pos) head(results, n = 10) #>     doc_id token_id text_id        token tag precision #>  1:   doc1        0      NA          UCD NNP    0.9967 #>  2:   doc1        1      NA           is VBZ    1.0000 #>  3:   doc1        2      NA          one  CD    0.9993 #>  4:   doc1        3      NA           of  IN    1.0000 #>  5:   doc1        4      NA          the  DT    1.0000 #>  6:   doc1        5      NA         best JJS    0.9988 #>  7:   doc1        6      NA universities NNS    0.9997 #>  8:   doc1        7      NA           in  IN    1.0000 #>  9:   doc1        8      NA      Ireland NNP    1.0000 #> 10:   doc1        9      NA            .   .    0.9998"},{"path":"https://davidycliao.github.io/flaiR/articles/quickstart.html","id":"tagging-entities-with-flair-models","dir":"Articles","previous_headings":"Featured Functions for NLP Tasks with data.table Output","what":"Tagging Entities with Flair Models","title":"Quick Start","text":"Load pretrained model “ner”. pretrained models, see https://flairnlp.github.io/docs/tutorial-basics/tagging-entities.  ","code":"library(flaiR) tagger_ner <- load_tagger_ner(\"ner\") #> 2023-10-09 17:24:50,803 SequenceTagger predicts: Dictionary with 20 tags: <unk>, O, S-ORG, S-MISC, B-PER, E-PER, S-LOC, B-ORG, E-ORG, I-PER, S-PER, B-MISC, I-MISC, E-MISC, I-ORG, B-LOC, E-LOC, I-LOC, <START>, <STOP> results <- get_entities(texts, doc_ids, tagger_ner) head(results, n = 10) #>     doc_id        entity tag #>  1:   doc1           UCD ORG #>  2:   doc1       Ireland LOC #>  3:   doc2           UCD ORG #>  4:   doc2        Dublin LOC #>  5:   doc3         Essex ORG #>  6:   doc4         Essex ORG #>  7:   doc4 Russell Group ORG #>  8:   doc5           TCD ORG #>  9:   doc5       Ireland LOC #> 10:   doc6           TCD ORG"},{"path":"https://davidycliao.github.io/flaiR/articles/quickstart.html","id":"tagging-sentiment","dir":"Articles","previous_headings":"Featured Functions for NLP Tasks with data.table Output","what":"Tagging Sentiment","title":"Quick Start","text":"Load pretrained model “sentiment”. pre-trained models “sentiment”, “sentiment-fast”, “de-offensive-language” currently available. pretrained models, see https://flairnlp.github.io/docs/tutorial-basics/tagging-sentiment.  ","code":"library(flaiR) tagger_sent <- load_tagger_sentiments(\"sentiment\") results <- get_sentiments(texts, doc_ids, tagger_sent) head(results, n = 10) #>    doc_id sentiment     score #> 1:   doc1  POSITIVE 0.9970598 #> 2:   doc2  NEGATIVE 0.8472336 #> 3:   doc3  POSITIVE 0.9928006 #> 4:   doc4  POSITIVE 0.9901405 #> 5:   doc5  POSITIVE 0.9952670 #> 6:   doc6  POSITIVE 0.9291794"},{"path":"https://davidycliao.github.io/flaiR/articles/quickstart.html","id":"how-to-contribute","dir":"Articles","previous_headings":"","what":"How to Contribute","title":"Quick Start","text":"currently working postdoctoral researcher Text Policy Research Group SPIRe University College Dublin, immersed numerous ongoing research projects. availability maintain, test, create examples R users may limited. warmly invite R users share similar interests join contributing package. Contributions – whether comments, code suggestions, tutorial examples, forking repository – greatly appreciated. Please note flaiR released Contributor Code Conduct. contributing project, agree abide terms.","code":""},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Tutorial in R","text":"Flair NLP open-source library Natural Language Processing (NLP) developed Zalando Research. Known state---art solutions NLP tasks like Named Entity Recognition (NER), Part--Speech tagging (POS), , garnered attention NLP community ease use powerful functionalities. Developed Python, built PyTorch framework, offers flexible dynamic approach deal textual data. hand, {flaiR} R aims continue framework established Flair Python creating framework R, thereby extending Flair’s capabilities R programming environment. One hallmark features Flair contextual string embeddings, crucial discerning meaning words different contextual usages. Traditional embeddings assign fixed vector word, without considering context, can limitation trying understand nuances word’s usage across different sentences. contrary, Flair’s contextual embeddings generate word vectors considering surrounding text, thus capturing word’s context semantics accurately. particularly impactful scenarios word can different meanings based usage. Flair offers pre-trained models various languages tasks, providing solid foundation various NLP applications text classification, sentiment analysis, entity recognition, etc. instance, ’re involved project requires identifying persons, organizations, locations text, Flair pre-trained NER models can simplify task.","code":""},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"oop-in-r-when-introducing-python","dir":"Articles","previous_headings":"Introduction","what":"OOP in R when Introducing Python","title":"Tutorial in R","text":"Object-Oriented Programming (OOP) programming paradigm uses objects, contain data (attributes) functions (methods), design applications software. idea bind data methods operate data one single unit, object. advent R6, OOP common early stages R. knowledge, R6 relatively rare; aside {mlr3}, written R6, packages accomplished S4 S3 (personal experience), , course, may greatly related habits tasks R users. However, purpose ‘flaiR’ standardize wrapping ‘{flair NLP}’ Python functionality R provide convenient access R users utilize flair NLP features. usage Flair NLP within {flaiR} employs concepts objects classes, similar R6. However, features packaged {reticulate} Python. words, functionalities imported R essentially belong Python classes modules. addition, tensors serve fundamental building block creating training neural networks conducting various numerical computations Python. Flair’s NLP tasks Python PyTorch, numerous extensive functionalities tensor operations, including element-wise operations, matrix multiplications, reshaping. tutorial, also cover work tensors R convert tensors matrices R environment. particularly important using Flair word embeddings.  ","code":""},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"the-overview","dir":"Articles","previous_headings":"Introduction","what":"The Overview","title":"Tutorial in R","text":"following tutorial mainly based Tadej Magajna’s ‘Natural Language Processing Flair: Practical Guide Understanding Solving NLP Problems’, well official Flair NLP Python tutorial blog. written Python. utilize examples {flaiR} R , welcome cite R repository, also cite works. Tutorial Key Aspects: Except necessary, everything accomplished within R environment, utilizing several important R packages, {quanteda}, {udpipe}, {mlr3}, complete following topics: Sentence Token Object Flair Embedding R Sequence Taggings Text Classification Training Model fliaR R Featured Function fliaR  ","code":""},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"sentence-and-token","dir":"Articles","previous_headings":"","what":"Sentence and Token","title":"Tutorial in R","text":"Sentence Token fundamental classes.","code":""},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"sentence","dir":"Articles","previous_headings":"Sentence and Token","what":"Sentence","title":"Tutorial in R","text":"Sentence Flair object contains sequence Token objects, can annotated labels, named entities, part--speech tags, . also can store embeddings sentence whole different kinds linguistic annotations. ’s simple example create Sentence: Sentence[26] means total 26 tokens sentence.","code":"# Creating a Sentence object library(flaiR) string <- \"What I see in UCD today, what I have seen of UCD in its impact on my own life and the life of Ireland.\" sentence <- flair_data.sentence(string) print(sentence) #> Sentence[26]: \"What I see in UCD today, what I have seen of UCD in its impact on my own life and the life of Ireland.\""},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"token","dir":"Articles","previous_headings":"Sentence and Token","what":"Token","title":"Tutorial in R","text":"use Flair handle text data,1 Sentence Token objects often play central roles many use cases. create Sentence object, usually automatically decomposes internal raw text multiple Token objects. words, Sentence object automatically handles text tokenization work, usually don’t need create Token objects manually. Unlike R, indexes 1, Python indexes 0. Therefore, use loop, use seq_along(sentence) - 1. output something like: can directly use $tokens method print tokens. Retrieve Token comprehend string representation format Sentence object, tagging least one token adequate. get_token(n) method, Python method, allows us retrieve Token object particular token. Additionally, can use [] index specific token. noteworthy Python indexes 0, whereas R starts indexing 1. word (punctuation) sentence treated individual Token object. Token objects store text information possible linguistic information (part--speech tags named entity tags) embeddings (used model generate ). Even though cases need create Token objects manually, understanding manage objects manually still useful situations, want fine-grained control tokenization process. example, can control exactness tokenization adding manually created Token objects Sentence object. design pattern Flair allows users handle text data flexible way. Users can use automatic tokenization feature rapid development, also perform finer-grained control accommodate use cases. Annotate POS tag NER tag add_label(label_type, value) method can employed assign label token. manually add tag preliminary tutorial, usually, Universal POS tags, sentence[10] ‘see’, ‘seen’ might tagged VERB, indicating past participle form verb. can also add NER (Named Entity Recognition) tag sentence[4], “UCD”, identifying university Dublin. print sentence object, Sentence[50] provides information 50 tokens → [‘’/ORG, ‘seen’/VERB], thus displaying two tagging pieces information.","code":"# The Sentence object has automatically created and contains multiple Token objects # We can iterate through the Sentence object to view each Token.  for (i in seq_along(sentence)-1) {   print(sentence[[i]]) } #> Token[0]: \"What\" #> Token[1]: \"I\" #> Token[2]: \"see\" #> Token[3]: \"in\" #> Token[4]: \"UCD\" #> Token[5]: \"today\" #> Token[6]: \",\" #> Token[7]: \"what\" #> Token[8]: \"I\" #> Token[9]: \"have\" #> Token[10]: \"seen\" #> Token[11]: \"of\" #> Token[12]: \"UCD\" #> Token[13]: \"in\" #> Token[14]: \"its\" #> Token[15]: \"impact\" #> Token[16]: \"on\" #> Token[17]: \"my\" #> Token[18]: \"own\" #> Token[19]: \"life\" #> Token[20]: \"and\" #> Token[21]: \"the\" #> Token[22]: \"life\" #> Token[23]: \"of\" #> Token[24]: \"Ireland\" #> Token[25]: \".\" print(sentence$tokens) #> [[1]] #> Token[0]: \"What\" #>  #> [[2]] #> Token[1]: \"I\" #>  #> [[3]] #> Token[2]: \"see\" #>  #> [[4]] #> Token[3]: \"in\" #>  #> [[5]] #> Token[4]: \"UCD\" #>  #> [[6]] #> Token[5]: \"today\" #>  #> [[7]] #> Token[6]: \",\" #>  #> [[8]] #> Token[7]: \"what\" #>  #> [[9]] #> Token[8]: \"I\" #>  #> [[10]] #> Token[9]: \"have\" #>  #> [[11]] #> Token[10]: \"seen\" #>  #> [[12]] #> Token[11]: \"of\" #>  #> [[13]] #> Token[12]: \"UCD\" #>  #> [[14]] #> Token[13]: \"in\" #>  #> [[15]] #> Token[14]: \"its\" #>  #> [[16]] #> Token[15]: \"impact\" #>  #> [[17]] #> Token[16]: \"on\" #>  #> [[18]] #> Token[17]: \"my\" #>  #> [[19]] #> Token[18]: \"own\" #>  #> [[20]] #> Token[19]: \"life\" #>  #> [[21]] #> Token[20]: \"and\" #>  #> [[22]] #> Token[21]: \"the\" #>  #> [[23]] #> Token[22]: \"life\" #>  #> [[24]] #> Token[23]: \"of\" #>  #> [[25]] #> Token[24]: \"Ireland\" #>  #> [[26]] #> Token[25]: \".\" # method in Python sentence$get_token(5) #> Token[4]: \"UCD\" # indexing in R  sentence[4] #> Token[4]: \"UCD\" sentence[10]$add_label('manual-pos', 'VERB') print(sentence[10]) #> Token[10]: \"seen\" → VERB (1.0) sentence[4]$add_label('ner', 'ORG') print(sentence[4]) #> Token[4]: \"UCD\" → ORG (1.0) print(sentence) #> Sentence[26]: \"What I see in UCD today, what I have seen of UCD in its impact on my own life and the life of Ireland.\" → [\"UCD\"/ORG, \"seen\"/VERB]"},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"flair-embedding","dir":"Articles","previous_headings":"","what":"Flair Embedding","title":"Tutorial in R","text":"Flair popular natural language processing library, providing variety embedding methods text representation Flair. Flair Embeddings word embedding framowork Natural Language Processing, developed Zalando. Flair focuses word-level representation can capture contextual information words, meaning word can different embeddings different contexts. Unlike traditional word embeddings (Word2Vec GloVe), Flair can dynamically generate word embeddings based context achieved excellent results various NLP tasks. key points Flair Embeddings: Context-Aware Flair can understand context word sentence dynamically generate word embeddings based context. different static embeddings, embedding word consider context sentence. Character-Based Flair uses character-level language model, meaning can generate embeddings rare words even misspelled words. important feature allows model understand process words never appeared training data. Multilingual Support Flair provides various pre-trained character-level language models, supporting contextual word embeddings multiple languages. Combinability Flair allows easily combine different word embeddings (e.g., Flair Embeddings, Word2Vec, GloVe, etc.) create powerful stacked embeddings.","code":""},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"classic-wordembeddings","dir":"Articles","previous_headings":"Flair Embedding","what":"Classic Wordembeddings","title":"Tutorial in R","text":"Flair, simplest form embedding still contains semantic information word called classic word embeddings. embeddings pre-trained non-contextual. Let’s retrieve word embeddings. , can utilize FastText embeddings following code. use , simply instantiate WordEmbeddings class passing ID embedding choice. , simply wrap text Sentence object, call embed(sentence) method WordEmbeddings class. Flair supports range classic word embeddings, offering unique features application scopes. overview, detailing ID required load embedding corresponding language.  ","code":"embedding = flair_embeddings.WordEmbeddings('crawl')  sentence = flair_data.sentence(\"one two three one\")  embedding$embed(sentence)  #> [[1]] #> Sentence[4]: \"one two three one\"  for (i in seq_along(sentence$tokens)) {   print(head(sentence$tokens[[i]]$embedding), n =5) } #> tensor([-0.0535, -0.0368, -0.2851, -0.0381, -0.0486,  0.2383]) #> tensor([ 0.0282, -0.0786, -0.1236,  0.1756, -0.1199,  0.0964]) #> tensor([-0.0920, -0.0690, -0.1475,  0.2313, -0.0872,  0.0799]) #> tensor([-0.0535, -0.0368, -0.2851, -0.0381, -0.0486,  0.2383])"},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"contexual-embeddings","dir":"Articles","previous_headings":"Flair Embedding","what":"Contexual Embeddings","title":"Tutorial in R","text":"Understanding contextuality Flair embeddings idea behind contextual string embeddings word embedding defined syntactic-semantic meaning also context appears . means word different embedding every context appears . pre-trained Flair model offers forward version backward version. Let’s assume processing language , just like book, uses left--right script. forward version takes account context happens word – left-hand side. backward version works opposite direction. takes account context word – right-hand side word. true, two words appear beginning two different sentences identical forward embeddings, context null. Let’s test : using forward model, takes account context occurs word. Additionally, since word context left-hand side position sentence, two embeddings identical, code assumes identical, indeed output True. test whether sum two 2048 embeddings ‘nice’ equal 2048. true, indicates embedding results consistent, theoretically case. Now separately add words, pretty, two sentence objects. two sets embeddings identical words different, returns False. measure similarity two vectors inner product space known cosine similarity. formula calculating cosine similarity two vectors, vectors B, follows: \\(Cosine Similarity = \\frac{\\sum_{} (A_i \\cdot B_i)}{\\sqrt{\\sum_{} (A_i^2)} \\cdot \\sqrt{\\sum_{} (B_i^2)}}\\) can observe similarity two words 0.55.  ","code":"embedding <- flair_embeddings.FlairEmbeddings('news-forward') #> Initialized Flair forward embeddings s1 <- flair_data.sentence(\"nice shirt\")  s2 <- flair_data.sentence(\"nice pants\")   embedding$embed(s1)  #> [[1]] #> Sentence[2]: \"nice shirt\" embedding$embed(s2)  #> [[1]] #> Sentence[2]: \"nice pants\" cat(\" s1 sentence:\", paste(s1[0], sep = \"\"), \"\\n\", \"s2 sentence:\", paste(s2[0], sep = \"\")) #>  s1 sentence: Token[0]: \"nice\"  #>  s2 sentence: Token[0]: \"nice\" length(s1[0]$embedding$numpy()) == sum(s1[0]$embedding$numpy() ==  s2[0]$embedding$numpy()) #> [1] TRUE embedding <- flair_embeddings.FlairEmbeddings('news-forward') #> Initialized Flair forward embeddings s1 <- flair_data.sentence(\"nice shirt\")  s2 <- flair_data.sentence(\"nice pants\") embedding <- flair_embeddings.FlairEmbeddings('news-forward') #> Initialized Flair forward embeddings s1 <- flair_data.sentence(\"very nice shirt\")  s2 <- flair_data.sentence(\"pretty nice pants\")   embedding$embed(s1)  #> [[1]] #> Sentence[3]: \"very nice shirt\" embedding$embed(s2)  #> [[1]] #> Sentence[3]: \"pretty nice pants\" length(s1[0]$embedding$numpy()) == sum(s1[0]$embedding$numpy() ==  s2[0]$embedding$numpy()) #> [1] FALSE library(lsa) #> Loading required package: SnowballC vector1 <- as.numeric(s1[0]$embedding$numpy()) vector2 <- as.numeric(s2[0]$embedding$numpy()) cosine_similarity <- cosine(vector1, vector2) print(cosine_similarity) #>           [,1] #> [1,] 0.5571664"},{"path":"https://davidycliao.github.io/flaiR/articles/tutorial.html","id":"extracting-embeddings-from-bert","dir":"Articles","previous_headings":"Flair Embedding","what":"Extracting Embeddings from BERT","title":"Tutorial in R","text":"First, utilize flair.embeddings.TransformerWordEmbeddings function download BERT, transformer models can also found Flair NLP’s Hugging Face. Traverse token sentence print . view token, ’s necessary usereticulate::py_str(token) since sentence Python object.","code":"TransformerWordEmbeddings <- flair_embeddings.TransformerWordEmbeddings(\"bert-base-uncased\") embedding <- TransformerWordEmbeddings$embed(sentence) # Iterate through each token in the sentence, printing them.  # Utilize reticulate::py_str(token) to view each token, given that the sentence is a Python object. for (i in seq_along(sentence$tokens)) {   cat(\"Token: \", reticulate::py_str(sentence$tokens[[i]]), \"\\n\")   # Access the embedding of the token, converting it to an R object,    # and print the first 10 elements of the vector.   token_embedding <- sentence$tokens[[i]]$embedding   print(head(token_embedding, 10)) } #> Token:  Token[0]: \"one\"  #> tensor([-0.0535, -0.0368, -0.2851, -0.0381, -0.0486,  0.2383, -0.1200,  0.2620, #>         -0.0575,  0.0228]) #> Token:  Token[1]: \"two\"  #> tensor([ 0.0282, -0.0786, -0.1236,  0.1756, -0.1199,  0.0964, -0.1327,  0.4449, #>         -0.0264, -0.1168]) #> Token:  Token[2]: \"three\"  #> tensor([-0.0920, -0.0690, -0.1475,  0.2313, -0.0872,  0.0799, -0.0901,  0.4403, #>         -0.0103, -0.1494]) #> Token:  Token[3]: \"one\"  #> tensor([-0.0535, -0.0368, -0.2851, -0.0381, -0.0486,  0.2383, -0.1200,  0.2620, #>         -0.0575,  0.0228])"},{"path":"https://davidycliao.github.io/flaiR/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"David Liao. Maintainer, author. Akbik Alan. Author, contributor. Blythe Duncan. Author, contributor. Vollgraf Roland. Author, contributor.","code":""},{"path":"https://davidycliao.github.io/flaiR/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Liao D, Alan , Duncan B, Roland V (2023). flaiR: R Wrapper Accessing Flair NLP Tagging Features. R package version 0.0.5.","code":"@Manual{,   title = {flaiR: An R Wrapper for Accessing Flair NLP Tagging Features},   author = {David Liao and Akbik Alan and Blythe Duncan and Vollgraf Roland},   year = {2023},   note = {R package version 0.0.5}, }"},{"path":"https://davidycliao.github.io/flaiR/index.html","id":"flairr-an-r-wrapper-for-accessing-flair-nlp-tagging-features-","dir":"","previous_headings":"","what":"flairR: An R Wrapper for Accessing Flair NLP Tagging Features","title":"An R Wrapper for Accessing Flair NLP Tagging Features","text":"{flaiR} R wrapper {flairNLP/flair} R users, particularly social science researchers. offers streamlined access core features {flairNLP}. {flairNLP} advanced NLP framework Python incorporates advanced techniques developed Humboldt University Berlin. deeper understanding {flairNLP/flair}’s architecture, refer research article ‘Contextual String Embeddings Sequence Labeling’ official mannual Python. R users, {flairR} primarily consists two main components. first wrapper function built top {reticulate}, enables interact directly Python modules R provides seamless support documents tutorial (progress) R community. Secondly, facilitate efficient use social science research, {flairR} wraps FlairNLP Python three major functions extract features tidy clean format using data.table. features include part--speech tagging, transformer-based sentiment analysis, named entity recognition.","code":""},{"path":"https://davidycliao.github.io/flaiR/index.html","id":"installation-via-github","dir":"","previous_headings":"flairR: An R Wrapper for Accessing Flair NLP Tagging Features","what":"Installation via GitHub","title":"An R Wrapper for Accessing Flair NLP Tagging Features","text":"installation consists two parts: First, install Python 3.7 higher, R 3.6.3 higher. Although tested Github Action R 3.6.2, strongly recommend installing R 4.0.0 ensure compatibility R environment {reticulate}. issues installation, feel free ask Discussion .","code":"install.packages(\"remotes\") remotes::install_github(\"davidycliao/flaiR\", force = TRUE) library(flaiR) #> flaiR: An R Wrapper for Accessing Flair NLP Tagging Features       #> Python: 3.11                                            #> Flair: 0.12.2"},{"path":"https://davidycliao.github.io/flaiR/index.html","id":"how-to-contribute","dir":"","previous_headings":"","what":"How to Contribute","title":"An R Wrapper for Accessing Flair NLP Tagging Features","text":"availability maintain, test, create examples R users may limited. warmly invite R users share similar interests join contributing package. Please feel free shoot email collaborate task. Contributions – whether comments, code suggestions, tutorial examples, forking repository – greatly appreciated. Please note flaiR released Contributor Code Conduct. contributing project, agree abide terms.","code":""},{"path":"https://davidycliao.github.io/flaiR/index.html","id":"citing-the-contributions-of-flair-nlp","dir":"","previous_headings":"","what":"Citing the Contributions of Flair NLP","title":"An R Wrapper for Accessing Flair NLP Tagging Features","text":"use tool academic research, recommend citing research article, Contextual String Embeddings Sequence Labeling Flair Zalando Research team.","code":"@inproceedings{akbik2018coling,   title={Contextual String Embeddings for Sequence Labeling},   author={Akbik, Alan and Blythe, Duncan and Vollgraf, Roland},   booktitle = {{COLING} 2018, 27th International Conference on Computational Linguistics},   pages     = {1638--1649},   year      = {2018} }"},{"path":"https://davidycliao.github.io/flaiR/reference/check_and_gc.html","id":null,"dir":"Reference","previous_headings":"","what":"Perform Garbage Collection Based on Condition — check_and_gc","title":"Perform Garbage Collection Based on Condition — check_and_gc","text":"function checks value `gc.active` determine whether perform garbage collection. `gc.active` `TRUE`, function perform garbage collection send message indicating completion process.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/check_and_gc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Perform Garbage Collection Based on Condition — check_and_gc","text":"","code":"check_and_gc(gc.active)"},{"path":"https://davidycliao.github.io/flaiR/reference/check_and_gc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Perform Garbage Collection Based on Condition — check_and_gc","text":"gc.active logical value indicating whether activate garbage collection.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/check_and_gc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Perform Garbage Collection Based on Condition — check_and_gc","text":"message indicating garbage collection performed `gc.active` `TRUE`. Otherwise, action taken message displayed.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/check_batch_size.html","id":null,"dir":"Reference","previous_headings":"","what":"Check the Specified Batch Size — check_batch_size","title":"Check the Specified Batch Size — check_batch_size","text":"Validates given batch size positive integer.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/check_batch_size.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check the Specified Batch Size — check_batch_size","text":"","code":"check_batch_size(batch_size)"},{"path":"https://davidycliao.github.io/flaiR/reference/check_batch_size.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check the Specified Batch Size — check_batch_size","text":"batch_size Integer. batch size checked.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/check_device.html","id":null,"dir":"Reference","previous_headings":"","what":"Check the Device for cccelerating PyTorch — check_device","title":"Check the Device for cccelerating PyTorch — check_device","text":"function verifies specified device available PyTorch. CUDA available, message shown. Additionally, system running Mac M1, MPS used instead CUDA.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/check_device.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check the Device for cccelerating PyTorch — check_device","text":"","code":"check_device(device)"},{"path":"https://davidycliao.github.io/flaiR/reference/check_device.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check the Device for cccelerating PyTorch — check_device","text":"device Character. device set PyTorch.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/check_flair_installed.html","id":null,"dir":"Reference","previous_headings":"","what":"Check Flair — check_flair_installed","title":"Check Flair — check_flair_installed","text":"Determines Flair Python module available current Python environment.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/check_flair_installed.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check Flair — check_flair_installed","text":"","code":"check_flair_installed(...)"},{"path":"https://davidycliao.github.io/flaiR/reference/check_flair_installed.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check Flair — check_flair_installed","text":"Logical. `TRUE` Flair installed, otherwise `FALSE`.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/check_language_supported.html","id":null,"dir":"Reference","previous_headings":"","what":"Check the Given Language Models against Supported Languages Models — check_language_supported","title":"Check the Given Language Models against Supported Languages Models — check_language_supported","text":"function checks whether provided language supported. , stops execution returns message indicating supported languages.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/check_language_supported.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check the Given Language Models against Supported Languages Models — check_language_supported","text":"","code":"check_language_supported(language, supported_lan_models)"},{"path":"https://davidycliao.github.io/flaiR/reference/check_language_supported.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check the Given Language Models against Supported Languages Models — check_language_supported","text":"language language check. supported_lan_models vector supported languages.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/check_language_supported.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check the Given Language Models against Supported Languages Models — check_language_supported","text":"function return anything, stops execution check fails.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/check_language_supported.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check the Given Language Models against Supported Languages Models — check_language_supported","text":"","code":"# Assuming 'en' is a supported language and 'abc' is not: check_language_supported(\"en\", c(\"en\", \"de\", \"fr\")) # check_language_supported(\"abc\", c(\"en\", \"de\", \"fr\")) # will stop execution"},{"path":"https://davidycliao.github.io/flaiR/reference/check_prerequisites.html","id":null,"dir":"Reference","previous_headings":"","what":"Check Environment Pre-requisites — check_prerequisites","title":"Check Environment Pre-requisites — check_prerequisites","text":"function checks Python installed, flair module available Python, active internet connection.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/check_prerequisites.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check Environment Pre-requisites — check_prerequisites","text":"","code":"check_prerequisites(...)"},{"path":"https://davidycliao.github.io/flaiR/reference/check_prerequisites.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check Environment Pre-requisites — check_prerequisites","text":"... passing additional arguments.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/check_prerequisites.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check Environment Pre-requisites — check_prerequisites","text":"message detailing missing pre-requisites.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/check_python_installed.html","id":null,"dir":"Reference","previous_headings":"","what":"Check for Available Python Installation — check_python_installed","title":"Check for Available Python Installation — check_python_installed","text":"function checks environment installed R system.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/check_python_installed.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check for Available Python Installation — check_python_installed","text":"","code":"check_python_installed(...)"},{"path":"https://davidycliao.github.io/flaiR/reference/check_python_installed.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check for Available Python Installation — check_python_installed","text":"... param run.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/check_python_installed.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check for Available Python Installation — check_python_installed","text":"Logical. `TRUE` Python installed, `FALSE` otherwise. Additionally, installed, path Python installation printed.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/check_show.text_id.html","id":null,"dir":"Reference","previous_headings":"","what":"Check the `show.text_id` parameter — check_show.text_id","title":"Check the `show.text_id` parameter — check_show.text_id","text":"Validates given `show.text_id` logical value.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/check_show.text_id.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check the `show.text_id` parameter — check_show.text_id","text":"","code":"check_show.text_id(show.text_id)"},{"path":"https://davidycliao.github.io/flaiR/reference/check_show.text_id.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check the `show.text_id` parameter — check_show.text_id","text":"show.text_id Logical. parameter checked.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/check_texts_and_ids.html","id":null,"dir":"Reference","previous_headings":"","what":"Check the texts and document IDs — check_texts_and_ids","title":"Check the texts and document IDs — check_texts_and_ids","text":"Validates given texts document IDs NULL empty.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/check_texts_and_ids.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check the texts and document IDs — check_texts_and_ids","text":"","code":"check_texts_and_ids(texts, doc_ids)"},{"path":"https://davidycliao.github.io/flaiR/reference/check_texts_and_ids.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check the texts and document IDs — check_texts_and_ids","text":"texts List. list texts. doc_ids List. list document IDs.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/clear_flair_cache.html","id":null,"dir":"Reference","previous_headings":"","what":"Clear Flair Cache — clear_flair_cache","title":"Clear Flair Cache — clear_flair_cache","text":"function clears cache associated Flair Python library. cache directory typically located \"~/.flair\".","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/clear_flair_cache.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Clear Flair Cache — clear_flair_cache","text":"","code":"clear_flair_cache(...)"},{"path":"https://davidycliao.github.io/flaiR/reference/clear_flair_cache.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Clear Flair Cache — clear_flair_cache","text":"... argument passed next.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/clear_flair_cache.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Clear Flair Cache — clear_flair_cache","text":"Returns NULL invisibly. Messages printed indicating whether cache found cleared.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/clear_flair_cache.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Clear Flair Cache — clear_flair_cache","text":"","code":"if (FALSE) { clear_flair_cache() }"},{"path":"https://davidycliao.github.io/flaiR/reference/create_flair_env.html","id":null,"dir":"Reference","previous_headings":"","what":"Create or Use Python environment for Flair — create_flair_env","title":"Create or Use Python environment for Flair — create_flair_env","text":"function checks whether Flair Python library installed current Python environment. , attempts install either current conda environment creates new one.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/create_flair_env.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create or Use Python environment for Flair — create_flair_env","text":"","code":"create_flair_env(env = \"r-reticulate\")"},{"path":"https://davidycliao.github.io/flaiR/reference/create_flair_env.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create or Use Python environment for Flair — create_flair_env","text":"env name conda environment used created (default \"r-reticulate\").","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/create_flair_env.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create or Use Python environment for Flair — create_flair_env","text":"Nothing returned. function primarily ensures Python library Flair installed available.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/de_immigration.html","id":null,"dir":"Reference","previous_headings":"","what":"German Bundestag Immigration Debate Data — de_immigration","title":"German Bundestag Immigration Debate Data — de_immigration","text":"dataset containing speeches debates German Bundestag topic immigration.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/de_immigration.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"German Bundestag Immigration Debate Data — de_immigration","text":"","code":"data(\"de_immigration\")"},{"path":"https://davidycliao.github.io/flaiR/reference/de_immigration.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"German Bundestag Immigration Debate Data — de_immigration","text":"data frame 16 variables: date Date speech, Date type agenda Agenda subject speech, character speechnumber Unique identifier speech, numeric speaker Name person giving speech, character party Political party speaker, character party.facts.id ID party, usually numeric character chair Person chairing session, character terms Terms tags associated speech, character list text Actual text speech, character parliament Bundestag session, character numeric iso3country ISO3 country code Germany, character year Year speech made, numeric agenda_ID Unique identifier agenda, usually numeric    character migration_dummy Dummy variable related migration topic,   usually numeric (0 1) comment_agenda Additional comments agenda, character","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/de_immigration.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"German Bundestag Immigration Debate Data — de_immigration","text":"Describe source data .","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/de_immigration.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"German Bundestag Immigration Debate Data — de_immigration","text":"","code":"if (FALSE) { data(de_immigration) head(de_immigration) }"},{"path":"https://davidycliao.github.io/flaiR/reference/dot-onAttach.html","id":null,"dir":"Reference","previous_headings":"","what":".onAttach Function for the flaiR Package — .onAttach","title":".onAttach Function for the flaiR Package — .onAttach","text":"function called flaiR package loaded. provides messages detailing versions Python Flair used, well package details.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/dot-onAttach.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":".onAttach Function for the flaiR Package — .onAttach","text":"","code":".onAttach(...)"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_data.sentence.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a Flair Sentence Object — flair_data.sentence","title":"Create a Flair Sentence Object — flair_data.sentence","text":"function uses reticulate package interface Python create Flair Sentence object.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_data.sentence.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a Flair Sentence Object — flair_data.sentence","text":"","code":"flair_data.sentence(sentence_text)"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_data.sentence.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a Flair Sentence Object — flair_data.sentence","text":"sentence_text character string converted Flair Sentence object.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_data.sentence.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a Flair Sentence Object — flair_data.sentence","text":"Flair Sentence object.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_data.sentence.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Create a Flair Sentence Object — flair_data.sentence","text":"Python equivalent:","code":"from flair.data import Sentence sentence = Sentence(\"The quick brown fox jumps over the lazy dog.\")"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_data.sentence.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a Flair Sentence Object — flair_data.sentence","text":"","code":"if (FALSE) { flair_data.sentence(\"The quick brown fox jumps over the lazy dog.\") }"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_datasets.html","id":null,"dir":"Reference","previous_headings":"","what":"Access the flair_datasets Module from Flair — flair_datasets","title":"Access the flair_datasets Module from Flair — flair_datasets","text":"Utilizes reticulate package import `flair.datasets` dataset Flair's datasets Python, enabling use dataset R environment.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_datasets.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Access the flair_datasets Module from Flair — flair_datasets","text":"","code":"flair_datasets()"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_datasets.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Access the flair_datasets Module from Flair — flair_datasets","text":"Python Module(flair.datasets) Flair, can utilized NLP tasks.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_datasets.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Access the flair_datasets Module from Flair — flair_datasets","text":"Python equivalent:","code":"from flair.datasets import UD_ENGLISH corpus = UD_ENGLISH().downsample(0.1)"},{"path":[]},{"path":"https://davidycliao.github.io/flaiR/reference/flair_datasets.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Access the flair_datasets Module from Flair — flair_datasets","text":"","code":"if (FALSE) { UD_ENGLISH <- flair_datasets()$UD_ENGLISH corpus <- UD_ENGLISH()$downsample(0.1) }"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_embeddings.FlairEmbeddings.html","id":null,"dir":"Reference","previous_headings":"","what":"Flair Embedding Initialization — flair_embeddings.FlairEmbeddings","title":"Flair Embedding Initialization — flair_embeddings.FlairEmbeddings","text":"function initializes Flair embeddings using Python's Flair library.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_embeddings.FlairEmbeddings.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Flair Embedding Initialization — flair_embeddings.FlairEmbeddings","text":"","code":"flair_embeddings.FlairEmbeddings(embeddings_type = \"news-forward\")"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_embeddings.FlairEmbeddings.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Flair Embedding Initialization — flair_embeddings.FlairEmbeddings","text":"embeddings_type Character, type embeddings initialize. Options: \"news-forward\", \"news-backward\".","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_embeddings.FlairEmbeddings.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Flair Embedding Initialization — flair_embeddings.FlairEmbeddings","text":"Flair embeddings object Python's Flair library.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_embeddings.FlairEmbeddings.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Flair Embedding Initialization — flair_embeddings.FlairEmbeddings","text":"FlairEmbeddings Flair library Python. Example usage Python:","code":"flair_embedding_forward = FlairEmbeddings('news-forward') flair_embedding_backward = FlairEmbeddings('news-backward')"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_embeddings.FlairEmbeddings.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Flair Embedding Initialization — flair_embeddings.FlairEmbeddings","text":"","code":"if (FALSE) { flair_embedding_forward <- flair_embeddings.FlairEmbeddings(\"news-forward\") flair_embedding_backward <- flair_embeddings.FlairEmbeddings(\"news-backward\") }"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_embeddings.TransformerDocumentEmbeddings.html","id":null,"dir":"Reference","previous_headings":"","what":"TransformerDocumentEmbeddings Function — flair_embeddings.TransformerDocumentEmbeddings","title":"TransformerDocumentEmbeddings Function — flair_embeddings.TransformerDocumentEmbeddings","text":"function initializes returns Transformer Document Embedding model Flair library. takes pre-trained model name argument returns respective embedding model.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_embeddings.TransformerDocumentEmbeddings.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"TransformerDocumentEmbeddings Function — flair_embeddings.TransformerDocumentEmbeddings","text":"","code":"flair_embeddings.TransformerDocumentEmbeddings(   pre_trained = \"bert-base-uncased\" )"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_embeddings.TransformerDocumentEmbeddings.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"TransformerDocumentEmbeddings Function — flair_embeddings.TransformerDocumentEmbeddings","text":"pre_trained string specifying name pre-trained transformer model.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_embeddings.TransformerDocumentEmbeddings.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"TransformerDocumentEmbeddings Function — flair_embeddings.TransformerDocumentEmbeddings","text":"instance TransformerDocumentEmbeddings model Flair library.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_embeddings.TransformerDocumentEmbeddings.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"TransformerDocumentEmbeddings Function — flair_embeddings.TransformerDocumentEmbeddings","text":"Python's Flair library:  flair.embeddings import TransformerDocumentEmbeddings embedding = TransformerDocumentEmbeddings('bert-base-uncased')","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_embeddings.TransformerDocumentEmbeddings.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"TransformerDocumentEmbeddings Function — flair_embeddings.TransformerDocumentEmbeddings","text":"","code":"if (FALSE) { embedding <- flair_embeddings.TransformerDocumentEmbeddings(pre_trained = \"bert-base-uncased\") }"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_embeddings.TransformerWordEmbeddings.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a Flair TransformerWordEmbeddings Object — flair_embeddings.TransformerWordEmbeddings","title":"Create a Flair TransformerWordEmbeddings Object — flair_embeddings.TransformerWordEmbeddings","text":"function interfaces Python via reticulate create `TransformerWordEmbeddings` object using Flair library.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_embeddings.TransformerWordEmbeddings.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a Flair TransformerWordEmbeddings Object — flair_embeddings.TransformerWordEmbeddings","text":"","code":"flair_embeddings.TransformerWordEmbeddings(   pre_trained_model = \"bert-base-uncased\" )"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_embeddings.TransformerWordEmbeddings.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a Flair TransformerWordEmbeddings Object — flair_embeddings.TransformerWordEmbeddings","text":"pre_trained_model character string specifying pre-trained model use. Defaults 'bert-base-uncased'.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_embeddings.TransformerWordEmbeddings.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a Flair TransformerWordEmbeddings Object — flair_embeddings.TransformerWordEmbeddings","text":"Flair TransformerWordEmbeddings object.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_embeddings.TransformerWordEmbeddings.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Create a Flair TransformerWordEmbeddings Object — flair_embeddings.TransformerWordEmbeddings","text":"Python equivalent:","code":"from flair.embeddings import TransformerWordEmbeddings embedding = TransformerWordEmbeddings('bert-base-uncased')"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_embeddings.TransformerWordEmbeddings.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a Flair TransformerWordEmbeddings Object — flair_embeddings.TransformerWordEmbeddings","text":"","code":"if (FALSE) { embedding <- flair_embeddings.TransformerWordEmbeddings(\"bert-base-uncased\") }"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_embeddings.WordEmbeddings.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a Flair WordEmbeddings Object — flair_embeddings.WordEmbeddings","title":"Create a Flair WordEmbeddings Object — flair_embeddings.WordEmbeddings","text":"function interfaces Python via reticulate create `WordEmbeddings` object using Flair library.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_embeddings.WordEmbeddings.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a Flair WordEmbeddings Object — flair_embeddings.WordEmbeddings","text":"","code":"flair_embeddings.WordEmbeddings(pre_trained = \"glove\")"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_embeddings.WordEmbeddings.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a Flair WordEmbeddings Object — flair_embeddings.WordEmbeddings","text":"pre_trained character string specifying pre-trained model use. Defaults \"`glove`\".","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_embeddings.WordEmbeddings.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a Flair WordEmbeddings Object — flair_embeddings.WordEmbeddings","text":"Flair WordEmbeddings object.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_embeddings.WordEmbeddings.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Create a Flair WordEmbeddings Object — flair_embeddings.WordEmbeddings","text":"Python equivalent:","code":"from flair.embeddings import WordEmbeddings embedding = WordEmbeddings('glove')"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_embeddings.WordEmbeddings.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a Flair WordEmbeddings Object — flair_embeddings.WordEmbeddings","text":"","code":"if (FALSE) { embedding <- flair_embeddings.WordEmbeddings(\"glove\") }"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_embeddings.html","id":null,"dir":"Reference","previous_headings":"","what":"Flair Embeddings Importer — flair_embeddings","title":"Flair Embeddings Importer — flair_embeddings","text":"function imports returns flair.embeddings module Flair. provides convenient R interface Flair library's embedding functionalities.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_embeddings.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Flair Embeddings Importer — flair_embeddings","text":"","code":"flair_embeddings()"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_embeddings.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Flair Embeddings Importer — flair_embeddings","text":"flair.embeddings module Flair.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_embeddings.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Flair Embeddings Importer — flair_embeddings","text":"Python's Flair library:  flair.embeddings import FlairEmbeddings","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_embeddings.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Flair Embeddings Importer — flair_embeddings","text":"","code":"if (FALSE) { flair_embeddings <- flair_embeddings()$FlairEmbeddings }"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_models.TextClassifier.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve TextClassifier from flair.models — flair_models.TextClassifier","title":"Retrieve TextClassifier from flair.models — flair_models.TextClassifier","text":"function utilizes reticulate package directly import TextClassifier flair.models Flair NLP Python library. Ensure Python environment properly set Flair package installed.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_models.TextClassifier.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve TextClassifier from flair.models — flair_models.TextClassifier","text":"","code":"flair_models.TextClassifier()"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_models.TextClassifier.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve TextClassifier from flair.models — flair_models.TextClassifier","text":"Python object representing flair.models.TextClassifier.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_models.TextClassifier.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Retrieve TextClassifier from flair.models — flair_models.TextClassifier","text":"Python equivalent:","code":"from flair.models import TextClassifier"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_models.TextClassifier.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Retrieve TextClassifier from flair.models — flair_models.TextClassifier","text":"","code":"if (FALSE) { # Ensure reticulate is using the correct Python environment # reticulate::use_python(\"path_to_your_python\", required = TRUE) # Load the TextClassifier TextClassifier <- flair_models.TextClassifier() # Load a pre-trained sentiment model classifier <- TextClassifier$load('sentiment')  # Create a sentence object sentence <- flair_data.sentence(\"Flair is pretty neat!\")  # Predict the sentiment classifier$predict(sentence) # Display the sentiment print(sentence$get_labels()) }"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_models.html","id":null,"dir":"Reference","previous_headings":"","what":"Import the flair.models Python module — flair_models","title":"Import the flair.models Python module — flair_models","text":"function utilizes reticulate package import flair.models Flair NLP Python library. Ensure Python environment properly set Flair package installed.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_models.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Import the flair.models Python module — flair_models","text":"","code":"flair_models()"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_models.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Import the flair.models Python module — flair_models","text":"Python module object representing flair.models.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_models.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Import the flair.models Python module — flair_models","text":"Python equivalent:","code":"from flair.models import *"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_models.sequencetagger.html","id":null,"dir":"Reference","previous_headings":"","what":"Access Flair's SequenceTagger — flair_models.sequencetagger","title":"Access Flair's SequenceTagger — flair_models.sequencetagger","text":"function utilizes reticulate package import `SequenceTagger`s Flair's models Python, enabling interaction Flair's sequence tagging models R environment.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_models.sequencetagger.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Access Flair's SequenceTagger — flair_models.sequencetagger","text":"","code":"flair_models.sequencetagger()"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_models.sequencetagger.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Access Flair's SequenceTagger — flair_models.sequencetagger","text":"Python module (`SequenceTagger`) Flair, can utilized load use sequence tagging models.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_models.sequencetagger.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Access Flair's SequenceTagger — flair_models.sequencetagger","text":"function take parameters directly returns `SequenceTagger` called, can used sequence tagging tasks using pre-trained models Flair.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_models.sequencetagger.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Access Flair's SequenceTagger — flair_models.sequencetagger","text":"Python equivalent:","code":"from flair.models import SequenceTagger"},{"path":[]},{"path":"https://davidycliao.github.io/flaiR/reference/flair_models.sequencetagger.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Access Flair's SequenceTagger — flair_models.sequencetagger","text":"","code":"if (FALSE) { sequence_tagger <- flair_models.sequencetagger() }"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_nn.classifier_load.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a Flair Classifier.load Object — flair_nn.classifier_load","title":"Create a Flair Classifier.load Object — flair_nn.classifier_load","text":"function utilizes reticulate package interface Python create Classifier object Flair library.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_nn.classifier_load.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a Flair Classifier.load Object — flair_nn.classifier_load","text":"","code":"flair_nn.classifier_load(pre_trained)"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_nn.classifier_load.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a Flair Classifier.load Object — flair_nn.classifier_load","text":"pre_trained character string specifying pre-trained model use. parameter defined used current function context.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_nn.classifier_load.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a Flair Classifier.load Object — flair_nn.classifier_load","text":"Flair Classifier object.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_nn.classifier_load.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Create a Flair Classifier.load Object — flair_nn.classifier_load","text":"Python equivalent:","code":"from flair.nn import Classifier"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_nn.classifier_load.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a Flair Classifier.load Object — flair_nn.classifier_load","text":"","code":"if (FALSE) { classifier <- flair_nn.classifier_load(\"ner\") }"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_splitter.SegtokSentenceSplitter.html","id":null,"dir":"Reference","previous_headings":"","what":"Segtok Sentence Splitter — flair_splitter.SegtokSentenceSplitter","title":"Segtok Sentence Splitter — flair_splitter.SegtokSentenceSplitter","text":"function interface Python `flair.splitter` module, specifically utilizing `SegtokSentenceSplitter` class/method.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_splitter.SegtokSentenceSplitter.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Segtok Sentence Splitter — flair_splitter.SegtokSentenceSplitter","text":"","code":"flair_splitter.SegtokSentenceSplitter()"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_splitter.SegtokSentenceSplitter.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Segtok Sentence Splitter — flair_splitter.SegtokSentenceSplitter","text":"Python module (`flair.splitter`).","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_splitter.SegtokSentenceSplitter.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Segtok Sentence Splitter — flair_splitter.SegtokSentenceSplitter","text":"Python reference:","code":"from flair.splitter import SegtokSentenceSplitter"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_splitter.SegtokSentenceSplitter.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Segtok Sentence Splitter — flair_splitter.SegtokSentenceSplitter","text":"","code":"if (FALSE) { splitter <- flair_splitter.SegtokSentenceSplitter() }"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_trainers.html","id":null,"dir":"Reference","previous_headings":"","what":"Import Flair's ModelTrainer in R — flair_trainers","title":"Import Flair's ModelTrainer in R — flair_trainers","text":"function provides R access Flair's ModelTrainer Python class using reticulate package.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_trainers.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Import Flair's ModelTrainer in R — flair_trainers","text":"","code":"flair_trainers()"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_trainers.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Import Flair's ModelTrainer in R — flair_trainers","text":"Python Module(flair.trainers) object allowing access Flair's trainers R.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/flair_trainers.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Import Flair's ModelTrainer in R — flair_trainers","text":"Flair GitHub Python equivalent:","code":"from flair.trainers import ModelTrainer"},{"path":"https://davidycliao.github.io/flaiR/reference/flair_trainers.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Import Flair's ModelTrainer in R — flair_trainers","text":"","code":"if (FALSE) { trainers <- flair_trainers() model_trainer <- trainers$ModelTrainer }"},{"path":"https://davidycliao.github.io/flaiR/reference/get_entities.html","id":null,"dir":"Reference","previous_headings":"","what":"Tagging Named Entities with Flair Models — get_entities","title":"Tagging Named Entities with Flair Models — get_entities","text":"function takes texts corresponding document IDs inputs, uses Flair NLP library extract named entities, returns dataframe identified entities along tags. entities detected text, function returns data table NA values. might clutter results. Depending use case, might decide either keep behavior skip rows detected entities.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/get_entities.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tagging Named Entities with Flair Models — get_entities","text":"","code":"get_entities(   texts,   doc_ids = NULL,   tagger = NULL,   language = NULL,   show.text_id = FALSE,   gc.active = FALSE )"},{"path":"https://davidycliao.github.io/flaiR/reference/get_entities.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tagging Named Entities with Flair Models — get_entities","text":"texts character vector containing texts process. doc_ids character numeric vector containing document IDs corresponding text. tagger optional tagger object. NULL (default), function load Flair tagger based specified language. language character string indicating language model load. Default \"en\". show.text_id logical value. TRUE, includes actual text entity extracted resulting data table. Useful verification traceability purposes might increase size output. Default FALSE. gc.active logical value. TRUE, runs garbage collector processing texts. can help freeing memory releasing unused memory space, especially processing large number texts. Default FALSE.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/get_entities.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tagging Named Entities with Flair Models — get_entities","text":"data table columns: doc_id ID document entity extracted. text_id TRUE, actual text entity   extracted. entity named entity extracted text. tag tag category named entity. Common tags include:   PERSON (names individuals),   ORG (organizations, institutions),   GPE (countries, cities, states),   LOCATION (mountain ranges, bodies water),   DATE (dates periods),   TIME (times day),   MONEY (monetary values),   PERCENT (percentage values),   FACILITY (buildings, airports),   PRODUCT (objects, vehicles),   EVENT (named events like wars sports events),   ART (titles books)","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/get_entities.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tagging Named Entities with Flair Models — get_entities","text":"","code":"if (FALSE) { library(reticulate) library(fliaR)  texts <- c(\"UCD is one of the best universities in Ireland.\",            \"UCD has a good campus but is very far from            my apartment in Dublin.\",            \"Essex is famous for social science research.\",            \"Essex is not in the Russell Group, but it is            famous for political science research.\",            \"TCD is the oldest university in Ireland.\",            \"TCD is similar to Oxford.\") doc_ids <- c(\"doc1\", \"doc2\", \"doc3\", \"doc4\", \"doc5\", \"doc6\") # Load NER (\"ner\") model tagger_ner <- load_tagger_ner('ner') results <- get_entities(texts, doc_ids, tagger_ner) print(results)}"},{"path":"https://davidycliao.github.io/flaiR/reference/get_entities_batch.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Named Entities from a Batch of Texts — get_entities_batch","title":"Extract Named Entities from a Batch of Texts — get_entities_batch","text":"function processes batches texts extracts named entities.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/get_entities_batch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Named Entities from a Batch of Texts — get_entities_batch","text":"","code":"get_entities_batch(   texts,   doc_ids,   tagger = NULL,   language = \"en\",   show.text_id = FALSE,   gc.active = FALSE,   batch_size = 5,   device = \"cpu\",   verbose = TRUE )"},{"path":"https://davidycliao.github.io/flaiR/reference/get_entities_batch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Named Entities from a Batch of Texts — get_entities_batch","text":"texts character vector texts process. doc_ids vector document IDs corresponding text. tagger pre-loaded Flair NER tagger. Default NULL, tagger loaded based provided language. language character string specifying language texts. Default \"en\" (English). show.text_id Logical, whether include text ID output. Default FALSE. gc.active Logical, whether activate garbage collection processing batch. Default FALSE. batch_size integer specifying size batch. Default 5. device character string specifying computation device. can either \"cpu\" string representation GPU device number. instance, \"0\" corresponds first GPU. GPU device number provided, attempt use GPU. default \"cpu\". \"cuda\" \"cuda:0\" (\"mps\" \"mps:0\" Mac M1/M2 )Refers first GPU system.       one GPU, specifying \"cuda\" \"cuda:0\" allocate       computations GPU. \"cuda:1\" (\"mps:1\")Refers second GPU system, allowing allocation       specific computations GPU. \"cuda:2\" (\"mps:2)Refers third GPU system, systems       GPUs. verbose logical value. TRUE, function prints batch processing progress updates. Default TRUE.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/get_entities_batch.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Named Entities from a Batch of Texts — get_entities_batch","text":"data.table containing extracted entities, corresponding tags, document IDs.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/get_entities_batch.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract Named Entities from a Batch of Texts — get_entities_batch","text":"","code":"if (FALSE) { library(reticulate) library(fliaR)  texts <- c(\"UCD is one of the best universities in Ireland.\",            \"UCD has a good campus but is very far from            my apartment in Dublin.\",            \"Essex is famous for social science research.\",            \"Essex is not in the Russell Group, but it is            famous for political science research.\",            \"TCD is the oldest university in Ireland.\",            \"TCD is similar to Oxford.\") doc_ids <- c(\"doc1\", \"doc2\", \"doc3\", \"doc4\", \"doc5\", \"doc6\") # Load NER (\"ner\") model tagger_ner <- load_tagger_ner('ner') results <- get_entities_batch(texts, doc_ids, tagger_ner) print(results)}"},{"path":"https://davidycliao.github.io/flaiR/reference/get_flair_version.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve Flair Version — get_flair_version","title":"Retrieve Flair Version — get_flair_version","text":"Gets version installed Flair module current Python environment.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/get_flair_version.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve Flair Version — get_flair_version","text":"","code":"get_flair_version(...)"},{"path":"https://davidycliao.github.io/flaiR/reference/get_flair_version.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve Flair Version — get_flair_version","text":"Character string representing version Flair. Flair installed, may return `NULL` cause error (based `reticulate` behavior).","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/get_pos.html","id":null,"dir":"Reference","previous_headings":"","what":"Tagging Part-of-Speech Tagging with Flair Models — get_pos","title":"Tagging Part-of-Speech Tagging with Flair Models — get_pos","text":"function returns data table POS tags related  data given texts.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/get_pos.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tagging Part-of-Speech Tagging with Flair Models — get_pos","text":"","code":"get_pos(   texts,   doc_ids = NULL,   tagger = NULL,   language = NULL,   show.text_id = FALSE,   gc.active = FALSE )"},{"path":"https://davidycliao.github.io/flaiR/reference/get_pos.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tagging Part-of-Speech Tagging with Flair Models — get_pos","text":"texts character vector containing texts processed. doc_ids character vector containing document ids. tagger tagger object (default NULL). language language texts (default NULL). show.text_id logical value. TRUE, includes actual text entity extracted resulting data table. Useful verification traceability purposes might increase size output. Default FALSE. gc.active logical value. TRUE, runs garbage collector processing texts. can help freeing memory releasing unused memory space, especially processing large number texts. Default FALSE.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/get_pos.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tagging Part-of-Speech Tagging with Flair Models — get_pos","text":"data.table containing following columns: doc_id document identifier corresponding text. token_id token number original text,   indicating position token. text_id actual text input passed function. token individual word token text   POS tagged. tag part--speech tag assigned token   Flair library. precision confidence score (numeric)   assigned POS tag.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/get_pos.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tagging Part-of-Speech Tagging with Flair Models — get_pos","text":"","code":"if (FALSE) { library(reticulate) library(fliaR) tagger_pos_fast <- load_tagger_pos('pos-fast') texts <- c(\"UCD is one of the best universities in Ireland.\",            \"Essex is not in the Russell Group, but it is famous for political science research.\",            \"TCD is the oldest university in Ireland.\") doc_ids <- c(\"doc1\", \"doc2\", \"doc3\")  get_pos(texts, doc_ids, tagger_pos_fast) }"},{"path":"https://davidycliao.github.io/flaiR/reference/get_pos_batch.html","id":null,"dir":"Reference","previous_headings":"","what":"Batch Process of Part-of-Speech Tagging — get_pos_batch","title":"Batch Process of Part-of-Speech Tagging — get_pos_batch","text":"function returns data table POS tags related data given texts using batch processing.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/get_pos_batch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Batch Process of Part-of-Speech Tagging — get_pos_batch","text":"","code":"get_pos_batch(   texts,   doc_ids,   tagger = NULL,   language = NULL,   show.text_id = FALSE,   gc.active = FALSE,   batch_size = 5,   device = \"cpu\",   verbose = TRUE )"},{"path":"https://davidycliao.github.io/flaiR/reference/get_pos_batch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Batch Process of Part-of-Speech Tagging — get_pos_batch","text":"texts character vector containing texts processed. doc_ids character vector containing document ids. tagger tagger object (default NULL). language language texts (default NULL). show.text_id logical value. TRUE, includes actual text entity extracted resulting data table. Useful verification traceability purposes might increase size output. Default FALSE. gc.active logical value. TRUE, runs garbage collector processing texts. can help freeing memory releasing unused memory space, especially processing large number texts. Default FALSE. batch_size integer specifying size batch. Default 5. device character string specifying computation device. \"cuda\" \"cuda:0\" (\"mps\" \"mps:0\" Mac M1/M2 )Refers first GPU system.       one GPU, specifying \"cuda\" \"cuda:0\" allocate       computations GPU. \"cuda:1\" (\"mps:1\")Refers second GPU system, allowing allocation       specific computations GPU. \"cuda:2\" (\"mps:2)Refers third GPU system, systems       GPUs. verbose logical value. TRUE, function prints batch processing progress updates. Default TRUE.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/get_pos_batch.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Batch Process of Part-of-Speech Tagging — get_pos_batch","text":"data.table containing following columns: doc_id document identifier corresponding text. token_id token number original text,   indicating position token. text_id actual text input passed function (show.text_id TRUE). token individual word token text   POS tagged. tag part--speech tag assigned token   Flair library. precision confidence score (numeric)   assigned POS tag.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/get_pos_batch.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Batch Process of Part-of-Speech Tagging — get_pos_batch","text":"","code":"if (FALSE) { library(reticulate) library(fliaR) tagger_pos_fast <- load_tagger_pos('pos-fast') texts <- c(\"UCD is one of the best universities in Ireland.\",            \"Essex is not in the Russell Group, but it is famous for political science research.\",            \"TCD is the oldest university in Ireland.\") doc_ids <- c(\"doc1\", \"doc2\", \"doc3\")  # Using the batch_size parameter get_pos_batch(texts, doc_ids, tagger_pos_fast, batch_size = 2) }"},{"path":"https://davidycliao.github.io/flaiR/reference/get_sentiments.html","id":null,"dir":"Reference","previous_headings":"","what":"Tagging Sentiment with Flair Standard Models — get_sentiments","title":"Tagging Sentiment with Flair Standard Models — get_sentiments","text":"function takes texts associated document IDs predict sentiments using flair Python library.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/get_sentiments.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tagging Sentiment with Flair Standard Models — get_sentiments","text":"","code":"get_sentiments(   texts,   doc_ids,   tagger = NULL,   ...,   language = NULL,   show.text_id = FALSE,   gc.active = FALSE )"},{"path":"https://davidycliao.github.io/flaiR/reference/get_sentiments.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tagging Sentiment with Flair Standard Models — get_sentiments","text":"texts list vector texts sentiment prediction made. doc_ids list vector document IDs corresponding texts. tagger optional flair sentiment model. NULL (default), function loads default model based language. ... Additional arguments passed next. language character string indicating language texts.  Currently supports \"sentiment\" (English), \"sentiment-fast\" (English), \"de-offensive-language\" (German) show.text_id logical value. TRUE, includes actual text sentiment predicted. Default FALSE. gc.active logical value. TRUE, runs garbage collector processing texts. can help freeing memory releasing unused memory space, especially processing large number texts. Default FALSE.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/get_sentiments.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tagging Sentiment with Flair Standard Models — get_sentiments","text":"data.table containing three columns:  doc_id: document ID input. sentiment: Predicted sentiment text. score: Score sentiment prediction.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/get_sentiments.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tagging Sentiment with Flair Standard Models — get_sentiments","text":"","code":"if (FALSE) { library(flaiR) texts <- c(\"UCD is one of the best universities in Ireland.\",            \"UCD has a good campus but is very far from my apartment in Dublin.\",            \"Essex is famous for social science research.\",            \"Essex is not in the Russell Group, but it is famous for political science research.\",            \"TCD is the oldest university in Ireland.\",            \"TCD is similar to Oxford.\")  doc_ids <- c(\"doc1\", \"doc2\", \"doc3\", \"doc4\", \"doc5\", \"doc6\")  # Load re-trained sentiment (\"sentiment\") model tagger_sent <- load_tagger_sentiments('sentiment')  results <- get_sentiments(texts, doc_ids, tagger_sent) print(results) }"},{"path":"https://davidycliao.github.io/flaiR/reference/get_sentiments_batch.html","id":null,"dir":"Reference","previous_headings":"","what":"Batch Process of Tagging Sentiment with Flair Models — get_sentiments_batch","title":"Batch Process of Tagging Sentiment with Flair Models — get_sentiments_batch","text":"function takes texts associated document IDs predict sentiments using flair Python library.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/get_sentiments_batch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Batch Process of Tagging Sentiment with Flair Models — get_sentiments_batch","text":"","code":"get_sentiments_batch(   texts,   doc_ids,   tagger = NULL,   ...,   language = NULL,   show.text_id = FALSE,   gc.active = FALSE,   batch_size = 5,   device = \"cpu\",   verbose = FALSE )"},{"path":"https://davidycliao.github.io/flaiR/reference/get_sentiments_batch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Batch Process of Tagging Sentiment with Flair Models — get_sentiments_batch","text":"texts list vector texts sentiment prediction made. doc_ids list vector document IDs corresponding texts. tagger optional flair sentiment model. NULL (default), function loads default model based language. ... Additional arguments passed next. language character string indicating language texts.  Currently supports \"sentiment\" (English), \"sentiment-fast\" (English), \"de-offensive-language\" (German) show.text_id logical value. TRUE, includes actual text sentiment predicted. Default FALSE. gc.active logical value. TRUE, runs garbage collector processing texts. can help freeing memory releasing unused memory space, especially processing large number texts. Default FALSE. batch_size integer specifying number texts processed . can help optimize performance leveraging parallel processing. Default 5. device character string specifying computation device. can either \"cpu\" string representation GPU device number. instance, \"0\" corresponds first GPU. GPU device number provided, attempt use GPU. default \"cpu\". \"cuda\" \"cuda:0\" (\"mps\" \"mps:0\" Mac M1/M2 )Refers first GPU system.       one GPU, specifying \"cuda\" \"cuda:0\" allocate       computations GPU. \"cuda:1\" (\"mps:1\")Refers second GPU system, allowing allocation       specific computations GPU. \"cuda:2\" (\"mps:2)Refers third GPU system, systems       GPUs. verbose logical value. TRUE, function prints batch processing progress updates. Default TRUE.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/get_sentiments_batch.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Batch Process of Tagging Sentiment with Flair Models — get_sentiments_batch","text":"data.table containing three columns:  doc_id: document ID input. sentiment: Predicted sentiment text. score: Score sentiment prediction.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/get_sentiments_batch.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Batch Process of Tagging Sentiment with Flair Models — get_sentiments_batch","text":"","code":"if (FALSE) { library(flaiR)   texts <- c(\"UCD is one of the best universities in Ireland.\",            \"UCD has a good campus but is very far from my apartment in Dublin.\",            \"Essex is famous for social science research.\",            \"Essex is not in the Russell Group, but it is famous for political science research.\",            \"TCD is the oldest university in Ireland.\",            \"TCD is similar to Oxford.\")  doc_ids <- c(\"doc1\", \"doc2\", \"doc3\", \"doc4\", \"doc5\", \"doc6\")  # Load re-trained sentiment (\"sentiment\") model tagger_sent <- load_tagger_sentiments('sentiment')  results <- get_sentiments_batch(texts, doc_ids, tagger_sent, batch_size = 3) print(results) }"},{"path":"https://davidycliao.github.io/flaiR/reference/highlight_text.html","id":null,"dir":"Reference","previous_headings":"","what":"Highlight Entities with Specified Colors and Tag — highlight_text","title":"Highlight Entities with Specified Colors and Tag — highlight_text","text":"function highlights specified entities text string specified background colors, font colors, optional labels. Additionally, allows setting specific font type highlighted text.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/highlight_text.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Highlight Entities with Specified Colors and Tag — highlight_text","text":"","code":"highlight_text(text, entities_mapping, font_family = \"Arial\")"},{"path":"https://davidycliao.github.io/flaiR/reference/highlight_text.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Highlight Entities with Specified Colors and Tag — highlight_text","text":"text character string containing text highlight. entities_mapping named list lists, sub-list containing: words: character vector words highlight. background_color: character string specifying CSS color highlight background. font_color: character string specifying CSS color highlighted text. label: character string specifying label append highlighted word. label_color: character string specifying CSS color label text. font_family character string specifying CSS font family highlighted text label. Default \"Arial\".","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/highlight_text.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Highlight Entities with Specified Colors and Tag — highlight_text","text":"HTML object containing text highlighted entities.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/highlight_text.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Highlight Entities with Specified Colors and Tag — highlight_text","text":"","code":"library(flaiR) data(\"uk_immigration\") uk_immigration <- head(uk_immigration, 1) tagger_ner <- load_tagger_ner(\"ner\") results <- get_entities(uk_immigration$text,                         uk_immigration$speaker,                         tagger_ner,                         show.text_id = FALSE)  highlighted_text <- highlight_text(uk_immigration$text, map_entities(results)) print(highlighted_text) #> <div style=\"text-align: justify; font-family: Arial\">I thank Mr. Speaker for giving me permission to hold this debate today. I welcome the Minister-I very much appreciate the contact from his office prior to today-and the <span style=\"background-color: pink; color: black; font-family: Arial\">Conservative<\/span> <span style=\"color: pink; font-family: Arial\">(ORG)<\/span> and <span style=\"background-color: pink; color: black; font-family: Arial\">Liberal Democrat Front Benchers<\/span> <span style=\"color: pink; font-family: Arial\">(ORG)<\/span> to the debate. I also welcome my hon. Friends on the <span style=\"background-color: yellow; color: black; font-family: Arial\">Back Benches<\/span> <span style=\"color: orange; font-family: Arial\">(MISC)<\/span>. Immigration is the most important issue for my constituents. I get more complaints, comments and suggestions about immigration than about anything else. In the <span style=\"background-color: lightblue; color: black; font-family: Arial\">Kettering<\/span> <span style=\"color: blue; font-family: Arial\">(LOC)<\/span> constituency, the number of immigrants is actually very low. There is a well-settled <span style=\"background-color: yellow; color: black; font-family: Arial\">Sikh<\/span> <span style=\"color: orange; font-family: Arial\">(MISC)<\/span> community in the middle of <span style=\"background-color: lightblue; color: black; font-family: Arial\">Kettering<\/span> <span style=\"color: blue; font-family: Arial\">(LOC)<\/span> town itself, which has been in <span style=\"background-color: lightblue; color: black; font-family: Arial\">Kettering<\/span> <span style=\"color: blue; font-family: Arial\">(LOC)<\/span> for some 40 or 50 years and is very much part of the local community and of the fabric of local life. There are other very small migrant groups in my constituency, but it is predominantly made up of indigenous <span style=\"background-color: yellow; color: black; font-family: Arial\">British<\/span> <span style=\"color: orange; font-family: Arial\">(MISC)<\/span> people. However, there is huge concern among my constituents about the level of immigration into our country. I believe that I am right in saying that, in recent years, net immigration into the <span style=\"background-color: lightblue; color: black; font-family: Arial\">United Kingdom<\/span> <span style=\"color: blue; font-family: Arial\">(LOC)<\/span> is the largest wave of immigration that our country has ever known and, proportionately, is probably the biggest wave of immigration since the <span style=\"background-color: yellow; color: black; font-family: Arial\">Norman<\/span> <span style=\"color: orange; font-family: Arial\">(MISC)<\/span> conquest. My contention is that our country simply cannot cope with immigration on that scale-to coin a phrase, we simply cannot go on like this. It is about time that mainstream politicians started airing the views of their constituents, because for too long people have muttered under their breath that they are concerned about immigration. They have been frightened to speak out about it because they are frightened of being accused of being racist. My contention is that immigration is not a racist issue; it is a question of numbers. I personally could not care tuppence about the ethnicity of the immigrants concerned, the colour of their skin or the language that they speak. What I am concerned about is the very large numbers of new arrivals to our country. My contention is that the <span style=\"background-color: lightblue; color: black; font-family: Arial\">United Kingdom<\/span> <span style=\"color: blue; font-family: Arial\">(LOC)<\/span> simply cannot cope with them.<\/div>"},{"path":"https://davidycliao.github.io/flaiR/reference/load_tagger_ner.html","id":null,"dir":"Reference","previous_headings":"","what":"Load the Named Entity Recognition (NER) Tagger — load_tagger_ner","title":"Load the Named Entity Recognition (NER) Tagger — load_tagger_ner","text":"helper function load appropriate tagger based provided language. function supports variety languages/models.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/load_tagger_ner.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load the Named Entity Recognition (NER) Tagger — load_tagger_ner","text":"","code":"load_tagger_ner(language = NULL)"},{"path":"https://davidycliao.github.io/flaiR/reference/load_tagger_ner.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load the Named Entity Recognition (NER) Tagger — load_tagger_ner","text":"language character string indicating desired language NER tagger. `NULL`, function default 'pos-fast' model. Supported languages models include: `\"en\"` - English NER tagging (`ner`) `\"de\"` - German NER tagging (`de-ner`) `\"fr\"` - French NER tagging (`fr-ner`) `\"nl\"` - Dutch NER tagging (`nl-ner`) `\"da\"` - Danish NER tagging (`da-ner`) `\"ar\"` - Arabic NER tagging (`ar-ner`) `\"ner-fast\"` - English NER fast model (`ner-fast`) `\"ner-large\"` - English NER large mode (`ner-large`) `\"de-ner-legal\"` - NER (legal text) (`de-ner-legal`) `\"nl\"` - Dutch NER tagging (`nl-ner`) `\"da\"` - Danish NER tagging (`da-ner`) `\"ar\"` - Arabic NER tagging (`ar-ner`)","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/load_tagger_ner.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Load the Named Entity Recognition (NER) Tagger — load_tagger_ner","text":"instance Flair SequenceTagger specified language.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/load_tagger_ner.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Load the Named Entity Recognition (NER) Tagger — load_tagger_ner","text":"","code":"# Load the English NER tagger tagger_en <- load_tagger_ner(\"en\")"},{"path":"https://davidycliao.github.io/flaiR/reference/load_tagger_pos.html","id":null,"dir":"Reference","previous_headings":"","what":"Load Flair POS Tagger — load_tagger_pos","title":"Load Flair POS Tagger — load_tagger_pos","text":"function loads POS (part--speech) tagger model specified language using Flair library. language specified, defaults 'pos-fast'.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/load_tagger_pos.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load Flair POS Tagger — load_tagger_pos","text":"","code":"load_tagger_pos(language = NULL)"},{"path":"https://davidycliao.github.io/flaiR/reference/load_tagger_pos.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load Flair POS Tagger — load_tagger_pos","text":"language character string indicating desired language model. `NULL`, function default 'pos-fast' model. Supported language models include: \"pos\" - General POS tagging \"pos-fast\" - Faster POS tagging \"upos\" - Universal POS tagging \"upos-fast\" - Faster Universal POS tagging \"pos-multi\" - Multi-language POS tagging \"pos-multi-fast\" - Faster Multi-language POS tagging \"ar-pos\" - Arabic POS tagging \"de-pos\" - German POS tagging \"de-pos-tweets\" - German POS tagging tweets \"da-pos\" - Danish POS tagging \"ml-pos\" - Malayalam POS tagging \"ml-upos\" - Malayalam Universal POS tagging \"pt-pos-clinical\" - Clinical Portuguese POS tagging \"pos-ukrainian\" - Ukrainian POS tagging","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/load_tagger_pos.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Load Flair POS Tagger — load_tagger_pos","text":"Flair POS tagger model corresponding specified (default) language.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/load_tagger_pos.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Load Flair POS Tagger — load_tagger_pos","text":"","code":"if (FALSE) { tagger <- load_tagger_pos(\"pos-fast\") }"},{"path":"https://davidycliao.github.io/flaiR/reference/load_tagger_sentiments.html","id":null,"dir":"Reference","previous_headings":"","what":"Load a Sentiment or Language Tagger Model from Flair — load_tagger_sentiments","title":"Load a Sentiment or Language Tagger Model from Flair — load_tagger_sentiments","text":"function loads pre-trained sentiment language tagger Flair library.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/load_tagger_sentiments.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load a Sentiment or Language Tagger Model from Flair — load_tagger_sentiments","text":"","code":"load_tagger_sentiments(language = NULL)"},{"path":"https://davidycliao.github.io/flaiR/reference/load_tagger_sentiments.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load a Sentiment or Language Tagger Model from Flair — load_tagger_sentiments","text":"language character string specifying language model load. Supported models include: \"sentiment\" - Sentiment analysis model \"sentiment-fast\" - Faster sentiment analysis model \"de-offensive-language\" - German offensive language detection model provided, function default \"sentiment\" model.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/load_tagger_sentiments.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Load a Sentiment or Language Tagger Model from Flair — load_tagger_sentiments","text":"object loaded Flair model.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/load_tagger_sentiments.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Load a Sentiment or Language Tagger Model from Flair — load_tagger_sentiments","text":"","code":"if (FALSE) {   tagger <- load_tagger_sentiments(\"sentiment\") }"},{"path":"https://davidycliao.github.io/flaiR/reference/map_entities.html","id":null,"dir":"Reference","previous_headings":"","what":"Create Mapping for NER Highlighting — map_entities","title":"Create Mapping for NER Highlighting — map_entities","text":"function generates mapping list Named Entity Recognition (NER) highlighting. mapping list defines different entity types highlighted text displays, defining background color, font color, label, label color entity type.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/map_entities.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create Mapping for NER Highlighting — map_entities","text":"","code":"map_entities(df, entity = \"entity\", tag = \"tag\")"},{"path":"https://davidycliao.github.io/flaiR/reference/map_entities.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create Mapping for NER Highlighting — map_entities","text":"df data frame containing least two columns: entity: character vector words/entities highlighted. tag: character vector indicating entity type word/entity. entity character vector entities annotated model. tag character vector tags corresponding annotated entities.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/map_entities.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create Mapping for NER Highlighting — map_entities","text":"list mapping settings entity type, entity type represented list containing:  words: character vector words highlighted. background_color: character string representing background color highlighting words. font_color: character string representing font color words. label: character string label entity type. label_color: character string representing font color label.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/map_entities.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create Mapping for NER Highlighting — map_entities","text":"","code":"if (FALSE) {   sample_df <- data.frame(     entity = c(\"Microsoft\", \"USA\", \"dollar\", \"Bill Gates\"),     tag = c(\"ORG\", \"LOC\", \"MISC\", \"PER\"),     stringsAsFactors = FALSE   )   mapping <- map_entities(sample_df) }"},{"path":"https://davidycliao.github.io/flaiR/reference/show_flair_cache.html","id":null,"dir":"Reference","previous_headings":"","what":"Show Flair Cache Preloaed flair's Directory — show_flair_cache","title":"Show Flair Cache Preloaed flair's Directory — show_flair_cache","text":"function lists contents flair cache directory returns data frame.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/show_flair_cache.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Show Flair Cache Preloaed flair's Directory — show_flair_cache","text":"","code":"show_flair_cache()"},{"path":"https://davidycliao.github.io/flaiR/reference/show_flair_cache.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Show Flair Cache Preloaed flair's Directory — show_flair_cache","text":"data frame containing file paths contents flair cache directory. directory exist empty, NULL returned.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/show_flair_cache.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Show Flair Cache Preloaed flair's Directory — show_flair_cache","text":"","code":"if (FALSE) { show_flair_cache() }"},{"path":"https://davidycliao.github.io/flaiR/reference/uk_immigration.html","id":null,"dir":"Reference","previous_headings":"","what":"UK House of Commons Immigration Debate Data — uk_immigration","title":"UK House of Commons Immigration Debate Data — uk_immigration","text":"dataset containing speeches debates UK House Commons topic immigration 2010.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/uk_immigration.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"UK House of Commons Immigration Debate Data — uk_immigration","text":"","code":"data(\"uk_immigration\")"},{"path":"https://davidycliao.github.io/flaiR/reference/uk_immigration.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"UK House of Commons Immigration Debate Data — uk_immigration","text":"data frame 12 variables: date Date speech, Date type agenda Agenda subject speech, character speechnumber Unique identifier speech, numeric speaker Name person giving speech, character party Political party speaker, character party.facts.id ID party, usually numeric character chair Person chairing session, character terms Terms tags associated speech, character list text Actual text speech, character parliament parliament session, character numeric iso3country ISO3 country code   parliament located, character year Year speech made, numeric","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/uk_immigration.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"UK House of Commons Immigration Debate Data — uk_immigration","text":"Data collected `ParSpeechV2` House Commons year 2010. dataset publicly available https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/L4OAKN.","code":""},{"path":"https://davidycliao.github.io/flaiR/reference/uk_immigration.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"UK House of Commons Immigration Debate Data — uk_immigration","text":"","code":"if (FALSE) { data(uk_immigration) head(uk_immigration) }"},{"path":"https://davidycliao.github.io/flaiR/news/index.html","id":"flair-005-2020-10-01","dir":"Changelog","previous_headings":"","what":"flaiR 0.0.5 (2020-10-01)","title":"flaiR 0.0.5 (2020-10-01)","text":"Added tests monitor function performance. However, zzz.R utils.R still fall 80%. Added wrapped functions integrating Python code. Created function coloring entities. Provided tutorials interacting R Python using Flair. add tutorial","code":""},{"path":"https://davidycliao.github.io/flaiR/news/index.html","id":"flair-003-2020-09-10","dir":"Changelog","previous_headings":"","what":"flaiR 0.0.3 (2020-09-10)","title":"flaiR 0.0.3 (2020-09-10)","text":"Modifications Overview Added show.text_id gc.active parameters get_entities(), get_pos(), get_sentiment(). Enhanced batch processing introduction batch_size functions get_entities_batch(), get_pos_batch(), get_sentiment_batch(). Introduced device parameter specify computation device. Introduction New Parameters: show.text_id: activated (TRUE), actual text (labeled ‘text_id’) entity derived appended resulting dataset. Although enriching output validation traceability, users cautious, might inflate output size. default, option remains deactivated (FALSE). context, previously, ‘text_id’ intrinsically generated, potentially elevating R’s memory consumption. gc.active: Activating (TRUE) trigger garbage collector post-text processing. action aids memory optimization relinquishing unallocated memory spaces, crucial step, particularly processing extensive text dataset. default set FALSE, users managing larger texts consider setting gc.active TRUE. Though action doesn’t bolster computational efficiency, circumvent potential RStudio crashes. Batch Processing Enhancement: inception batch_size parameter (defaulted 5) get_entities_batch(), get_pos_batch(), get_sentiment_batch() augments batch processing capabilities. addition led creation internal function named process_batch proficiently manage text batch linked doc_ids. core functionality adapted segregate texts doc_ids specific batches, subsequently processed via process_batch function, final results amalgamated seamlessly. device: descriptive character string pinpointing computation device. Users can opt “cpu” GPU device number string format. instance, representing primary GPU 0. GPU device number furnished, system endeavor harness specific GPU, “cpu” default setting. batch_size: integer specifying size batch. Default 5.","code":""},{"path":"https://davidycliao.github.io/flaiR/news/index.html","id":"flair-001-development-version","dir":"Changelog","previous_headings":"","what":"flaiR 0.0.1 (development version)","title":"flaiR 0.0.1 (development version)","text":"features flaiR currently include part--speech tagging, sentiment tagging, named entity recognition tagging. flaiR requires Python version 3.7 higher operate concurrently. create_flair_env(): function install Flair Python library using reticulate R package, automatically generated.","code":""}]
