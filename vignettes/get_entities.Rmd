---
title: "Tagging Named Entities with Flair Standard Models"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Tagging Named Entities with Flair Standard Models}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---


```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r, include = FALSE}
library(flaiR)
library(reticulate)
# system(paste(reticulate::py_config()$python, "-m pip install flair"))
reticulate::py_install("flair")
```

## Generic Approach Using Pre-trained NER English Model

```{r}
library(flaiR)
data("uk_immigration")
uk_immigration <- head(uk_immigration, 10)
```

<div style="text-align: justify">

Use `load_tagger_ner` to call the NER pretrained model. The model will be downloaded from Flair's Hugging Face repo. Thus, ensure you have an internet connection. Once downloaded, the model will be stored in __.flair__ as the cache in your device. So, once you've downloaded it and it hasn't been manually removed, executing the command again will not trigger a download.
</div>

```{r}
tagger_ner <- load_tagger_ner("ner")
```
<div style="text-align: justify">

If you want the computation to run faster, it is recommended to keep the show.text_id set to FALSE by default. 
</div>
```{r}
time <- system.time({
    results <- get_entities(uk_immigration$text,
                            uk_immigration$speaker, 
                            tagger_ner,
                            show.text_id = FALSE
                            )
    gc()
})

print(time)
```

```{r}
print(results)
```

## Batch Processing

<div style="text-align: justify">
Processing texts individually can be both inefficient and memory-intensive. On the other hand, processing all the texts simultaneously could surpass memory constraints, especially if each document in the dataset is sizable. Parsing the documents in smaller batches may provide an optimal compromise between these two scenarios. Batch processing can enhance efficiency and aid in memory management.

</div>


```{r}
batch_process_time <- system.time({
    batch_process_results  <- get_entities_batch(uk_immigration$text,
                                                 uk_immigration$speaker, 
                                                 tagger_ner, 
                                                 show.text_id = FALSE,
                                                 batch_size = 5)
    gc()
})
print(batch_process_time)
```

```{r}
print(batch_process_results)
```
