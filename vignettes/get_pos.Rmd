---
title: "Tagging Part-of-Speech Tagging with Flair Standard Models"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Tagging Part-of-Speech Tagging with Flair Standard Models}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```


```{r, include = FALSE}
library(flaiR)
library(reticulate)
# system(paste(reticulate::py_config()$python, "-m pip install flair"))
reticulate::py_install("flair")
```

## Generic Approach Using Part-of-Speech Tagging

```{r}
library(flaiR)
data("de_immigration")
uk_immigration <- head(uk_immigration, 2)
```

Download the de-pos part-of-speech tagging model from FlairNLP on Hugging Face.
```{r}
tagger_pos <- load_tagger_pos("pos")
```

Flair NLP operates under the [PyTorch](https://pytorch.org) framework. As such, we can use the `$to` method to set the device for the Flair Python library. The flair_device("cpu")  allows you to select whether to use the CPU, CUDA devices (like cuda:0, cuda:1, cuda:2), or specific MPS devices on Mac (such as mps:0, mps:1, mps:2). For information on Accelerated PyTorch training on Mac, please refer to https://developer.apple.com/metal/pytorch/. For more about CUDA, please visit: https://developer.nvidia.com/cuda-zone 


```{r eval=FALSE, include=TRUE}
tagger_pos$to(flair_device("mps")) 
```

```
SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): FlairEmbeddings(
      (lm): LanguageModel(
        (drop): Dropout(p=0.05, inplace=False)
        (encoder): Embedding(300, 100)
        (rnn): LSTM(100, 2048)
        (decoder): Linear(in_features=2048, out_features=300, bias=True)
      )
    )
    (list_embedding_1): FlairEmbeddings(
      (lm): LanguageModel(
        (drop): Dropout(p=0.05, inplace=False)
        (encoder): Embedding(300, 100)
        (rnn): LSTM(100, 2048)
        (decoder): Linear(in_features=2048, out_features=300, bias=True)
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=4096, out_features=4096, bias=True)
  (rnn): LSTM(4096, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=53, bias=True)
  (loss_function): ViterbiLoss()
  (crf): CRF()
)
```
```{r}
results <- get_pos(uk_immigration$text, 
                   uk_immigration$speaker, tagger_pos, 
                   show.text_id = FALSE,
                   gc.active = FALSE)
print(results)
```


## Batch Processing
```{r}
batch_process_results  <- get_pos_batch(uk_immigration$text,
                                        uk_immigration$speaker, 
                                        tagger_pos, 
                                        show.text_id = FALSE,
                                        batch_size = 10,
                                        verbose = TRUE)
print(batch_process_results)
```




