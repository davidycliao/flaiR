---
title: "Tagging Sentiment with Flair Standard Models"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Tagging Sentiment with Flair Standard Models}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r, include = FALSE}
library(flaiR)
library(reticulate)

# system(paste(reticulate::py_config()$python, "-m pip install flair"))
reticulate::py_install("flair")

```


## An Example Using `sentiment` Model (Pre-trained English Model)
```{r}
library(flaiR)
data("uk_immigration")
uk_immigration <- head(uk_immigration, 5)
```

<div style="text-align: justify">

Download the English sentiment model from FlairNLP on [Hugging Face](https://huggingface.co/flair). Currently, it also supports a large English sentiment model and a German pre-trained model.

```{r}
tagger_sent <- load_tagger_sentiments("sentiment")
```

Flair NLP operates under the [PyTorch](https://pytorch.org) framework. As such, we can use the `$to` method to set the device for the Flair Python library. The flair_device("cpu")  allows you to select whether to use the CPU, CUDA devices (like cuda:0, cuda:1, cuda:2), or specific MPS devices on Mac (such as mps:0, mps:1, mps:2). For information on Accelerated PyTorch training on Mac, please refer to https://developer.apple.com/metal/pytorch/. For more about CUDA, please visit: https://developer.nvidia.com/cuda-zone 

```{r eval=FALSE, include=TRUE}
tagger_sent$to(flair_device("mps")) 
```

```
TextClassifier(
  (embeddings): TransformerDocumentEmbeddings(
    (model): DistilBertModel(
      (embeddings): Embeddings(
        (word_embeddings): Embedding(30522, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (transformer): Transformer(
        (layer): ModuleList(
          (0-5): 6 x TransformerBlock(
            (attention): MultiHeadSelfAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (q_lin): Linear(in_features=768, out_features=768, bias=True)
              (k_lin): Linear(in_features=768, out_features=768, bias=True)
              (v_lin): Linear(in_features=768, out_features=768, bias=True)
              (out_lin): Linear(in_features=768, out_features=768, bias=True)
            )
            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (ffn): FFN(
              (dropout): Dropout(p=0.1, inplace=False)
              (lin1): Linear(in_features=768, out_features=3072, bias=True)
              (lin2): Linear(in_features=3072, out_features=768, bias=True)
              (activation): GELUActivation()
            )
            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          )
        )
      )
    )
  )
  (decoder): Linear(in_features=768, out_features=2, bias=True)
  (dropout): Dropout(p=0.0, inplace=False)
  (locked_dropout): LockedDropout(p=0.0)
  (word_dropout): WordDropout(p=0.0)
  (loss_function): CrossEntropyLoss()
)
```
```{r }
results <- get_sentiments(uk_immigration$text, seq_len(nrow(uk_immigration)),
                          tagger_sent)
```

```{r}
print(results)
```

</div>

## Batch Processing in English Sentiment Model
```{r}
batch_process_results  <- get_sentiments_batch(uk_immigration$text,
                                               uk_immigration$speaker, 
                                               tagger_sent, 
                                               show.text_id = FALSE,
                                               batch_size = 2,
                                               verbose = TRUE)
```

```{r}
print(batch_process_results)
```

