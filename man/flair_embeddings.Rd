% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/flair_embeddings.R
\name{flair_embeddings}
\alias{flair_embeddings}
\title{Initialization of Flair Embeddings Modules}
\usage{
flair_embeddings()
}
\value{
The \code{flair.embeddings} module from Flair.
}
\description{
This function provides an interface for R users to access and utilize the
\code{flair.embeddings} module from the Flair NLP library. Flair's embedding functionalities offer
various state-of-the-art embeddings crucial for natural language processing tasks. By using this function,
R users can seamlessly incorporate these advanced embeddings into their NLP workflows without delving
deep into Python. Essentially, this function acts as a bridge between R's ecosystem and Flair's rich
embedding capabilities.
}
\details{
This function allows R users to access the following Flair embeddings modules:
\describe{
  \item{FlairEmbeddings}{Contextual string embeddings capturing latent syntactic-semantic information beyond standard word embeddings.}
  \item{WordEmbeddings}{Classic word embeddings like GloVe or FastText.}
  \item{TransformerWordEmbeddings}{Word embeddings from transformer models such as BERT, RoBERTa, etc.}
  \item{TransformerDocumentEmbeddings}{Transformer-based embeddings for entire documents or sentences.}
  \item{StackedEmbeddings}{Combines multiple embeddings for a richer representation.}
  \item{DocumentPoolEmbeddings}{Provides a single embedding vector for an entire document based on the chosen operation mode (mean, max, etc.).}
  \item{BytePairEmbeddings}{Embeddings based on the Byte-Pair Encoding (BPE) mechanism used in subword tokenization.}
  \item{ELMoEmbeddings}{Deep contextual embeddings derived from the internal state of a pretrained bidirectional LSTM.}
}
Each embedding type offers unique features suitable for various NLP tasks. By understanding their differences and capabilities, R users can select
the appropriate embeddings to enhance their NLP models.
}
\examples{
Example 1: Initialize FlairEmbeddings
FlairEmbeddings <- flair_embeddings()$FlairEmbeddings
embedding <- FlairEmbeddings('news-forward')

Example 2: Initialize WordEmbeddings
WordEmbeddings <- flair_embeddings()$WordEmbeddings
embedding <- WordEmbeddings('glove')

Example 3: Initialize TransformerWordEmbeddings
TransformerWordEmbeddings <- flair_embeddings()$TransformerWordEmbeddings
embedding <- TransformerWordEmbeddings('bert-base-uncased')

Example 4: Initialize TransformerDocumentEmbeddings
TransformerDocumentEmbeddings <- flair_embeddings()$TransformerDocumentEmbeddings
embedding <- TransformerDocumentEmbeddings('bert-base-uncased')

Example 5: Initialize StackedEmbeddings
StackedEmbeddings <- flair_embeddings()$StackedEmbeddings
WordEmbeddings <-  flair_embeddings()$WordEmbeddings
FlairEmbeddings <-  flair_embeddings()$FlairEmbeddings

stacked_embeddings <- StackedEmbeddings(
                                       list(WordEmbeddings('glove'),
                                            FlairEmbeddings('news-forward'),
                                            FlairEmbeddings('news-backward')
                                            )
                                       )

Example 6: Initialize DocumentPoolEmbeddings
DocumentPoolEmbeddings <- flair_embeddings()$DocumentPoolEmbeddings
WordEmbeddings <- flair_embeddings()$WordEmbeddings
doc_embeddings <- DocumentPoolEmbeddings(list(WordEmbeddings('glove')))


}
\references{
In Python's Flair library:
\preformatted{
from flair.embeddings import *
}
}
