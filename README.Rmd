---
output: github_document
---

## <u>`flairR`</u>: An R Wrapper for Accessing Flair NLP Library <img src="man/figures/logo.png" align="right" width="180"/>

[![R-MacOS](https://github.com/davidycliao/flaiR/actions/workflows/r_macos.yml/badge.svg)](https://github.com/davidycliao/flaiR/actions/workflows/r_macos.yml)
[![R-ubuntu](https://github.com/davidycliao/flaiR/actions/workflows/r_ubuntu.yaml/badge.svg)](https://github.com/davidycliao/flaiR/actions/workflows/r_ubuntu.yaml)
[![R-Windows](https://github.com/davidycliao/flaiR/actions/workflows/r_window.yml/badge.svg)](https://github.com/davidycliao/flaiR/actions/workflows/r_window.yml)

[![R-CMD-Check](https://github.com/davidycliao/flaiR/actions/workflows/r.yml/badge.svg)](https://github.com/davidycliao/flaiR/actions/workflows/r.yml)
[![coverage](https://github.com/davidycliao/flaiR/actions/workflows/test-coverage.yaml/badge.svg)](https://github.com/davidycliao/flaiR/actions/workflows/test-coverage.yaml)
[![codecov](https://codecov.io/gh/davidycliao/flaiR/graph/badge.svg?token=CPIBIB6L78)](https://codecov.io/gh/davidycliao/flaiR)
[![CodeFactor](https://www.codefactor.io/repository/github/davidycliao/flair/badge)](https://www.codefactor.io/repository/github/davidycliao/flair)

<!-- README.md is generated from README.Rmd. Please edit that file -->


```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

```{r include=FALSE}
library(reticulate)
library(flaiR)
reticulate::py_install("flair")
system(paste(reticulate::py_config()$python, "-m pip install flair"))
# options(repos = c(CRAN = "https://cloud.r-project.org/"))
install.packages("remotes")
```

<div style="text-align: justify">


`flaiR` is an R wrapper for accessing the `flairNLP/flair` Python library, specially tailored for R users in social and political sciences. `flaiR` provides easy access to the main functionalities of `flairNLP`. Developed by [Zalando Research in Berlin](https://engineering.zalando.com/posts/2018/11/zalando-research-releases-flair.html).  `flairNLP` is a straightforward framework for state-of-the-art Natural Language Processing (NLP) and is compatible with Hugging Face. Flair offers intuitive interfaces and exceptional multilingual support for various embedding models, transformers and state-of-the-art NLP tasks to analyze text, such as named entity recognition, sentiment analysis, part-of-speech tagging, with support for a rapidly growing number of language models in the community.

For a comprehensive understanding of the `{flairNLP/flair}` architecture and NLP tagging models by [Zalando Research](https://engineering.zalando.com/posts/2018/11/zalando-research-releases-flair.html), you can refer to the research article '[Contextual String Embeddings for Sequence Labeling](https://aclanthology.org/C18-1139.pdf)' and the official [manual](https://flairnlp.github.io) written for its Python implementation. 

`flaiR` unofficial platform provides R users with documentation, examples applied to political and social sciences, and tutorials for using Flair NLP. The aim of this R wrapper is to facilitate the access to powerful NLP tools provided by Flair NLP to R users.


## Tutorial Updates



  
<br>


## Installation via  <u>__`GitHub`__</u>

<div style="text-align: justify">

The installation consists of two parts: First, install [Python 3.8](https://www.python.org/downloads/) or higher (avoid developmental versions and the very latest release for compatibility reasons).  Secondly, install [R 4.2.0](https://www.r-project.org) or higher.

__System Requirement:__

- Python (>= 3.10.x)

- R (>= 4.2.0)

- RStudio _(The GUI interface allows users to adjust and manage the Python environment in R)_

- Anaconda or miniconda _(highly recommended)_

We have tested flaiR using CI/CD with GitHub Actions, conducting integration tests across [various operating syste](https://github.com/davidycliao/flaiR/actions) These tests include intergration between R versions 4.2.1, 4.3.2, and 4.2.0 and Python 3.10.x. The testing also covers environments with flair NLP and PyTorch (given that [Flair NLP](https://flairnlp.github.io) is built on [Torch](https://pytorch.org)). For stable usage, we strongly recommend installing these specific versions.

When first installed, {`flaiR`} automatically detects whether you have Python 3.8 or higher. If not, it will skip the automatic installation of Python and flair NLP. In this case, you will need to manually install it yourself and reload {`flaiR`} again. If you have correct Python installed, the {`flaiR`} will automatically install flair Python NLP in your global environment. If you are using {reticulate}, {flaiR} will typically assume the __r-reticulate__ environment by default. At the same time, you can use `py_config()` to check the location of your environment. Please note that flaiR will directly install flair NLP in the Python environment that your R is using. This environment can be adjusted through _RStudio_ by navigating to __`Tools -> Global Options -> Python`__. If there are any issues with the installation, feel free to ask in the <u>[Discussion](https://github.com/davidycliao/flaiR/discussions) </u>.

First, understanding which Python environment your RStudio is using is very important. We advise you to confirm which Python environment RStudio is using. You can do this by checking with `reticulate::py_config()` or manually via __Tools -> Global Options -> Python__. 

```r
install.packages("reticulate")
reticulate::py_config()
```
At this stage, you'll observe that RStudio has defaulted to using the 'flair_env' environment (my personal environment) I have set up. Then, the Python Flair package will be installed within this environment. Should you wish to modify this setting, you have the option to either adjust it within RStudio's settings or use the {reticulate} package to manage the Python environment in R

```shell
#> python:         /Users/*********/.virtualenvs/flair_env/bin/python
#> libpython:      /Users/*********/.pyenv/versions/3.10.13/lib/libpython3.10.dylib
#> pythonhome:     /Users/*********/.virtualenvs/flair_env:/Users/*********/.virtualenvs/flair_env
#> version:        3.10.13 (main, Oct 27 2023, 04:44:16) [Clang 15.0.0 (clang-1500.0.40.1)]
#> numpy:          /Users/*********/.virtualenvs/flair_env/lib/python3.10/site-packages/numpy
#> numpy_version:  1.26.2
#> flair:          /Users/*********/.virtualenvs/flair_env/lib/python3.10/site-packages/flair

#> NOTE: Python version was forced by use_python() function
```

Now, you can confidently install flaiR in your R environment.
```r
install.packages("remotes")
remotes::install_github("davidycliao/flaiR", force = TRUE)
```

You will notice the following message, indicating a successful installation. This means that your RStudio has successfully detected the correct Python and has installed Flair in your Python environment.
```r
library(flaiR)
#> flaiR: An R Wrapper for Accessing Flair NLP 0.13.0
```

<br>

</div>

## Introduction
  
<div style="text-align: justify">
           
For R users, {`flairR`} primarily consists of two main components. The first is wrapper functions in {`flaiR`} built on top of {`reticulate`}, which enables you to interact directly with Python modules in R and provides seamless support for documents and [tutorial (in progress)](https://davidycliao.github.io/flaiR/articles/tutorial.html) in the R community. The {flaiR} package enables R users to leverage Flair's capabilities to train their own models using the Flair framework and state-of-the-art NLP models without the need to interact directly with Python.

Flair offers a simpler and more intuitive approach for training custom NLP models compared to using Transformer-based models directly. With Flair, data loading and preprocessing are streamlined, facilitating the easy integration of various pre-trained embeddings, including both traditional and Transformer-based types like BERT. The training process in Flair is condensed to just a few lines of code, with automatic handling of fundamental preprocessing steps.  Evaluation and optimization are also made user-friendly with accessible tools.  In addition, Flair NLP provides an easy framework for training language models and is compatible with HuggingFace.


</div>


#### __Training Models with HuggingFace via flaiR__

<div style="text-align: justify">

The following example offers a straightforward introduction on how to fully train your own model using the Flair framework and import a `BERT` model from [HuggingFace ðŸ¤—](https://github.com/huggingface). This example utilizes grandstanding score as training data from Julia Park's paper (_[When Do Politicians Grandstand? Measuring Message Politics in Committee Hearings](https://www.journals.uchicago.edu/doi/abs/10.1086/709147?journalCode=jop&mobileUi=0)_) and trains the model using Transformer-based models via flair NLP through `{flaiR}`.

<u>__Step 1__</u> Load Necessary Modules from Flair

```{r}
# load training data: grandstanding score from Julia Park's paper
library(flaiR)
data(gs_score) 
```

Load necessary classes from `flair` package.
```{r}
# Sentence is a class for holding a text sentence
Sentence <- flair_data()$Sentence

# Corpus is a class for text corpora
Corpus <- flair_data()$Corpus

# TransformerDocumentEmbeddings is a class for loading transformer 
TransformerDocumentEmbeddings <- flair_embeddings()$TransformerDocumentEmbeddings

# TextClassifier is a class for text classification
TextClassifier <- flair_models()$TextClassifier

# ModelTrainer is a class for training and evaluating models
ModelTrainer <- flair_trainers()$ModelTrainer
```


<u>__Step 2__</u> Split and Preprocess Data with Corpus Object

Split data into train and test sets using basic R functions.
```{r}
# split the data
text <- lapply(gs_score$speech, Sentence)
labels <- as.character(gs_score$rescaled_gs)

for (i in 1:length(text)) {
  text[[i]]$add_label("classification", labels[[i]])
}
```

```{r}
set.seed(2046)
sample <- sample(c(TRUE, FALSE), length(text), replace=TRUE, prob=c(0.8, 0.2))
train  <- text[sample]
test   <- text[!sample]
```

If you do not provide a development split (dev split) while using Flair, it will automatically split the training data into training and development datasets. The test set is used for training the model and evaluating its final performance, whereas the development set (dev set) is used for adjusting model parameters and preventing overfitting, or in other words, for early stopping of the model.

```{r}
corpus <- Corpus(train=train, test=test)
```

Alternatively, you can also create dev sets splitting test set. The following code splits the data into train, test, and dev sets with a ratio of 8:1:1.
```{r}
set.seed(2046)
sample <- sample(c(TRUE, FALSE), length(text), replace=TRUE, prob=c(0.8, 0.2))
train  <- text[sample]
test   <- text[!sample]

test_id <- sample(c(TRUE, FALSE), length(test), replace=TRUE, prob=c(0.5, 0.5))
test   <- test[sample]
dev   <- test[!sample]
```


```{r}
corpus <- Corpus(train=train, test=test, dev=dev)
```


<u>__Step 3__</u> Load Transformer Embeddings


```{r}
document_embeddings <- TransformerDocumentEmbeddings('distilbert-base-uncased', fine_tune=TRUE)
```

First, `$make_label_dictionary` function is used to automatically create a label dictionary for the classification task. The label dictionary is a mapping from label to index, which is used to map the labels to a tensor of label indices. expcept classifcation task, flair also supports other label types for training custom model, such as `ner`, `pos` and `sentiment`.

```{r}
label_dict <- corpus$make_label_dictionary(label_type="classification")
```

Besides, you can also create a label dictionary manually. The following code creates a label dictionary with two labels, `0` and `1`, and maps them to the indices `0` and `1` respectively. 

```{r}
# load Dictionary object from flair_data
Dictionary <- flair_data()$Dictionary

# manually create label_dict with two labels, 0 and 1
label_dict <- Dictionary(add_unk=FALSE)

# you can specify the order of labels. Please note the label should be a list and character (string) type.
specific_order_labels <- list('0', '1')

for (label in seq_along(specific_order_labels)) {
  label_dict$add_item(as.character(specific_order_labels [[label]]))
}
```

Then, we can use the `$item2idx` method to check the mapping from label to index. This is very important to make sure the labels are mapped correctly to the indices and tensors.
```{r}
print(label_dict$idx2item)
```

```{r}
print(label_dict$item2idx)
```
`TextClassifier` is used to create a text classifier. The classifier takes the document embeddings (importing from `'distilbert-base-uncased'` from HugginFace)  and the label dictionary as input. The label type is also specified as classification.
```{r}
classifier <- TextClassifier(document_embeddings,
                             label_dictionary=label_dict, 
                             label_type='classification')
```

<u>__Step 4__</u> Start Training 

specific computation devices on your local machine. If you have a GPU, you can use `flair_gpu` to specify the GPU device. If you don't have a GPU, you can use `flaiR::flair_device` to specify the CPU device. 

```{r}
classifier$to(flair_device("cpu")) 
```

`ModelTrainer` is used to train the model, which learns from the data based on the grandstanding score.

```{r eval=FALSE}
trainer <- ModelTrainer(classifier, corpus)
```

```{r eval=FALSE}
trainer$train('grand_standing_model',          # output directory
              learning_rate=0.02,              # learning rate: if batch_growth_annealing activates,lr should starts a bit higher.
              mini_batch_size=8L,              # batch size
              anneal_with_restarts = TRUE,
              save_final_model=TRUE,
              max_epochs=10L)                  # Maximum number of epochs
```

<u>__Step 5__</u> Evaluate the Model

During and after the model training process, evaluating the performance of the trained model on the development set is straightforward and easy.

```{r}
# import the performance metrics generated during the training process
performance_df <- read.table(file = "grand_standing/loss.tsv", header = TRUE, sep = "\t")
head(performance_df)
```

```{r}
library(ggplot2)
ggplot(performance_df, aes(x = EPOCH)) + 
  geom_line(aes(y = TRAIN_LOSS, color = "Training Loss")) +
  geom_line(aes(y = DEV_LOSS, color = "Development Loss")) +
  geom_line(aes(y = DEV_RECALL, color = "Development Recall")) +
  geom_line(aes(y = DEV_F1, color = "Development F1")) +
  labs(title = "Training and Development Loss per Epoch",
       x = "Epochs / Grandstanding Classifier",
       y = "") +
  scale_color_manual("", 
                     values = c("Training Loss" = "blue",
                                "Development Loss" = "red",
                                "Development F1" = "green"))+
  theme_minimal() 

```

The overall performance of the model on the test set is also straightforward and easy to evaluate. You can find the performance metrics in the `model/training.log` file.

```
Results:
- F-score (micro) 0.7443
- F-score (macro) 0.7438
- Accuracy 0.7443

By class:
              precision    recall  f1-score   support

           1     0.6781    0.8519    0.7551       324
           0     0.8362    0.6516    0.7324       376

    accuracy                         0.7443       700
   macro avg     0.7572    0.7517    0.7438       700
weighted avg     0.7630    0.7443    0.7429       700
```

<u>__Step 6__</u> Apply the Trained Model on Unseen Data for Prediction

We use the statement in the dataset as an example.

```{r}
# load the trained model
data(statements)
Sentence <- flair_data()$Sentence

text <- statements[1, "Statement"]
sentence <- Sentence(text)
```

`lassifier$predict function is used to predict the label of the sentence. The function returns a sentence object with the predicted label.` 
```{r}
classifier$predict(sentence)
print(sentence)
```

`sentence$labels` is a list of labels, each of which has a value and a score. The value is the label itself, and the score is the probability of the label. The label with the highest score is the predicted label.

```{r}
sentence$labels[[1]]$value
```

```{r}
sentence$labels[[1]]$score
```

<u>__Step 7__</u> Reload the Model with the Best Performance

When you train the model with `save_final_model=TRUE`, the model with the best performance on the development set will be saved in the output directory. You can reload the model with the best performance using the `load` function.

```{r}
Sentence <- flair_data()$Sentence
TextClassifier <- flair_models()$TextClassifier
classifier <- TextClassifier$load('grand_standing/best-model.pt')
```

We can create a function to classify the text using the specified Flair classifier.
```{r}
classify_text <- function(text, classifier) {
  # Classifies the given text using the specified Flair classifier.
  #
  # Args:
  # text (str): The text to be classified.
  # classifier (TextClassifier): The Flair classifier to use for prediction.
  #
  # Returns:
  #   list: A list containing the predicted class label and score as strings.  
  sentence <- Sentence(text)
  classifier$predict(sentence)
  return(list (labels  = sentence$labels[[1]]$value, score  = as.character(sentence$labels[[1]]$score)))
  }

```

Before performing classification task, let's quickly check the exmaple dataset.
```{r}
data(statements)
print(statements)
```
Let's apply the function to the dataset.
```{r}
for (i in seq_along(statements$Statement) ) {
  out_come <- classify_text(statements$Statement[[i]], classifier)
  statements[i, 'predicted_labels'] <- out_come[[1]]
  statements[i, 'prop_score'] <- out_come[[2]]
}
```

```{r}
statements[c("Type", "predicted_labels", "prop_score")]
```

</div>


<br>

#### __Performing NLP Tasks in R__

<div style="text-align: justify">

Flair NLP also provides a set of functions to perform NLP tasks, such as named entity recognition, sentiment analysis, and part-of-speech tagging. 

First, we load the data and the model to perform NER task on the text below.

> _Yesterday, Dr. Jane Smith spoke at the United Nations in New York. She discussed climate change and its impact on global economies. The event was attended by representatives from various countries including France and Japan. Dr. Smith mentioned that by 2050, the world could see a rise in sea level by approximately 2 feet. The World Health Organization (WHO) has pledged $50 million to combat the health effects of global warming. In an interview with The New York Times, Dr. Smith emphasized the urgent need for action. Later that day, she flew back to London, arriving at 10:00 PM GMT._

```{r}
Classifier <- flair_nn()$Classifier
Sentence <- flair_data()$Sentence

# load the model flair NLP already trained for us
tagger <- Classifier$load('ner')

# make a sentence object
text <- "Yesterday, Dr. Jane Smith spoke at the United Nations in New York. She discussed climate change and its impact on global economies. The event was attended by representatives from various countries including France and Japan. Dr. Smith mentioned that by 2050, the world could see a rise in sea level by approximately 2 feet. The World Health Organization (WHO) has pledged $50 million to combat the health effects of global warming. In an interview with The New York Times, Dr. Smith emphasized the urgent need for action. Later that day, she flew back to London, arriving at 10:00 PM GMT."
sentence <- Sentence(text)

# predict NER tags
tagger$predict(sentence)

# print sentence with predicted tags
print(sentence)
```


Alternatively, to facilitate more efficient use for social science research, {`flairR`} expands {`flairNLP/flair`}'s core functionality for working with three major functions to extract features in a tidy and fast format-- [data.table](https://cran.r-project.org/web/packages/data.table/index.html) in R. 

The expanded features in `flaiR` can be used to perform and extract features from the sentence object in a tidy format. 

- [**named entity recognition**](https://davidycliao.github.io/flaiR/articles/get_entities.html)
- [**transformer-based sentiment analysis**](https://davidycliao.github.io/flaiR/articles/get_sentiments.html)
- [**part-of-speech tagging**](https://davidycliao.github.io/flaiR/articles/get_pos.html)

For example, we can use the `get_entities` function and `load_tagger_ner("ner") `in flaiR to extract the named entities from the sentence object in a tidy format. 

```{r}
tagger_ner <- load_tagger_ner("ner")
results <- get_entities(text = text, 
                        doc_ids = "example text",
                        tagger_ner)
print(results)
```

In most cases, we need to extract the named entities from a large corpus. For example, we can use Stefan's data from ___The Temporal Focus of Campaign Communication___ (JOP 2022) as an example.

```{r}
library(flaiR)
data(cc_muller)
examples <- head(cc_muller, 10)
examples[c("text", "countryname")]
```

```{r}
tagger_ner <- load_tagger_ner("ner")
results <- get_entities(text = examples$text, 
                        doc_ids = examples$countryname,
                        tagger_ner)
print(results)
```


In addition, to handle the load on RAM when dealing with larger corpus, {`flairR`}  supports batch processing to handle texts in batches, which is especially useful when dealing with large datasets, to optimize memory usage and performance. The implementation of batch processing can also utilize GPU acceleration for faster computations.

</div>


## Contribution and Open Source


<div style="text-align: justify">

`{flaiR}` is maintained and developed by [David Liao](https://davidycliao.github.io) and friends in [Connected_Politics Lab](https://www.ucd.ie/connected_politics/) in UCD. R developers who want to contribute to {`flaiR`} are welcome â€“ {`flaiR`} is an open source project. I warmly invite R users who share similar interests to join in contributing to this package. Please feel free to shoot me an email to collaborate on the task. Contributions â€“ whether they be comments, code suggestions, tutorial examples, or forking the repository â€“ are greatly appreciated. Please note that the `flaiR` is released with the [Contributor Code of Conduct](https://github.com/davidycliao/flaiR/blob/master/CONDUCT.md). By contributing to this project, you agree to abide by its terms. 

The primary communication channel for R users can be found [here](https://github.com/davidycliao/flaiR/discussions). Please feel free to share your insights on the [Discussion](https://github.com/davidycliao/flaiR/discussions) page and report any issues related to the R interface in the [Issue](https://github.com/davidycliao/flaiR/issues) section. If the issue pertains to the actual implementation of Flair in Python, please submit a pull request to the offical [flair NLP](https://github.com/flairnlp/flair). 


</div>

<br>


